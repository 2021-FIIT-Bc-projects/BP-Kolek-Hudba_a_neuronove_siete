{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa32159f",
   "metadata": {},
   "source": [
    "# Hudba a neurónové siete\n",
    "## Bakárska práca\n",
    "### Peter Oliver Kolek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d922943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack, MetaMessage, bpm2tempo, Message\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from scipy.stats import gmean\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b128547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_content(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    return f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775690a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_midi(midi_file):\n",
    "    # open midi file\n",
    "    mid = MidiFile(midi_file, clip=True)\n",
    "\n",
    "    drum_track_number = 0\n",
    "    # find track number of drums\n",
    "    for i in range(len(mid.tracks)):\n",
    "        for j in range(len(mid.tracks[i])):\n",
    "            if mid.tracks[i][j].is_meta:\n",
    "                continue\n",
    "            if mid.tracks[i][j].channel == 9:\n",
    "                drum_track_number = i\n",
    "                break\n",
    "    print(\"Drum track number: \", str(drum_track_number))\n",
    "    return mid, mid.tracks[drum_track_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbacaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcription(drum_track, mid):\n",
    "    # find ticks per beat, and divide it to Thirty-Second 32 notes\n",
    "    ticks_per_beat_in_32_notes = mid.ticks_per_beat / 8\n",
    "#     print(ticks_per_beat_in_32_notes)\n",
    "    # change notes time to stick it to 32 notes\n",
    "    tmp_time = 0\n",
    "    time_with_note = {}\n",
    "    for i, message in enumerate(drum_track):\n",
    "        # find time how it goes through song\n",
    "        tmp_time += drum_track[i].time\n",
    "        message.time = round(tmp_time / ticks_per_beat_in_32_notes)\n",
    "#         print(\"i: \", i, \"msg time: \", message.time, \"tmp time: \", tmp_time, \"Msg_type: \", message.type)\n",
    "        # make velocity of notes same\n",
    "        if message.type == 'note_on':\n",
    "            if message.velocity > 0:\n",
    "                message.velocity = 1\n",
    "\n",
    "    # crating DataFrame for notes sticked to 32s and filter only note_on notes\n",
    "    transcription = pd.DataFrame(m.dict() for m in drum_track)\n",
    "    transcription = transcription[transcription.type == 'note_on']\n",
    "    # modify table to have columns for every note and lines with time (32 notes as they folow the song)\n",
    "    transcription = transcription.pivot_table(index='time', columns='note', values='velocity', fill_value=0)\n",
    "    # because we have 4/4 tempo, we have to add notes to have folowing 32 notes and empty values we fill with zeros\n",
    "    transcription = transcription.reindex(pd.RangeIndex(transcription.index.max() + 1)).fillna(0).sort_index()\n",
    "    # retype to int\n",
    "    transcription = transcription.astype(int)\n",
    "    transcription.columns = transcription.columns.astype(int)\n",
    "    transcription = transcription.reset_index(drop=True)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797eeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(tempo, transcription, ticks_per_beat, file_name, instruments):\n",
    "    # create new midi file\n",
    "    new_mid = MidiFile()\n",
    "    new_mid.ticks_per_beat = ticks_per_beat\n",
    "    meta_track = MidiTrack()\n",
    "    new_mid.tracks.append(meta_track)\n",
    "\n",
    "    # necessary meta track\n",
    "    meta_track.append(MetaMessage(type='track_name', name='meta_track', time=0))\n",
    "    meta_track.append(MetaMessage(type='time_signature', numerator=4, denominator=4, clocks_per_click=24,\n",
    "                                  notated_32nd_notes_per_beat=8, time=0))\n",
    "    meta_track.append(MetaMessage(type='set_tempo', tempo=bpm2tempo(tempo), time=0))\n",
    "\n",
    "    drum_track_new = MidiTrack()\n",
    "    new_mid.tracks.append(drum_track_new)\n",
    "\n",
    "    # apend notes to drum track\n",
    "\n",
    "    ticks_per_32note = int(ticks_per_beat/8)\n",
    "    notes_from_last_message = 0\n",
    "    for i, note in enumerate(transcription):\n",
    "        if i == 0:\n",
    "            for idx, inst in enumerate(note):\n",
    "                if inst == 0:\n",
    "                    continue\n",
    "                drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80, time=0))\n",
    "            continue\n",
    "        else:\n",
    "            if sum(note) < 1:\n",
    "                notes_from_last_message += 1\n",
    "                continue\n",
    "            else:\n",
    "                notes_from_last_message += 1\n",
    "\n",
    "            same_note_count = 0\n",
    "            for idx, inst in enumerate(note):\n",
    "                if inst == 0:\n",
    "                    pass\n",
    "                # if there are more notes at the same time played, they must have time 0\n",
    "                elif same_note_count == 0:\n",
    "                    drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80,\n",
    "                                                  time=notes_from_last_message * ticks_per_32note))\n",
    "                    same_note_count += 1\n",
    "                else:\n",
    "                    drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80, time=0))\n",
    "                    same_note_count += 1\n",
    "            notes_from_last_message = 0\n",
    "#     print(new_mid)\n",
    "    new_mid.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95fbb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ba59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BloodSugarSexMagik.mid', 'ParallelUniverse.mid', 'UniversallySpeaking.mid', 'Easily.mid', 'Snow(heyoh).mid', 'VeniceQueen.mid', 'FortuneFaded.mid', 'SuckMyKiss.mid', 'ZephyrSong.mid', 'FunkyMonks.mid', 'ThisVelvetGlove.mid']\n"
     ]
    }
   ],
   "source": [
    "rhcp_list = get_list_of_content('./RHCP_midi/list.txt')\n",
    "print(rhcp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drum track number:  5\n",
      "Drum track number:  7\n",
      "Drum track number:  1\n",
      "Drum track number:  3\n",
      "Drum track number:  7\n",
      "Drum track number:  8\n",
      "Drum track number:  4\n",
      "Drum track number:  3\n",
      "Drum track number:  5\n",
      "Drum track number:  7\n",
      "Drum track number:  5\n",
      "note   35  36  40  43  44  45  46  48  49  50  ...  51  52  57  39  42  47  \\\n",
      "0       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "1       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "2       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "3       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "39647   0   1   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   0   \n",
      "39648   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "39649   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "39650   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "39651   0   1   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   \n",
      "\n",
      "note   41  55  37  56  \n",
      "0       0   0   0   0  \n",
      "1       0   0   0   0  \n",
      "2       0   0   0   0  \n",
      "3       0   0   0   0  \n",
      "4       0   0   0   0  \n",
      "...    ..  ..  ..  ..  \n",
      "39647   0   0   0   0  \n",
      "39648   0   0   0   0  \n",
      "39649   0   0   0   0  \n",
      "39650   0   0   0   0  \n",
      "39651   0   0   0   0  \n",
      "\n",
      "[39652 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "rhcp_transcription_full = pd.DataFrame()\n",
    "frames = []\n",
    "for item in rhcp_list:\n",
    "#     print(item)\n",
    "    mid, drum_track = open_midi('./RHCP_midi/' + item)\n",
    "    transcription = get_transcription(drum_track, mid)\n",
    "    frames.append(transcription)\n",
    "    # print(transcription)\n",
    "    # for i in transcription:\n",
    "    #     print(i)\n",
    "    # find all instruments in song\n",
    "    instruments = transcription.columns.tolist()\n",
    "#     print(instruments)\n",
    "#     print(transcription)\n",
    "#     print()\n",
    "\n",
    "instruments = rhcp_transcription_full.columns.tolist()\n",
    "rhcp_transcription_full = pd.concat(frames)\n",
    "rhcp_transcription_full = rhcp_transcription_full.fillna(0)\n",
    "rhcp_transcription_full = rhcp_transcription_full.astype(int)\n",
    "rhcp_transcription_full = rhcp_transcription_full.reset_index(drop=True)\n",
    "# print(rhcp_transcription_full)\n",
    "instruments = rhcp_transcription_full.columns.tolist()\n",
    "# print(instruments)\n",
    "create_midi(120, rhcp_transcription_full.values, mid.ticks_per_beat, \"./output/transcription_full.mid\", instruments)\n",
    "# print(frames)\n",
    "# print(30*'*')\n",
    "# print(rhcp_transcription_full.count)\n",
    "# rhcp_transcription_full.to_csv(\"transcription_full.csv\")\n",
    "# print(30*'*')\n",
    "# print(30*'*')\n",
    "# for col in rhcp_transcription_full:\n",
    "#     print(col, rhcp_transcription_full[col].unique())\n",
    "print(rhcp_transcription_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65395d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27756"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split = int(rhcp_transcription_full.shape[0]*0.7)\n",
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6978f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = rhcp_transcription_full.loc[:train_test_split]\n",
    "test = rhcp_transcription_full.loc[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f55c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = []\n",
    "outputs_list = []\n",
    "sequence_len = 32\n",
    "raw_notes = train.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    inputs_list.append(raw_notes[input_start:input_end])\n",
    "    outputs_list.append(raw_notes[output_start:output_end])\n",
    "\n",
    "outputs_list = list(np.array(outputs_list).reshape(-1, np.array(outputs_list).shape[-1]))\n",
    "\n",
    "inputs_list = np.array(inputs_list)\n",
    "outputs_list = np.array(outputs_list)\n",
    "\n",
    "output_shape = outputs_list.shape[1]\n",
    "\n",
    "test_list = []\n",
    "test_out = []\n",
    "raw_notes = test.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    test_list.append(raw_notes[input_start:input_end])\n",
    "    test_out.append(raw_notes[output_start:output_end])\n",
    "\n",
    "test_out = list(np.array(test_out).reshape(-1, np.array(test_out).shape[-1]))\n",
    "\n",
    "test_list = np.array(test_list)\n",
    "test_out = np.array(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb251a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:01:52.305824: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32, 32)            6912      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32, 32)            8320      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 21)                693       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,245\n",
      "Trainable params: 24,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "778/780 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.1188 - binary_crossentropy: 0.1205\n",
      "Epoch 1: val_loss improved from inf to 0.13414, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 24s 25ms/step - loss: 0.1204 - accuracy: 0.1185 - binary_crossentropy: 0.1204 - val_loss: 0.1341 - val_accuracy: 0.0079 - val_binary_crossentropy: 0.1341\n",
      "Epoch 2/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.1383 - binary_crossentropy: 0.0915\n",
      "Epoch 2: val_loss improved from 0.13414 to 0.13397, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 23s 29ms/step - loss: 0.0915 - accuracy: 0.1383 - binary_crossentropy: 0.0915 - val_loss: 0.1340 - val_accuracy: 0.0079 - val_binary_crossentropy: 0.1340\n",
      "Epoch 3/300\n",
      "778/780 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.1368 - binary_crossentropy: 0.0912\n",
      "Epoch 3: val_loss did not improve from 0.13397\n",
      "780/780 [==============================] - 20s 26ms/step - loss: 0.0912 - accuracy: 0.1365 - binary_crossentropy: 0.0912 - val_loss: 0.1346 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1346\n",
      "Epoch 4/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.1389 - binary_crossentropy: 0.0911\n",
      "Epoch 4: val_loss did not improve from 0.13397\n",
      "780/780 [==============================] - 21s 27ms/step - loss: 0.0911 - accuracy: 0.1389 - binary_crossentropy: 0.0911 - val_loss: 0.1352 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1352\n",
      "Epoch 5/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.1341 - binary_crossentropy: 0.0908\n",
      "Epoch 5: val_loss did not improve from 0.13397\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0908 - accuracy: 0.1341 - binary_crossentropy: 0.0908 - val_loss: 0.1353 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1353\n",
      "Epoch 6/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.1387 - binary_crossentropy: 0.0909\n",
      "Epoch 6: val_loss did not improve from 0.13397\n",
      "780/780 [==============================] - 38s 48ms/step - loss: 0.0909 - accuracy: 0.1387 - binary_crossentropy: 0.0909 - val_loss: 0.1343 - val_accuracy: 0.0079 - val_binary_crossentropy: 0.1343\n",
      "Epoch 7/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.1327 - binary_crossentropy: 0.0916\n",
      "Epoch 7: val_loss improved from 0.13397 to 0.12851, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 34s 43ms/step - loss: 0.0916 - accuracy: 0.1327 - binary_crossentropy: 0.0916 - val_loss: 0.1285 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1285\n",
      "Epoch 8/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0900 - accuracy: 0.1683 - binary_crossentropy: 0.0900\n",
      "Epoch 8: val_loss improved from 0.12851 to 0.12653, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0900 - accuracy: 0.1683 - binary_crossentropy: 0.0900 - val_loss: 0.1265 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1265\n",
      "Epoch 9/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.1812 - binary_crossentropy: 0.0882\n",
      "Epoch 9: val_loss improved from 0.12653 to 0.11840, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 32s 40ms/step - loss: 0.0882 - accuracy: 0.1812 - binary_crossentropy: 0.0882 - val_loss: 0.1184 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.1184\n",
      "Epoch 10/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.1816 - binary_crossentropy: 0.0819\n",
      "Epoch 10: val_loss improved from 0.11840 to 0.10706, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0819 - accuracy: 0.1816 - binary_crossentropy: 0.0819 - val_loss: 0.1071 - val_accuracy: 0.0627 - val_binary_crossentropy: 0.1071\n",
      "Epoch 11/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.1640 - binary_crossentropy: 0.0641\n",
      "Epoch 11: val_loss improved from 0.10706 to 0.09653, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0641 - accuracy: 0.1640 - binary_crossentropy: 0.0641 - val_loss: 0.0965 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.0965\n",
      "Epoch 12/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.1617 - binary_crossentropy: 0.0574\n",
      "Epoch 12: val_loss improved from 0.09653 to 0.09165, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 32s 41ms/step - loss: 0.0574 - accuracy: 0.1617 - binary_crossentropy: 0.0574 - val_loss: 0.0917 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.0917\n",
      "Epoch 13/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.1710 - binary_crossentropy: 0.0551\n",
      "Epoch 13: val_loss improved from 0.09165 to 0.08324, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 35s 44ms/step - loss: 0.0551 - accuracy: 0.1710 - binary_crossentropy: 0.0551 - val_loss: 0.0832 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.0832\n",
      "Epoch 14/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.1837 - binary_crossentropy: 0.0521\n",
      "Epoch 14: val_loss improved from 0.08324 to 0.08177, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 33s 42ms/step - loss: 0.0521 - accuracy: 0.1837 - binary_crossentropy: 0.0521 - val_loss: 0.0818 - val_accuracy: 0.0635 - val_binary_crossentropy: 0.0818\n",
      "Epoch 15/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.1871 - binary_crossentropy: 0.0515\n",
      "Epoch 15: val_loss improved from 0.08177 to 0.08042, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0515 - accuracy: 0.1871 - binary_crossentropy: 0.0515 - val_loss: 0.0804 - val_accuracy: 0.0775 - val_binary_crossentropy: 0.0804\n",
      "Epoch 16/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.1948 - binary_crossentropy: 0.0488\n",
      "Epoch 16: val_loss improved from 0.08042 to 0.07895, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 33s 43ms/step - loss: 0.0488 - accuracy: 0.1948 - binary_crossentropy: 0.0488 - val_loss: 0.0790 - val_accuracy: 0.0829 - val_binary_crossentropy: 0.0790\n",
      "Epoch 17/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.2045 - binary_crossentropy: 0.0473\n",
      "Epoch 17: val_loss did not improve from 0.07895\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0473 - accuracy: 0.2045 - binary_crossentropy: 0.0473 - val_loss: 0.0791 - val_accuracy: 0.0664 - val_binary_crossentropy: 0.0791\n",
      "Epoch 18/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.2256 - binary_crossentropy: 0.0455\n",
      "Epoch 18: val_loss improved from 0.07895 to 0.07290, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0455 - accuracy: 0.2256 - binary_crossentropy: 0.0455 - val_loss: 0.0729 - val_accuracy: 0.0945 - val_binary_crossentropy: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.2340 - binary_crossentropy: 0.0441\n",
      "Epoch 19: val_loss improved from 0.07290 to 0.07191, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0441 - accuracy: 0.2340 - binary_crossentropy: 0.0441 - val_loss: 0.0719 - val_accuracy: 0.0851 - val_binary_crossentropy: 0.0719\n",
      "Epoch 20/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.2483 - binary_crossentropy: 0.0417\n",
      "Epoch 20: val_loss improved from 0.07191 to 0.06755, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0417 - accuracy: 0.2482 - binary_crossentropy: 0.0417 - val_loss: 0.0676 - val_accuracy: 0.0851 - val_binary_crossentropy: 0.0676\n",
      "Epoch 21/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.2945 - binary_crossentropy: 0.0407\n",
      "Epoch 21: val_loss improved from 0.06755 to 0.06671, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0407 - accuracy: 0.2944 - binary_crossentropy: 0.0407 - val_loss: 0.0667 - val_accuracy: 0.0855 - val_binary_crossentropy: 0.0667\n",
      "Epoch 22/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.2873 - binary_crossentropy: 0.0387\n",
      "Epoch 22: val_loss did not improve from 0.06671\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0387 - accuracy: 0.2872 - binary_crossentropy: 0.0387 - val_loss: 0.0765 - val_accuracy: 0.0851 - val_binary_crossentropy: 0.0765\n",
      "Epoch 23/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.2618 - binary_crossentropy: 0.0388\n",
      "Epoch 23: val_loss did not improve from 0.06671\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0388 - accuracy: 0.2616 - binary_crossentropy: 0.0388 - val_loss: 0.0698 - val_accuracy: 0.0829 - val_binary_crossentropy: 0.0698\n",
      "Epoch 24/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.2999 - binary_crossentropy: 0.0373\n",
      "Epoch 24: val_loss improved from 0.06671 to 0.06456, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 31s 39ms/step - loss: 0.0373 - accuracy: 0.2999 - binary_crossentropy: 0.0373 - val_loss: 0.0646 - val_accuracy: 0.0898 - val_binary_crossentropy: 0.0646\n",
      "Epoch 25/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.3320 - binary_crossentropy: 0.0366\n",
      "Epoch 25: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0366 - accuracy: 0.3320 - binary_crossentropy: 0.0366 - val_loss: 0.0687 - val_accuracy: 0.0851 - val_binary_crossentropy: 0.0687\n",
      "Epoch 26/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.3264 - binary_crossentropy: 0.0355\n",
      "Epoch 26: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0355 - accuracy: 0.3264 - binary_crossentropy: 0.0355 - val_loss: 0.0677 - val_accuracy: 0.0844 - val_binary_crossentropy: 0.0677\n",
      "Epoch 27/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.3048 - binary_crossentropy: 0.0337\n",
      "Epoch 27: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0337 - accuracy: 0.3048 - binary_crossentropy: 0.0337 - val_loss: 0.0694 - val_accuracy: 0.0804 - val_binary_crossentropy: 0.0694\n",
      "Epoch 28/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.2881 - binary_crossentropy: 0.0328\n",
      "Epoch 28: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0328 - accuracy: 0.2880 - binary_crossentropy: 0.0328 - val_loss: 0.0709 - val_accuracy: 0.1057 - val_binary_crossentropy: 0.0709\n",
      "Epoch 29/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.2985 - binary_crossentropy: 0.0323\n",
      "Epoch 29: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0323 - accuracy: 0.2983 - binary_crossentropy: 0.0323 - val_loss: 0.0691 - val_accuracy: 0.0815 - val_binary_crossentropy: 0.0691\n",
      "Epoch 30/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.3182 - binary_crossentropy: 0.0310\n",
      "Epoch 30: val_loss did not improve from 0.06456\n",
      "780/780 [==============================] - 31s 39ms/step - loss: 0.0309 - accuracy: 0.3180 - binary_crossentropy: 0.0309 - val_loss: 0.0647 - val_accuracy: 0.0865 - val_binary_crossentropy: 0.0647\n",
      "Epoch 31/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.3306 - binary_crossentropy: 0.0311\n",
      "Epoch 31: val_loss improved from 0.06456 to 0.05966, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0311 - accuracy: 0.3306 - binary_crossentropy: 0.0311 - val_loss: 0.0597 - val_accuracy: 0.0927 - val_binary_crossentropy: 0.0597\n",
      "Epoch 32/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.3344 - binary_crossentropy: 0.0302\n",
      "Epoch 32: val_loss improved from 0.05966 to 0.05441, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0302 - accuracy: 0.3344 - binary_crossentropy: 0.0302 - val_loss: 0.0544 - val_accuracy: 0.0934 - val_binary_crossentropy: 0.0544\n",
      "Epoch 33/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.3026 - binary_crossentropy: 0.0295\n",
      "Epoch 33: val_loss improved from 0.05441 to 0.05395, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0295 - accuracy: 0.3024 - binary_crossentropy: 0.0295 - val_loss: 0.0539 - val_accuracy: 0.1201 - val_binary_crossentropy: 0.0539\n",
      "Epoch 34/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.2847 - binary_crossentropy: 0.0285\n",
      "Epoch 34: val_loss did not improve from 0.05395\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0285 - accuracy: 0.2847 - binary_crossentropy: 0.0285 - val_loss: 0.0545 - val_accuracy: 0.1244 - val_binary_crossentropy: 0.0545\n",
      "Epoch 35/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.2770 - binary_crossentropy: 0.0283\n",
      "Epoch 35: val_loss did not improve from 0.05395\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0283 - accuracy: 0.2770 - binary_crossentropy: 0.0283 - val_loss: 0.0549 - val_accuracy: 0.1197 - val_binary_crossentropy: 0.0549\n",
      "Epoch 36/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.2383 - binary_crossentropy: 0.0276\n",
      "Epoch 36: val_loss did not improve from 0.05395\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0276 - accuracy: 0.2381 - binary_crossentropy: 0.0276 - val_loss: 0.0550 - val_accuracy: 0.1316 - val_binary_crossentropy: 0.0550\n",
      "Epoch 37/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.2599 - binary_crossentropy: 0.0268\n",
      "Epoch 37: val_loss improved from 0.05395 to 0.05235, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0268 - accuracy: 0.2599 - binary_crossentropy: 0.0268 - val_loss: 0.0524 - val_accuracy: 0.1381 - val_binary_crossentropy: 0.0524\n",
      "Epoch 38/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.2553 - binary_crossentropy: 0.0262\n",
      "Epoch 38: val_loss improved from 0.05235 to 0.05097, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0262 - accuracy: 0.2553 - binary_crossentropy: 0.0262 - val_loss: 0.0510 - val_accuracy: 0.1424 - val_binary_crossentropy: 0.0510\n",
      "Epoch 39/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.2724 - binary_crossentropy: 0.0256\n",
      "Epoch 39: val_loss did not improve from 0.05097\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0256 - accuracy: 0.2724 - binary_crossentropy: 0.0256 - val_loss: 0.0522 - val_accuracy: 0.1724 - val_binary_crossentropy: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.2835 - binary_crossentropy: 0.0247\n",
      "Epoch 40: val_loss improved from 0.05097 to 0.05072, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0247 - accuracy: 0.2835 - binary_crossentropy: 0.0247 - val_loss: 0.0507 - val_accuracy: 0.1626 - val_binary_crossentropy: 0.0507\n",
      "Epoch 41/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.2960 - binary_crossentropy: 0.0239\n",
      "Epoch 41: val_loss did not improve from 0.05072\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0239 - accuracy: 0.2960 - binary_crossentropy: 0.0239 - val_loss: 0.0508 - val_accuracy: 0.1821 - val_binary_crossentropy: 0.0508\n",
      "Epoch 42/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.2885 - binary_crossentropy: 0.0237\n",
      "Epoch 42: val_loss did not improve from 0.05072\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0237 - accuracy: 0.2884 - binary_crossentropy: 0.0237 - val_loss: 0.0513 - val_accuracy: 0.1727 - val_binary_crossentropy: 0.0513\n",
      "Epoch 43/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.3035 - binary_crossentropy: 0.0232\n",
      "Epoch 43: val_loss did not improve from 0.05072\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0232 - accuracy: 0.3035 - binary_crossentropy: 0.0232 - val_loss: 0.0515 - val_accuracy: 0.1598 - val_binary_crossentropy: 0.0515\n",
      "Epoch 44/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.3010 - binary_crossentropy: 0.0234\n",
      "Epoch 44: val_loss did not improve from 0.05072\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0234 - accuracy: 0.3009 - binary_crossentropy: 0.0234 - val_loss: 0.0511 - val_accuracy: 0.1839 - val_binary_crossentropy: 0.0511\n",
      "Epoch 45/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.3236 - binary_crossentropy: 0.0227\n",
      "Epoch 45: val_loss improved from 0.05072 to 0.05037, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0227 - accuracy: 0.3236 - binary_crossentropy: 0.0227 - val_loss: 0.0504 - val_accuracy: 0.1241 - val_binary_crossentropy: 0.0504\n",
      "Epoch 46/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.3080 - binary_crossentropy: 0.0224\n",
      "Epoch 46: val_loss improved from 0.05037 to 0.04803, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0224 - accuracy: 0.3080 - binary_crossentropy: 0.0224 - val_loss: 0.0480 - val_accuracy: 0.1558 - val_binary_crossentropy: 0.0480\n",
      "Epoch 47/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.3012 - binary_crossentropy: 0.0219\n",
      "Epoch 47: val_loss improved from 0.04803 to 0.04593, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0219 - accuracy: 0.3011 - binary_crossentropy: 0.0219 - val_loss: 0.0459 - val_accuracy: 0.1720 - val_binary_crossentropy: 0.0459\n",
      "Epoch 48/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.2981 - binary_crossentropy: 0.0217\n",
      "Epoch 48: val_loss did not improve from 0.04593\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0217 - accuracy: 0.2980 - binary_crossentropy: 0.0217 - val_loss: 0.0484 - val_accuracy: 0.1760 - val_binary_crossentropy: 0.0484\n",
      "Epoch 49/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.3154 - binary_crossentropy: 0.0214\n",
      "Epoch 49: val_loss did not improve from 0.04593\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0214 - accuracy: 0.3154 - binary_crossentropy: 0.0214 - val_loss: 0.0478 - val_accuracy: 0.1493 - val_binary_crossentropy: 0.0478\n",
      "Epoch 50/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.3343 - binary_crossentropy: 0.0209\n",
      "Epoch 50: val_loss did not improve from 0.04593\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0209 - accuracy: 0.3342 - binary_crossentropy: 0.0209 - val_loss: 0.0463 - val_accuracy: 0.1713 - val_binary_crossentropy: 0.0463\n",
      "Epoch 51/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.3079 - binary_crossentropy: 0.0208\n",
      "Epoch 51: val_loss improved from 0.04593 to 0.04508, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0208 - accuracy: 0.3079 - binary_crossentropy: 0.0208 - val_loss: 0.0451 - val_accuracy: 0.1572 - val_binary_crossentropy: 0.0451\n",
      "Epoch 52/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.2896 - binary_crossentropy: 0.0210\n",
      "Epoch 52: val_loss did not improve from 0.04508\n",
      "780/780 [==============================] - 31s 39ms/step - loss: 0.0210 - accuracy: 0.2895 - binary_crossentropy: 0.0210 - val_loss: 0.0460 - val_accuracy: 0.1641 - val_binary_crossentropy: 0.0460\n",
      "Epoch 53/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.3083 - binary_crossentropy: 0.0202\n",
      "Epoch 53: val_loss did not improve from 0.04508\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0202 - accuracy: 0.3083 - binary_crossentropy: 0.0202 - val_loss: 0.0451 - val_accuracy: 0.1724 - val_binary_crossentropy: 0.0451\n",
      "Epoch 54/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.3133 - binary_crossentropy: 0.0202\n",
      "Epoch 54: val_loss did not improve from 0.04508\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0202 - accuracy: 0.3131 - binary_crossentropy: 0.0202 - val_loss: 0.0480 - val_accuracy: 0.1781 - val_binary_crossentropy: 0.0480\n",
      "Epoch 55/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.3102 - binary_crossentropy: 0.0200\n",
      "Epoch 55: val_loss improved from 0.04508 to 0.04339, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0200 - accuracy: 0.3102 - binary_crossentropy: 0.0200 - val_loss: 0.0434 - val_accuracy: 0.1918 - val_binary_crossentropy: 0.0434\n",
      "Epoch 56/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.3105 - binary_crossentropy: 0.0196\n",
      "Epoch 56: val_loss did not improve from 0.04339\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0196 - accuracy: 0.3103 - binary_crossentropy: 0.0196 - val_loss: 0.0440 - val_accuracy: 0.1569 - val_binary_crossentropy: 0.0440\n",
      "Epoch 57/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.2993 - binary_crossentropy: 0.0197\n",
      "Epoch 57: val_loss did not improve from 0.04339\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0197 - accuracy: 0.2993 - binary_crossentropy: 0.0197 - val_loss: 0.0442 - val_accuracy: 0.1854 - val_binary_crossentropy: 0.0442\n",
      "Epoch 58/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3106 - binary_crossentropy: 0.0194\n",
      "Epoch 58: val_loss did not improve from 0.04339\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0194 - accuracy: 0.3105 - binary_crossentropy: 0.0194 - val_loss: 0.0437 - val_accuracy: 0.1771 - val_binary_crossentropy: 0.0437\n",
      "Epoch 59/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.3110 - binary_crossentropy: 0.0193\n",
      "Epoch 59: val_loss improved from 0.04339 to 0.04289, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0193 - accuracy: 0.3108 - binary_crossentropy: 0.0193 - val_loss: 0.0429 - val_accuracy: 0.1926 - val_binary_crossentropy: 0.0429\n",
      "Epoch 60/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.3011 - binary_crossentropy: 0.0187\n",
      "Epoch 60: val_loss did not improve from 0.04289\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0186 - accuracy: 0.3009 - binary_crossentropy: 0.0186 - val_loss: 0.0436 - val_accuracy: 0.1637 - val_binary_crossentropy: 0.0436\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/780 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.2931 - binary_crossentropy: 0.0187\n",
      "Epoch 61: val_loss did not improve from 0.04289\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0187 - accuracy: 0.2931 - binary_crossentropy: 0.0187 - val_loss: 0.0430 - val_accuracy: 0.1745 - val_binary_crossentropy: 0.0430\n",
      "Epoch 62/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.2967 - binary_crossentropy: 0.0185\n",
      "Epoch 62: val_loss improved from 0.04289 to 0.04277, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0185 - accuracy: 0.2966 - binary_crossentropy: 0.0185 - val_loss: 0.0428 - val_accuracy: 0.1727 - val_binary_crossentropy: 0.0428\n",
      "Epoch 63/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.2907 - binary_crossentropy: 0.0183\n",
      "Epoch 63: val_loss did not improve from 0.04277\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0182 - accuracy: 0.2906 - binary_crossentropy: 0.0182 - val_loss: 0.0446 - val_accuracy: 0.1727 - val_binary_crossentropy: 0.0446\n",
      "Epoch 64/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.2961 - binary_crossentropy: 0.0186\n",
      "Epoch 64: val_loss did not improve from 0.04277\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0186 - accuracy: 0.2961 - binary_crossentropy: 0.0186 - val_loss: 0.0428 - val_accuracy: 0.1958 - val_binary_crossentropy: 0.0428\n",
      "Epoch 65/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.3004 - binary_crossentropy: 0.0180\n",
      "Epoch 65: val_loss did not improve from 0.04277\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0180 - accuracy: 0.3004 - binary_crossentropy: 0.0180 - val_loss: 0.0438 - val_accuracy: 0.1702 - val_binary_crossentropy: 0.0438\n",
      "Epoch 66/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.2916 - binary_crossentropy: 0.0178\n",
      "Epoch 66: val_loss improved from 0.04277 to 0.04201, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0178 - accuracy: 0.2916 - binary_crossentropy: 0.0178 - val_loss: 0.0420 - val_accuracy: 0.1709 - val_binary_crossentropy: 0.0420\n",
      "Epoch 67/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.2915 - binary_crossentropy: 0.0178\n",
      "Epoch 67: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0178 - accuracy: 0.2915 - binary_crossentropy: 0.0178 - val_loss: 0.0435 - val_accuracy: 0.2041 - val_binary_crossentropy: 0.0435\n",
      "Epoch 68/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.2892 - binary_crossentropy: 0.0176\n",
      "Epoch 68: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0176 - accuracy: 0.2891 - binary_crossentropy: 0.0176 - val_loss: 0.0447 - val_accuracy: 0.1468 - val_binary_crossentropy: 0.0447\n",
      "Epoch 69/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.2780 - binary_crossentropy: 0.0180\n",
      "Epoch 69: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0180 - accuracy: 0.2779 - binary_crossentropy: 0.0180 - val_loss: 0.0424 - val_accuracy: 0.1799 - val_binary_crossentropy: 0.0424\n",
      "Epoch 70/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.2871 - binary_crossentropy: 0.0172\n",
      "Epoch 70: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0172 - accuracy: 0.2870 - binary_crossentropy: 0.0172 - val_loss: 0.0443 - val_accuracy: 0.1652 - val_binary_crossentropy: 0.0443\n",
      "Epoch 71/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.2829 - binary_crossentropy: 0.0172\n",
      "Epoch 71: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0172 - accuracy: 0.2829 - binary_crossentropy: 0.0172 - val_loss: 0.0421 - val_accuracy: 0.2452 - val_binary_crossentropy: 0.0421\n",
      "Epoch 72/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.2767 - binary_crossentropy: 0.0170\n",
      "Epoch 72: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0170 - accuracy: 0.2766 - binary_crossentropy: 0.0170 - val_loss: 0.0444 - val_accuracy: 0.1417 - val_binary_crossentropy: 0.0444\n",
      "Epoch 73/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.2740 - binary_crossentropy: 0.0172\n",
      "Epoch 73: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0172 - accuracy: 0.2740 - binary_crossentropy: 0.0172 - val_loss: 0.0450 - val_accuracy: 0.1262 - val_binary_crossentropy: 0.0450\n",
      "Epoch 74/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.2685 - binary_crossentropy: 0.0167\n",
      "Epoch 74: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0166 - accuracy: 0.2684 - binary_crossentropy: 0.0166 - val_loss: 0.0462 - val_accuracy: 0.1846 - val_binary_crossentropy: 0.0462\n",
      "Epoch 75/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.2797 - binary_crossentropy: 0.0167\n",
      "Epoch 75: val_loss did not improve from 0.04201\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0166 - accuracy: 0.2796 - binary_crossentropy: 0.0166 - val_loss: 0.0434 - val_accuracy: 0.1756 - val_binary_crossentropy: 0.0434\n",
      "Epoch 76/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.2709 - binary_crossentropy: 0.0166\n",
      "Epoch 76: val_loss improved from 0.04201 to 0.04199, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0166 - accuracy: 0.2707 - binary_crossentropy: 0.0166 - val_loss: 0.0420 - val_accuracy: 0.1673 - val_binary_crossentropy: 0.0420\n",
      "Epoch 77/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.2757 - binary_crossentropy: 0.0162\n",
      "Epoch 77: val_loss did not improve from 0.04199\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0162 - accuracy: 0.2756 - binary_crossentropy: 0.0162 - val_loss: 0.0437 - val_accuracy: 0.1652 - val_binary_crossentropy: 0.0437\n",
      "Epoch 78/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.2712 - binary_crossentropy: 0.0165\n",
      "Epoch 78: val_loss did not improve from 0.04199\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0165 - accuracy: 0.2712 - binary_crossentropy: 0.0165 - val_loss: 0.0481 - val_accuracy: 0.1637 - val_binary_crossentropy: 0.0481\n",
      "Epoch 79/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.2734 - binary_crossentropy: 0.0161\n",
      "Epoch 79: val_loss did not improve from 0.04199\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0161 - accuracy: 0.2734 - binary_crossentropy: 0.0161 - val_loss: 0.0438 - val_accuracy: 0.1432 - val_binary_crossentropy: 0.0438\n",
      "Epoch 80/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.2777 - binary_crossentropy: 0.0161\n",
      "Epoch 80: val_loss did not improve from 0.04199\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0161 - accuracy: 0.2777 - binary_crossentropy: 0.0161 - val_loss: 0.0435 - val_accuracy: 0.1515 - val_binary_crossentropy: 0.0435\n",
      "Epoch 81/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.2763 - binary_crossentropy: 0.0164\n",
      "Epoch 81: val_loss improved from 0.04199 to 0.03996, saving model to ./new_encode_1st_try.h5\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0164 - accuracy: 0.2763 - binary_crossentropy: 0.0164 - val_loss: 0.0400 - val_accuracy: 0.2564 - val_binary_crossentropy: 0.0400\n",
      "Epoch 82/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.2809 - binary_crossentropy: 0.0162\n",
      "Epoch 82: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0162 - accuracy: 0.2808 - binary_crossentropy: 0.0162 - val_loss: 0.0400 - val_accuracy: 0.2413 - val_binary_crossentropy: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.2789 - binary_crossentropy: 0.0163\n",
      "Epoch 83: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0163 - accuracy: 0.2789 - binary_crossentropy: 0.0163 - val_loss: 0.0434 - val_accuracy: 0.1818 - val_binary_crossentropy: 0.0434\n",
      "Epoch 84/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.2839 - binary_crossentropy: 0.0163\n",
      "Epoch 84: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0163 - accuracy: 0.2839 - binary_crossentropy: 0.0163 - val_loss: 0.0424 - val_accuracy: 0.1691 - val_binary_crossentropy: 0.0424\n",
      "Epoch 85/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.2787 - binary_crossentropy: 0.0158\n",
      "Epoch 85: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0158 - accuracy: 0.2787 - binary_crossentropy: 0.0158 - val_loss: 0.0474 - val_accuracy: 0.2048 - val_binary_crossentropy: 0.0474\n",
      "Epoch 86/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.2823 - binary_crossentropy: 0.0160\n",
      "Epoch 86: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0160 - accuracy: 0.2823 - binary_crossentropy: 0.0160 - val_loss: 0.0451 - val_accuracy: 0.1933 - val_binary_crossentropy: 0.0451\n",
      "Epoch 87/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.2826 - binary_crossentropy: 0.0156\n",
      "Epoch 87: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0155 - accuracy: 0.2825 - binary_crossentropy: 0.0155 - val_loss: 0.0428 - val_accuracy: 0.2286 - val_binary_crossentropy: 0.0428\n",
      "Epoch 88/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.2726 - binary_crossentropy: 0.0155\n",
      "Epoch 88: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0155 - accuracy: 0.2725 - binary_crossentropy: 0.0155 - val_loss: 0.0460 - val_accuracy: 0.1843 - val_binary_crossentropy: 0.0460\n",
      "Epoch 89/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.2803 - binary_crossentropy: 0.0154\n",
      "Epoch 89: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0154 - accuracy: 0.2803 - binary_crossentropy: 0.0154 - val_loss: 0.0460 - val_accuracy: 0.2218 - val_binary_crossentropy: 0.0460\n",
      "Epoch 90/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.2746 - binary_crossentropy: 0.0153\n",
      "Epoch 90: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0153 - accuracy: 0.2745 - binary_crossentropy: 0.0153 - val_loss: 0.0425 - val_accuracy: 0.3621 - val_binary_crossentropy: 0.0425\n",
      "Epoch 91/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.2782 - binary_crossentropy: 0.0156\n",
      "Epoch 91: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0155 - accuracy: 0.2781 - binary_crossentropy: 0.0155 - val_loss: 0.0439 - val_accuracy: 0.2092 - val_binary_crossentropy: 0.0439\n",
      "Epoch 92/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.2726 - binary_crossentropy: 0.0150\n",
      "Epoch 92: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0150 - accuracy: 0.2726 - binary_crossentropy: 0.0150 - val_loss: 0.0435 - val_accuracy: 0.2651 - val_binary_crossentropy: 0.0435\n",
      "Epoch 93/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.2810 - binary_crossentropy: 0.0148\n",
      "Epoch 93: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0148 - accuracy: 0.2810 - binary_crossentropy: 0.0148 - val_loss: 0.0415 - val_accuracy: 0.3469 - val_binary_crossentropy: 0.0415\n",
      "Epoch 94/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.2851 - binary_crossentropy: 0.0150\n",
      "Epoch 94: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0150 - accuracy: 0.2850 - binary_crossentropy: 0.0150 - val_loss: 0.0437 - val_accuracy: 0.2391 - val_binary_crossentropy: 0.0437\n",
      "Epoch 95/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.2856 - binary_crossentropy: 0.0148\n",
      "Epoch 95: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0148 - accuracy: 0.2856 - binary_crossentropy: 0.0148 - val_loss: 0.0445 - val_accuracy: 0.3051 - val_binary_crossentropy: 0.0445\n",
      "Epoch 96/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.2870 - binary_crossentropy: 0.0148\n",
      "Epoch 96: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0148 - accuracy: 0.2870 - binary_crossentropy: 0.0148 - val_loss: 0.0464 - val_accuracy: 0.2178 - val_binary_crossentropy: 0.0464\n",
      "Epoch 97/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.2777 - binary_crossentropy: 0.0149\n",
      "Epoch 97: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0149 - accuracy: 0.2777 - binary_crossentropy: 0.0149 - val_loss: 0.0442 - val_accuracy: 0.2290 - val_binary_crossentropy: 0.0442\n",
      "Epoch 98/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.2781 - binary_crossentropy: 0.0146\n",
      "Epoch 98: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0146 - accuracy: 0.2780 - binary_crossentropy: 0.0146 - val_loss: 0.0434 - val_accuracy: 0.2506 - val_binary_crossentropy: 0.0434\n",
      "Epoch 99/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.2704 - binary_crossentropy: 0.0145\n",
      "Epoch 99: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0145 - accuracy: 0.2703 - binary_crossentropy: 0.0145 - val_loss: 0.0439 - val_accuracy: 0.2167 - val_binary_crossentropy: 0.0439\n",
      "Epoch 100/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.2840 - binary_crossentropy: 0.0143\n",
      "Epoch 100: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0143 - accuracy: 0.2839 - binary_crossentropy: 0.0143 - val_loss: 0.0468 - val_accuracy: 0.2074 - val_binary_crossentropy: 0.0468\n",
      "Epoch 101/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.2779 - binary_crossentropy: 0.0144\n",
      "Epoch 101: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0144 - accuracy: 0.2779 - binary_crossentropy: 0.0144 - val_loss: 0.0439 - val_accuracy: 0.2939 - val_binary_crossentropy: 0.0439\n",
      "Epoch 102/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.2708 - binary_crossentropy: 0.0144\n",
      "Epoch 102: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0144 - accuracy: 0.2707 - binary_crossentropy: 0.0144 - val_loss: 0.0440 - val_accuracy: 0.2344 - val_binary_crossentropy: 0.0440\n",
      "Epoch 103/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.2820 - binary_crossentropy: 0.0142\n",
      "Epoch 103: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0142 - accuracy: 0.2819 - binary_crossentropy: 0.0142 - val_loss: 0.0425 - val_accuracy: 0.2726 - val_binary_crossentropy: 0.0425\n",
      "Epoch 104/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.2831 - binary_crossentropy: 0.0142\n",
      "Epoch 104: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0142 - accuracy: 0.2831 - binary_crossentropy: 0.0142 - val_loss: 0.0419 - val_accuracy: 0.3671 - val_binary_crossentropy: 0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.2823 - binary_crossentropy: 0.0142\n",
      "Epoch 105: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0142 - accuracy: 0.2823 - binary_crossentropy: 0.0142 - val_loss: 0.0407 - val_accuracy: 0.2903 - val_binary_crossentropy: 0.0407\n",
      "Epoch 106/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.2807 - binary_crossentropy: 0.0144\n",
      "Epoch 106: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0144 - accuracy: 0.2806 - binary_crossentropy: 0.0144 - val_loss: 0.0457 - val_accuracy: 0.3173 - val_binary_crossentropy: 0.0457\n",
      "Epoch 107/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.2765 - binary_crossentropy: 0.0138\n",
      "Epoch 107: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0138 - accuracy: 0.2763 - binary_crossentropy: 0.0138 - val_loss: 0.0467 - val_accuracy: 0.2308 - val_binary_crossentropy: 0.0467\n",
      "Epoch 108/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.2769 - binary_crossentropy: 0.0136\n",
      "Epoch 108: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0136 - accuracy: 0.2769 - binary_crossentropy: 0.0136 - val_loss: 0.0438 - val_accuracy: 0.2917 - val_binary_crossentropy: 0.0438\n",
      "Epoch 109/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.2812 - binary_crossentropy: 0.0141\n",
      "Epoch 109: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0141 - accuracy: 0.2811 - binary_crossentropy: 0.0141 - val_loss: 0.0464 - val_accuracy: 0.2878 - val_binary_crossentropy: 0.0464\n",
      "Epoch 110/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.2908 - binary_crossentropy: 0.0137\n",
      "Epoch 110: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0137 - accuracy: 0.2906 - binary_crossentropy: 0.0137 - val_loss: 0.0458 - val_accuracy: 0.1659 - val_binary_crossentropy: 0.0458\n",
      "Epoch 111/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.2839 - binary_crossentropy: 0.0139\n",
      "Epoch 111: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0139 - accuracy: 0.2839 - binary_crossentropy: 0.0139 - val_loss: 0.0457 - val_accuracy: 0.2780 - val_binary_crossentropy: 0.0457\n",
      "Epoch 112/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.2769 - binary_crossentropy: 0.0135\n",
      "Epoch 112: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0135 - accuracy: 0.2769 - binary_crossentropy: 0.0135 - val_loss: 0.0488 - val_accuracy: 0.2276 - val_binary_crossentropy: 0.0488\n",
      "Epoch 113/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.2831 - binary_crossentropy: 0.0140\n",
      "Epoch 113: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0140 - accuracy: 0.2831 - binary_crossentropy: 0.0140 - val_loss: 0.0492 - val_accuracy: 0.2816 - val_binary_crossentropy: 0.0492\n",
      "Epoch 114/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.2779 - binary_crossentropy: 0.0134\n",
      "Epoch 114: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0134 - accuracy: 0.2779 - binary_crossentropy: 0.0134 - val_loss: 0.0481 - val_accuracy: 0.2095 - val_binary_crossentropy: 0.0481\n",
      "Epoch 115/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.2831 - binary_crossentropy: 0.0137\n",
      "Epoch 115: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0137 - accuracy: 0.2831 - binary_crossentropy: 0.0137 - val_loss: 0.0497 - val_accuracy: 0.1457 - val_binary_crossentropy: 0.0497\n",
      "Epoch 116/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.2873 - binary_crossentropy: 0.0136\n",
      "Epoch 116: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0136 - accuracy: 0.2872 - binary_crossentropy: 0.0136 - val_loss: 0.0472 - val_accuracy: 0.2362 - val_binary_crossentropy: 0.0472\n",
      "Epoch 117/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.2914 - binary_crossentropy: 0.0133\n",
      "Epoch 117: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0132 - accuracy: 0.2913 - binary_crossentropy: 0.0132 - val_loss: 0.0490 - val_accuracy: 0.2596 - val_binary_crossentropy: 0.0490\n",
      "Epoch 118/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.2766 - binary_crossentropy: 0.0132\n",
      "Epoch 118: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0132 - accuracy: 0.2765 - binary_crossentropy: 0.0132 - val_loss: 0.0482 - val_accuracy: 0.1915 - val_binary_crossentropy: 0.0482\n",
      "Epoch 119/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.2832 - binary_crossentropy: 0.0133\n",
      "Epoch 119: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0133 - accuracy: 0.2832 - binary_crossentropy: 0.0133 - val_loss: 0.0489 - val_accuracy: 0.1807 - val_binary_crossentropy: 0.0489\n",
      "Epoch 120/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.2803 - binary_crossentropy: 0.0133\n",
      "Epoch 120: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 31s 39ms/step - loss: 0.0133 - accuracy: 0.2801 - binary_crossentropy: 0.0133 - val_loss: 0.0469 - val_accuracy: 0.1937 - val_binary_crossentropy: 0.0469\n",
      "Epoch 121/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.2917 - binary_crossentropy: 0.0130\n",
      "Epoch 121: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0130 - accuracy: 0.2916 - binary_crossentropy: 0.0130 - val_loss: 0.0468 - val_accuracy: 0.2167 - val_binary_crossentropy: 0.0468\n",
      "Epoch 122/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.2878 - binary_crossentropy: 0.0134\n",
      "Epoch 122: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0134 - accuracy: 0.2878 - binary_crossentropy: 0.0134 - val_loss: 0.0476 - val_accuracy: 0.2070 - val_binary_crossentropy: 0.0476\n",
      "Epoch 123/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.2836 - binary_crossentropy: 0.0129\n",
      "Epoch 123: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0129 - accuracy: 0.2835 - binary_crossentropy: 0.0129 - val_loss: 0.0485 - val_accuracy: 0.2268 - val_binary_crossentropy: 0.0485\n",
      "Epoch 124/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.2995 - binary_crossentropy: 0.0130\n",
      "Epoch 124: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0130 - accuracy: 0.2995 - binary_crossentropy: 0.0130 - val_loss: 0.0468 - val_accuracy: 0.2366 - val_binary_crossentropy: 0.0468\n",
      "Epoch 125/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.2863 - binary_crossentropy: 0.0131\n",
      "Epoch 125: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0131 - accuracy: 0.2861 - binary_crossentropy: 0.0131 - val_loss: 0.0500 - val_accuracy: 0.1879 - val_binary_crossentropy: 0.0500\n",
      "Epoch 126/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.2792 - binary_crossentropy: 0.0131\n",
      "Epoch 126: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0131 - accuracy: 0.2792 - binary_crossentropy: 0.0131 - val_loss: 0.0508 - val_accuracy: 0.1652 - val_binary_crossentropy: 0.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.2958 - binary_crossentropy: 0.0129\n",
      "Epoch 127: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0129 - accuracy: 0.2958 - binary_crossentropy: 0.0129 - val_loss: 0.0457 - val_accuracy: 0.4198 - val_binary_crossentropy: 0.0457\n",
      "Epoch 128/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.2880 - binary_crossentropy: 0.0127\n",
      "Epoch 128: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0127 - accuracy: 0.2880 - binary_crossentropy: 0.0127 - val_loss: 0.0446 - val_accuracy: 0.2294 - val_binary_crossentropy: 0.0446\n",
      "Epoch 129/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.2843 - binary_crossentropy: 0.0131\n",
      "Epoch 129: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0131 - accuracy: 0.2843 - binary_crossentropy: 0.0131 - val_loss: 0.0468 - val_accuracy: 0.2027 - val_binary_crossentropy: 0.0468\n",
      "Epoch 130/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.2932 - binary_crossentropy: 0.0127\n",
      "Epoch 130: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0127 - accuracy: 0.2930 - binary_crossentropy: 0.0127 - val_loss: 0.0470 - val_accuracy: 0.2117 - val_binary_crossentropy: 0.0470\n",
      "Epoch 131/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.3002 - binary_crossentropy: 0.0128\n",
      "Epoch 131: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0128 - accuracy: 0.3002 - binary_crossentropy: 0.0128 - val_loss: 0.0466 - val_accuracy: 0.2925 - val_binary_crossentropy: 0.0466\n",
      "Epoch 132/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.2912 - binary_crossentropy: 0.0126\n",
      "Epoch 132: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0126 - accuracy: 0.2912 - binary_crossentropy: 0.0126 - val_loss: 0.0462 - val_accuracy: 0.2993 - val_binary_crossentropy: 0.0462\n",
      "Epoch 133/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.2950 - binary_crossentropy: 0.0131\n",
      "Epoch 133: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0131 - accuracy: 0.2949 - binary_crossentropy: 0.0131 - val_loss: 0.0470 - val_accuracy: 0.2719 - val_binary_crossentropy: 0.0470\n",
      "Epoch 134/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.2896 - binary_crossentropy: 0.0125\n",
      "Epoch 134: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0125 - accuracy: 0.2896 - binary_crossentropy: 0.0125 - val_loss: 0.0486 - val_accuracy: 0.3220 - val_binary_crossentropy: 0.0486\n",
      "Epoch 135/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.2833 - binary_crossentropy: 0.0125\n",
      "Epoch 135: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0125 - accuracy: 0.2833 - binary_crossentropy: 0.0125 - val_loss: 0.0466 - val_accuracy: 0.2935 - val_binary_crossentropy: 0.0466\n",
      "Epoch 136/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.2936 - binary_crossentropy: 0.0128\n",
      "Epoch 136: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0128 - accuracy: 0.2935 - binary_crossentropy: 0.0128 - val_loss: 0.0489 - val_accuracy: 0.2853 - val_binary_crossentropy: 0.0489\n",
      "Epoch 137/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.2953 - binary_crossentropy: 0.0125\n",
      "Epoch 137: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0125 - accuracy: 0.2952 - binary_crossentropy: 0.0125 - val_loss: 0.0532 - val_accuracy: 0.2239 - val_binary_crossentropy: 0.0532\n",
      "Epoch 138/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.2825 - binary_crossentropy: 0.0124\n",
      "Epoch 138: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0124 - accuracy: 0.2824 - binary_crossentropy: 0.0124 - val_loss: 0.0504 - val_accuracy: 0.2485 - val_binary_crossentropy: 0.0504\n",
      "Epoch 139/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.2898 - binary_crossentropy: 0.0124\n",
      "Epoch 139: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0124 - accuracy: 0.2897 - binary_crossentropy: 0.0124 - val_loss: 0.0500 - val_accuracy: 0.2178 - val_binary_crossentropy: 0.0500\n",
      "Epoch 140/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.2883 - binary_crossentropy: 0.0123\n",
      "Epoch 140: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0123 - accuracy: 0.2883 - binary_crossentropy: 0.0123 - val_loss: 0.0545 - val_accuracy: 0.2239 - val_binary_crossentropy: 0.0545\n",
      "Epoch 141/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.2908 - binary_crossentropy: 0.0122\n",
      "Epoch 141: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0122 - accuracy: 0.2908 - binary_crossentropy: 0.0122 - val_loss: 0.0518 - val_accuracy: 0.3527 - val_binary_crossentropy: 0.0518\n",
      "Epoch 142/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.2933 - binary_crossentropy: 0.0123\n",
      "Epoch 142: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0123 - accuracy: 0.2933 - binary_crossentropy: 0.0123 - val_loss: 0.0516 - val_accuracy: 0.2355 - val_binary_crossentropy: 0.0516\n",
      "Epoch 143/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.2966 - binary_crossentropy: 0.0123\n",
      "Epoch 143: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0123 - accuracy: 0.2966 - binary_crossentropy: 0.0123 - val_loss: 0.0476 - val_accuracy: 0.3649 - val_binary_crossentropy: 0.0476\n",
      "Epoch 144/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.2912 - binary_crossentropy: 0.0123\n",
      "Epoch 144: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0123 - accuracy: 0.2912 - binary_crossentropy: 0.0123 - val_loss: 0.0480 - val_accuracy: 0.3098 - val_binary_crossentropy: 0.0480\n",
      "Epoch 145/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.2955 - binary_crossentropy: 0.0122\n",
      "Epoch 145: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0122 - accuracy: 0.2954 - binary_crossentropy: 0.0122 - val_loss: 0.0530 - val_accuracy: 0.2539 - val_binary_crossentropy: 0.0530\n",
      "Epoch 146/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.2976 - binary_crossentropy: 0.0123\n",
      "Epoch 146: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0123 - accuracy: 0.2974 - binary_crossentropy: 0.0123 - val_loss: 0.0493 - val_accuracy: 0.3116 - val_binary_crossentropy: 0.0493\n",
      "Epoch 147/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.2964 - binary_crossentropy: 0.0119\n",
      "Epoch 147: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0119 - accuracy: 0.2964 - binary_crossentropy: 0.0119 - val_loss: 0.0508 - val_accuracy: 0.2517 - val_binary_crossentropy: 0.0508\n",
      "Epoch 148/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.2928 - binary_crossentropy: 0.0121\n",
      "Epoch 148: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0121 - accuracy: 0.2926 - binary_crossentropy: 0.0121 - val_loss: 0.0501 - val_accuracy: 0.2445 - val_binary_crossentropy: 0.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.2874 - binary_crossentropy: 0.0123\n",
      "Epoch 149: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0123 - accuracy: 0.2874 - binary_crossentropy: 0.0123 - val_loss: 0.0507 - val_accuracy: 0.2986 - val_binary_crossentropy: 0.0507\n",
      "Epoch 150/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.3114 - binary_crossentropy: 0.0120\n",
      "Epoch 150: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0120 - accuracy: 0.3113 - binary_crossentropy: 0.0120 - val_loss: 0.0483 - val_accuracy: 0.3213 - val_binary_crossentropy: 0.0483\n",
      "Epoch 151/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.2923 - binary_crossentropy: 0.0121\n",
      "Epoch 151: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0121 - accuracy: 0.2923 - binary_crossentropy: 0.0121 - val_loss: 0.0490 - val_accuracy: 0.2701 - val_binary_crossentropy: 0.0490\n",
      "Epoch 152/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.3090 - binary_crossentropy: 0.0120\n",
      "Epoch 152: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0120 - accuracy: 0.3088 - binary_crossentropy: 0.0120 - val_loss: 0.0484 - val_accuracy: 0.3458 - val_binary_crossentropy: 0.0484\n",
      "Epoch 153/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.2940 - binary_crossentropy: 0.0119\n",
      "Epoch 153: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0119 - accuracy: 0.2940 - binary_crossentropy: 0.0119 - val_loss: 0.0505 - val_accuracy: 0.2514 - val_binary_crossentropy: 0.0505\n",
      "Epoch 154/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.2926 - binary_crossentropy: 0.0121\n",
      "Epoch 154: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0121 - accuracy: 0.2924 - binary_crossentropy: 0.0121 - val_loss: 0.0497 - val_accuracy: 0.3458 - val_binary_crossentropy: 0.0497\n",
      "Epoch 155/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.3049 - binary_crossentropy: 0.0118\n",
      "Epoch 155: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0118 - accuracy: 0.3049 - binary_crossentropy: 0.0118 - val_loss: 0.0471 - val_accuracy: 0.3978 - val_binary_crossentropy: 0.0471\n",
      "Epoch 156/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.3003 - binary_crossentropy: 0.0121\n",
      "Epoch 156: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0121 - accuracy: 0.3001 - binary_crossentropy: 0.0121 - val_loss: 0.0483 - val_accuracy: 0.4100 - val_binary_crossentropy: 0.0483\n",
      "Epoch 157/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.2967 - binary_crossentropy: 0.0120\n",
      "Epoch 157: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0120 - accuracy: 0.2965 - binary_crossentropy: 0.0120 - val_loss: 0.0519 - val_accuracy: 0.4010 - val_binary_crossentropy: 0.0519\n",
      "Epoch 158/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.2960 - binary_crossentropy: 0.0119\n",
      "Epoch 158: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0119 - accuracy: 0.2958 - binary_crossentropy: 0.0119 - val_loss: 0.0507 - val_accuracy: 0.4050 - val_binary_crossentropy: 0.0507\n",
      "Epoch 159/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.3016 - binary_crossentropy: 0.0118\n",
      "Epoch 159: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0118 - accuracy: 0.3016 - binary_crossentropy: 0.0118 - val_loss: 0.0484 - val_accuracy: 0.3152 - val_binary_crossentropy: 0.0484\n",
      "Epoch 160/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.2869 - binary_crossentropy: 0.0115\n",
      "Epoch 160: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0115 - accuracy: 0.2868 - binary_crossentropy: 0.0115 - val_loss: 0.0491 - val_accuracy: 0.3163 - val_binary_crossentropy: 0.0491\n",
      "Epoch 161/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.2910 - binary_crossentropy: 0.0116\n",
      "Epoch 161: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0116 - accuracy: 0.2908 - binary_crossentropy: 0.0116 - val_loss: 0.0496 - val_accuracy: 0.2560 - val_binary_crossentropy: 0.0496\n",
      "Epoch 162/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.3000 - binary_crossentropy: 0.0114\n",
      "Epoch 162: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0114 - accuracy: 0.2999 - binary_crossentropy: 0.0114 - val_loss: 0.0487 - val_accuracy: 0.1814 - val_binary_crossentropy: 0.0487\n",
      "Epoch 163/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.2874 - binary_crossentropy: 0.0117\n",
      "Epoch 163: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0117 - accuracy: 0.2872 - binary_crossentropy: 0.0117 - val_loss: 0.0478 - val_accuracy: 0.2752 - val_binary_crossentropy: 0.0478\n",
      "Epoch 164/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.2907 - binary_crossentropy: 0.0116\n",
      "Epoch 164: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0116 - accuracy: 0.2907 - binary_crossentropy: 0.0116 - val_loss: 0.0477 - val_accuracy: 0.3130 - val_binary_crossentropy: 0.0477\n",
      "Epoch 165/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.2992 - binary_crossentropy: 0.0116\n",
      "Epoch 165: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0116 - accuracy: 0.2992 - binary_crossentropy: 0.0116 - val_loss: 0.0478 - val_accuracy: 0.3657 - val_binary_crossentropy: 0.0478\n",
      "Epoch 166/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.3076 - binary_crossentropy: 0.0115\n",
      "Epoch 166: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0115 - accuracy: 0.3074 - binary_crossentropy: 0.0115 - val_loss: 0.0492 - val_accuracy: 0.3029 - val_binary_crossentropy: 0.0492\n",
      "Epoch 167/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.3073 - binary_crossentropy: 0.0117\n",
      "Epoch 167: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 31s 40ms/step - loss: 0.0117 - accuracy: 0.3071 - binary_crossentropy: 0.0117 - val_loss: 0.0495 - val_accuracy: 0.3707 - val_binary_crossentropy: 0.0495\n",
      "Epoch 168/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.2858 - binary_crossentropy: 0.0114\n",
      "Epoch 168: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0114 - accuracy: 0.2857 - binary_crossentropy: 0.0114 - val_loss: 0.0517 - val_accuracy: 0.2964 - val_binary_crossentropy: 0.0517\n",
      "Epoch 169/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.2908 - binary_crossentropy: 0.0117\n",
      "Epoch 169: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0117 - accuracy: 0.2908 - binary_crossentropy: 0.0117 - val_loss: 0.0490 - val_accuracy: 0.2286 - val_binary_crossentropy: 0.0490\n",
      "Epoch 170/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.3045 - binary_crossentropy: 0.0113\n",
      "Epoch 170: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0113 - accuracy: 0.3045 - binary_crossentropy: 0.0113 - val_loss: 0.0543 - val_accuracy: 0.2099 - val_binary_crossentropy: 0.0543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.3013 - binary_crossentropy: 0.0112\n",
      "Epoch 171: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0112 - accuracy: 0.3013 - binary_crossentropy: 0.0112 - val_loss: 0.0505 - val_accuracy: 0.3934 - val_binary_crossentropy: 0.0505\n",
      "Epoch 172/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.3092 - binary_crossentropy: 0.0113\n",
      "Epoch 172: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0113 - accuracy: 0.3092 - binary_crossentropy: 0.0113 - val_loss: 0.0514 - val_accuracy: 0.2780 - val_binary_crossentropy: 0.0514\n",
      "Epoch 173/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.3066 - binary_crossentropy: 0.0114\n",
      "Epoch 173: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0114 - accuracy: 0.3066 - binary_crossentropy: 0.0114 - val_loss: 0.0517 - val_accuracy: 0.3036 - val_binary_crossentropy: 0.0517\n",
      "Epoch 174/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.3161 - binary_crossentropy: 0.0114\n",
      "Epoch 174: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0114 - accuracy: 0.3161 - binary_crossentropy: 0.0114 - val_loss: 0.0512 - val_accuracy: 0.2463 - val_binary_crossentropy: 0.0512\n",
      "Epoch 175/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.3123 - binary_crossentropy: 0.0111\n",
      "Epoch 175: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0111 - accuracy: 0.3122 - binary_crossentropy: 0.0111 - val_loss: 0.0528 - val_accuracy: 0.2402 - val_binary_crossentropy: 0.0528\n",
      "Epoch 176/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.3025 - binary_crossentropy: 0.0113\n",
      "Epoch 176: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0113 - accuracy: 0.3025 - binary_crossentropy: 0.0113 - val_loss: 0.0579 - val_accuracy: 0.1893 - val_binary_crossentropy: 0.0579\n",
      "Epoch 177/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.3126 - binary_crossentropy: 0.0113\n",
      "Epoch 177: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0113 - accuracy: 0.3124 - binary_crossentropy: 0.0113 - val_loss: 0.0537 - val_accuracy: 0.2337 - val_binary_crossentropy: 0.0537\n",
      "Epoch 178/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.3289 - binary_crossentropy: 0.0115\n",
      "Epoch 178: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0115 - accuracy: 0.3289 - binary_crossentropy: 0.0115 - val_loss: 0.0545 - val_accuracy: 0.2236 - val_binary_crossentropy: 0.0545\n",
      "Epoch 179/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.3112 - binary_crossentropy: 0.0112\n",
      "Epoch 179: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0112 - accuracy: 0.3112 - binary_crossentropy: 0.0112 - val_loss: 0.0519 - val_accuracy: 0.1933 - val_binary_crossentropy: 0.0519\n",
      "Epoch 180/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.3158 - binary_crossentropy: 0.0112\n",
      "Epoch 180: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0112 - accuracy: 0.3156 - binary_crossentropy: 0.0112 - val_loss: 0.0514 - val_accuracy: 0.2128 - val_binary_crossentropy: 0.0514\n",
      "Epoch 181/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.3114 - binary_crossentropy: 0.0108\n",
      "Epoch 181: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0108 - accuracy: 0.3112 - binary_crossentropy: 0.0108 - val_loss: 0.0520 - val_accuracy: 0.1911 - val_binary_crossentropy: 0.0520\n",
      "Epoch 182/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.3178 - binary_crossentropy: 0.0113\n",
      "Epoch 182: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0113 - accuracy: 0.3176 - binary_crossentropy: 0.0113 - val_loss: 0.0538 - val_accuracy: 0.2578 - val_binary_crossentropy: 0.0538\n",
      "Epoch 183/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.3208 - binary_crossentropy: 0.0111\n",
      "Epoch 183: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0111 - accuracy: 0.3206 - binary_crossentropy: 0.0111 - val_loss: 0.0516 - val_accuracy: 0.2373 - val_binary_crossentropy: 0.0516\n",
      "Epoch 184/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.3122 - binary_crossentropy: 0.0111\n",
      "Epoch 184: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0111 - accuracy: 0.3120 - binary_crossentropy: 0.0111 - val_loss: 0.0540 - val_accuracy: 0.2117 - val_binary_crossentropy: 0.0540\n",
      "Epoch 185/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.3067 - binary_crossentropy: 0.0111\n",
      "Epoch 185: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0111 - accuracy: 0.3067 - binary_crossentropy: 0.0111 - val_loss: 0.0507 - val_accuracy: 0.3080 - val_binary_crossentropy: 0.0507\n",
      "Epoch 186/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.3058 - binary_crossentropy: 0.0109\n",
      "Epoch 186: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0109 - accuracy: 0.3058 - binary_crossentropy: 0.0109 - val_loss: 0.0494 - val_accuracy: 0.3249 - val_binary_crossentropy: 0.0494\n",
      "Epoch 187/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.3286 - binary_crossentropy: 0.0109\n",
      "Epoch 187: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0109 - accuracy: 0.3285 - binary_crossentropy: 0.0109 - val_loss: 0.0498 - val_accuracy: 0.3008 - val_binary_crossentropy: 0.0498\n",
      "Epoch 188/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.3153 - binary_crossentropy: 0.0111\n",
      "Epoch 188: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0111 - accuracy: 0.3153 - binary_crossentropy: 0.0111 - val_loss: 0.0512 - val_accuracy: 0.2679 - val_binary_crossentropy: 0.0512\n",
      "Epoch 189/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.3115 - binary_crossentropy: 0.0110\n",
      "Epoch 189: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0110 - accuracy: 0.3115 - binary_crossentropy: 0.0110 - val_loss: 0.0512 - val_accuracy: 0.3145 - val_binary_crossentropy: 0.0512\n",
      "Epoch 190/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.3137 - binary_crossentropy: 0.0110\n",
      "Epoch 190: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0110 - accuracy: 0.3137 - binary_crossentropy: 0.0110 - val_loss: 0.0494 - val_accuracy: 0.3130 - val_binary_crossentropy: 0.0494\n",
      "Epoch 191/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.3157 - binary_crossentropy: 0.0108\n",
      "Epoch 191: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0108 - accuracy: 0.3155 - binary_crossentropy: 0.0108 - val_loss: 0.0567 - val_accuracy: 0.2809 - val_binary_crossentropy: 0.0567\n",
      "Epoch 192/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.3082 - binary_crossentropy: 0.0110\n",
      "Epoch 192: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0110 - accuracy: 0.3082 - binary_crossentropy: 0.0110 - val_loss: 0.0525 - val_accuracy: 0.2925 - val_binary_crossentropy: 0.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.3061 - binary_crossentropy: 0.0107\n",
      "Epoch 193: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0107 - accuracy: 0.3061 - binary_crossentropy: 0.0107 - val_loss: 0.0518 - val_accuracy: 0.3761 - val_binary_crossentropy: 0.0518\n",
      "Epoch 194/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.3109 - binary_crossentropy: 0.0108\n",
      "Epoch 194: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0108 - accuracy: 0.3109 - binary_crossentropy: 0.0108 - val_loss: 0.0531 - val_accuracy: 0.2593 - val_binary_crossentropy: 0.0531\n",
      "Epoch 195/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.3208 - binary_crossentropy: 0.0111\n",
      "Epoch 195: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0111 - accuracy: 0.3208 - binary_crossentropy: 0.0111 - val_loss: 0.0539 - val_accuracy: 0.2834 - val_binary_crossentropy: 0.0539\n",
      "Epoch 196/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.3159 - binary_crossentropy: 0.0110\n",
      "Epoch 196: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0110 - accuracy: 0.3158 - binary_crossentropy: 0.0110 - val_loss: 0.0506 - val_accuracy: 0.3920 - val_binary_crossentropy: 0.0506\n",
      "Epoch 197/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.3163 - binary_crossentropy: 0.0110\n",
      "Epoch 197: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0110 - accuracy: 0.3163 - binary_crossentropy: 0.0110 - val_loss: 0.0482 - val_accuracy: 0.3087 - val_binary_crossentropy: 0.0482\n",
      "Epoch 198/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.3281 - binary_crossentropy: 0.0110\n",
      "Epoch 198: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0110 - accuracy: 0.3279 - binary_crossentropy: 0.0110 - val_loss: 0.0517 - val_accuracy: 0.2889 - val_binary_crossentropy: 0.0517\n",
      "Epoch 199/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.3115 - binary_crossentropy: 0.0108\n",
      "Epoch 199: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0108 - accuracy: 0.3115 - binary_crossentropy: 0.0108 - val_loss: 0.0520 - val_accuracy: 0.2863 - val_binary_crossentropy: 0.0520\n",
      "Epoch 200/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.3148 - binary_crossentropy: 0.0110\n",
      "Epoch 200: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0110 - accuracy: 0.3146 - binary_crossentropy: 0.0110 - val_loss: 0.0521 - val_accuracy: 0.3152 - val_binary_crossentropy: 0.0521\n",
      "Epoch 201/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.3263 - binary_crossentropy: 0.0109\n",
      "Epoch 201: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0109 - accuracy: 0.3263 - binary_crossentropy: 0.0109 - val_loss: 0.0520 - val_accuracy: 0.3790 - val_binary_crossentropy: 0.0520\n",
      "Epoch 202/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.3206 - binary_crossentropy: 0.0107\n",
      "Epoch 202: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0107 - accuracy: 0.3206 - binary_crossentropy: 0.0107 - val_loss: 0.0521 - val_accuracy: 0.3411 - val_binary_crossentropy: 0.0521\n",
      "Epoch 203/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.3300 - binary_crossentropy: 0.0110\n",
      "Epoch 203: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0110 - accuracy: 0.3300 - binary_crossentropy: 0.0110 - val_loss: 0.0531 - val_accuracy: 0.3350 - val_binary_crossentropy: 0.0531\n",
      "Epoch 204/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.3168 - binary_crossentropy: 0.0107\n",
      "Epoch 204: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0107 - accuracy: 0.3168 - binary_crossentropy: 0.0107 - val_loss: 0.0545 - val_accuracy: 0.3588 - val_binary_crossentropy: 0.0545\n",
      "Epoch 205/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.3255 - binary_crossentropy: 0.0107\n",
      "Epoch 205: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0107 - accuracy: 0.3255 - binary_crossentropy: 0.0107 - val_loss: 0.0526 - val_accuracy: 0.3321 - val_binary_crossentropy: 0.0526\n",
      "Epoch 206/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.3309 - binary_crossentropy: 0.0107\n",
      "Epoch 206: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0107 - accuracy: 0.3307 - binary_crossentropy: 0.0107 - val_loss: 0.0518 - val_accuracy: 0.3130 - val_binary_crossentropy: 0.0518\n",
      "Epoch 207/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.3212 - binary_crossentropy: 0.0107\n",
      "Epoch 207: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0107 - accuracy: 0.3210 - binary_crossentropy: 0.0107 - val_loss: 0.0524 - val_accuracy: 0.3794 - val_binary_crossentropy: 0.0524\n",
      "Epoch 208/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.3200 - binary_crossentropy: 0.0108\n",
      "Epoch 208: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0108 - accuracy: 0.3200 - binary_crossentropy: 0.0108 - val_loss: 0.0527 - val_accuracy: 0.3610 - val_binary_crossentropy: 0.0527\n",
      "Epoch 209/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.3363 - binary_crossentropy: 0.0106\n",
      "Epoch 209: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 38ms/step - loss: 0.0106 - accuracy: 0.3360 - binary_crossentropy: 0.0106 - val_loss: 0.0494 - val_accuracy: 0.3567 - val_binary_crossentropy: 0.0494\n",
      "Epoch 210/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.3270 - binary_crossentropy: 0.0106\n",
      "Epoch 210: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0106 - accuracy: 0.3268 - binary_crossentropy: 0.0106 - val_loss: 0.0502 - val_accuracy: 0.3509 - val_binary_crossentropy: 0.0502\n",
      "Epoch 211/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.3288 - binary_crossentropy: 0.0105\n",
      "Epoch 211: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 38ms/step - loss: 0.0105 - accuracy: 0.3288 - binary_crossentropy: 0.0105 - val_loss: 0.0520 - val_accuracy: 0.3556 - val_binary_crossentropy: 0.0520\n",
      "Epoch 212/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.3282 - binary_crossentropy: 0.0106\n",
      "Epoch 212: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0106 - accuracy: 0.3282 - binary_crossentropy: 0.0106 - val_loss: 0.0485 - val_accuracy: 0.3040 - val_binary_crossentropy: 0.0485\n",
      "Epoch 213/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.3214 - binary_crossentropy: 0.0103\n",
      "Epoch 213: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 30s 39ms/step - loss: 0.0103 - accuracy: 0.3214 - binary_crossentropy: 0.0103 - val_loss: 0.0492 - val_accuracy: 0.4504 - val_binary_crossentropy: 0.0492\n",
      "Epoch 214/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.3369 - binary_crossentropy: 0.0105\n",
      "Epoch 214: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 26s 33ms/step - loss: 0.0105 - accuracy: 0.3366 - binary_crossentropy: 0.0105 - val_loss: 0.0506 - val_accuracy: 0.3949 - val_binary_crossentropy: 0.0506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.3650 - binary_crossentropy: 0.0104\n",
      "Epoch 215: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 26s 33ms/step - loss: 0.0104 - accuracy: 0.3647 - binary_crossentropy: 0.0104 - val_loss: 0.0527 - val_accuracy: 0.3671 - val_binary_crossentropy: 0.0527\n",
      "Epoch 216/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.3585 - binary_crossentropy: 0.0108\n",
      "Epoch 216: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 34ms/step - loss: 0.0108 - accuracy: 0.3583 - binary_crossentropy: 0.0108 - val_loss: 0.0502 - val_accuracy: 0.3246 - val_binary_crossentropy: 0.0502\n",
      "Epoch 217/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.3187 - binary_crossentropy: 0.0110\n",
      "Epoch 217: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0110 - accuracy: 0.3185 - binary_crossentropy: 0.0110 - val_loss: 0.0511 - val_accuracy: 0.3109 - val_binary_crossentropy: 0.0511\n",
      "Epoch 218/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.3286 - binary_crossentropy: 0.0107\n",
      "Epoch 218: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 34ms/step - loss: 0.0107 - accuracy: 0.3286 - binary_crossentropy: 0.0107 - val_loss: 0.0522 - val_accuracy: 0.3040 - val_binary_crossentropy: 0.0522\n",
      "Epoch 219/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.3429 - binary_crossentropy: 0.0105\n",
      "Epoch 219: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0105 - accuracy: 0.3429 - binary_crossentropy: 0.0105 - val_loss: 0.0504 - val_accuracy: 0.2802 - val_binary_crossentropy: 0.0504\n",
      "Epoch 220/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.3320 - binary_crossentropy: 0.0104\n",
      "Epoch 220: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 31s 39ms/step - loss: 0.0104 - accuracy: 0.3320 - binary_crossentropy: 0.0104 - val_loss: 0.0515 - val_accuracy: 0.3213 - val_binary_crossentropy: 0.0515\n",
      "Epoch 221/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.3434 - binary_crossentropy: 0.0103\n",
      "Epoch 221: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 25s 33ms/step - loss: 0.0103 - accuracy: 0.3432 - binary_crossentropy: 0.0103 - val_loss: 0.0515 - val_accuracy: 0.3668 - val_binary_crossentropy: 0.0515\n",
      "Epoch 222/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.3340 - binary_crossentropy: 0.0105\n",
      "Epoch 222: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0105 - accuracy: 0.3338 - binary_crossentropy: 0.0105 - val_loss: 0.0494 - val_accuracy: 0.3166 - val_binary_crossentropy: 0.0494\n",
      "Epoch 223/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3602 - binary_crossentropy: 0.0102\n",
      "Epoch 223: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3600 - binary_crossentropy: 0.0102 - val_loss: 0.0523 - val_accuracy: 0.3700 - val_binary_crossentropy: 0.0523\n",
      "Epoch 224/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.3337 - binary_crossentropy: 0.0104\n",
      "Epoch 224: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0104 - accuracy: 0.3335 - binary_crossentropy: 0.0104 - val_loss: 0.0512 - val_accuracy: 0.3505 - val_binary_crossentropy: 0.0512\n",
      "Epoch 225/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.3531 - binary_crossentropy: 0.0104\n",
      "Epoch 225: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0104 - accuracy: 0.3529 - binary_crossentropy: 0.0104 - val_loss: 0.0530 - val_accuracy: 0.3588 - val_binary_crossentropy: 0.0530\n",
      "Epoch 226/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.3552 - binary_crossentropy: 0.0101\n",
      "Epoch 226: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3550 - binary_crossentropy: 0.0100 - val_loss: 0.0567 - val_accuracy: 0.3202 - val_binary_crossentropy: 0.0567\n",
      "Epoch 227/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.3460 - binary_crossentropy: 0.0102\n",
      "Epoch 227: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3460 - binary_crossentropy: 0.0102 - val_loss: 0.0522 - val_accuracy: 0.3559 - val_binary_crossentropy: 0.0522\n",
      "Epoch 228/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.3287 - binary_crossentropy: 0.0103\n",
      "Epoch 228: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3286 - binary_crossentropy: 0.0103 - val_loss: 0.0512 - val_accuracy: 0.3567 - val_binary_crossentropy: 0.0512\n",
      "Epoch 229/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.3413 - binary_crossentropy: 0.0103\n",
      "Epoch 229: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3413 - binary_crossentropy: 0.0103 - val_loss: 0.0513 - val_accuracy: 0.3599 - val_binary_crossentropy: 0.0513\n",
      "Epoch 230/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.3613 - binary_crossentropy: 0.0106\n",
      "Epoch 230: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0106 - accuracy: 0.3611 - binary_crossentropy: 0.0106 - val_loss: 0.0542 - val_accuracy: 0.3379 - val_binary_crossentropy: 0.0542\n",
      "Epoch 231/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3500 - binary_crossentropy: 0.0102\n",
      "Epoch 231: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3498 - binary_crossentropy: 0.0102 - val_loss: 0.0590 - val_accuracy: 0.3624 - val_binary_crossentropy: 0.0590\n",
      "Epoch 232/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3607 - binary_crossentropy: 0.0102\n",
      "Epoch 232: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3604 - binary_crossentropy: 0.0102 - val_loss: 0.0551 - val_accuracy: 0.3415 - val_binary_crossentropy: 0.0551\n",
      "Epoch 233/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3537 - binary_crossentropy: 0.0100\n",
      "Epoch 233: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3537 - binary_crossentropy: 0.0100 - val_loss: 0.0544 - val_accuracy: 0.3433 - val_binary_crossentropy: 0.0544\n",
      "Epoch 234/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.3544 - binary_crossentropy: 0.0101\n",
      "Epoch 234: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0101 - accuracy: 0.3542 - binary_crossentropy: 0.0101 - val_loss: 0.0521 - val_accuracy: 0.3033 - val_binary_crossentropy: 0.0521\n",
      "Epoch 235/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.3469 - binary_crossentropy: 0.0103\n",
      "Epoch 235: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3469 - binary_crossentropy: 0.0103 - val_loss: 0.0520 - val_accuracy: 0.3170 - val_binary_crossentropy: 0.0520\n",
      "Epoch 236/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3569 - binary_crossentropy: 0.0099\n",
      "Epoch 236: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 37ms/step - loss: 0.0099 - accuracy: 0.3567 - binary_crossentropy: 0.0099 - val_loss: 0.0496 - val_accuracy: 0.3758 - val_binary_crossentropy: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3770 - binary_crossentropy: 0.0100\n",
      "Epoch 237: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0100 - accuracy: 0.3768 - binary_crossentropy: 0.0100 - val_loss: 0.0558 - val_accuracy: 0.3260 - val_binary_crossentropy: 0.0558\n",
      "Epoch 238/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.3581 - binary_crossentropy: 0.0103\n",
      "Epoch 238: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3581 - binary_crossentropy: 0.0103 - val_loss: 0.0550 - val_accuracy: 0.2427 - val_binary_crossentropy: 0.0550\n",
      "Epoch 239/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.3585 - binary_crossentropy: 0.0104\n",
      "Epoch 239: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0104 - accuracy: 0.3583 - binary_crossentropy: 0.0104 - val_loss: 0.0550 - val_accuracy: 0.2921 - val_binary_crossentropy: 0.0550\n",
      "Epoch 240/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3592 - binary_crossentropy: 0.0102\n",
      "Epoch 240: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3590 - binary_crossentropy: 0.0102 - val_loss: 0.0521 - val_accuracy: 0.3422 - val_binary_crossentropy: 0.0521\n",
      "Epoch 241/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3626 - binary_crossentropy: 0.0100\n",
      "Epoch 241: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3626 - binary_crossentropy: 0.0100 - val_loss: 0.0556 - val_accuracy: 0.4104 - val_binary_crossentropy: 0.0556\n",
      "Epoch 242/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3795 - binary_crossentropy: 0.0100\n",
      "Epoch 242: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3793 - binary_crossentropy: 0.0100 - val_loss: 0.0477 - val_accuracy: 0.4519 - val_binary_crossentropy: 0.0477\n",
      "Epoch 243/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.3664 - binary_crossentropy: 0.0102\n",
      "Epoch 243: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3664 - binary_crossentropy: 0.0102 - val_loss: 0.0536 - val_accuracy: 0.3274 - val_binary_crossentropy: 0.0536\n",
      "Epoch 244/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.3764 - binary_crossentropy: 0.0103\n",
      "Epoch 244: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3762 - binary_crossentropy: 0.0103 - val_loss: 0.0515 - val_accuracy: 0.3689 - val_binary_crossentropy: 0.0515\n",
      "Epoch 245/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.3511 - binary_crossentropy: 0.0104\n",
      "Epoch 245: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0104 - accuracy: 0.3511 - binary_crossentropy: 0.0104 - val_loss: 0.0529 - val_accuracy: 0.3765 - val_binary_crossentropy: 0.0529\n",
      "Epoch 246/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.3621 - binary_crossentropy: 0.0101\n",
      "Epoch 246: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0101 - accuracy: 0.3620 - binary_crossentropy: 0.0101 - val_loss: 0.0516 - val_accuracy: 0.4180 - val_binary_crossentropy: 0.0516\n",
      "Epoch 247/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3604 - binary_crossentropy: 0.0102\n",
      "Epoch 247: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3602 - binary_crossentropy: 0.0102 - val_loss: 0.0540 - val_accuracy: 0.3794 - val_binary_crossentropy: 0.0540\n",
      "Epoch 248/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3651 - binary_crossentropy: 0.0100\n",
      "Epoch 248: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3648 - binary_crossentropy: 0.0100 - val_loss: 0.0504 - val_accuracy: 0.3700 - val_binary_crossentropy: 0.0504\n",
      "Epoch 249/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.3538 - binary_crossentropy: 0.0103\n",
      "Epoch 249: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3538 - binary_crossentropy: 0.0103 - val_loss: 0.0513 - val_accuracy: 0.3581 - val_binary_crossentropy: 0.0513\n",
      "Epoch 250/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.3746 - binary_crossentropy: 0.0102\n",
      "Epoch 250: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3746 - binary_crossentropy: 0.0102 - val_loss: 0.0518 - val_accuracy: 0.3383 - val_binary_crossentropy: 0.0518\n",
      "Epoch 251/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.3530 - binary_crossentropy: 0.0102\n",
      "Epoch 251: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0102 - accuracy: 0.3528 - binary_crossentropy: 0.0102 - val_loss: 0.0533 - val_accuracy: 0.2791 - val_binary_crossentropy: 0.0533\n",
      "Epoch 252/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3563 - binary_crossentropy: 0.0100\n",
      "Epoch 252: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3563 - binary_crossentropy: 0.0100 - val_loss: 0.0532 - val_accuracy: 0.3008 - val_binary_crossentropy: 0.0532\n",
      "Epoch 253/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.3347 - binary_crossentropy: 0.0101\n",
      "Epoch 253: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3344 - binary_crossentropy: 0.0100 - val_loss: 0.0552 - val_accuracy: 0.2362 - val_binary_crossentropy: 0.0552\n",
      "Epoch 254/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.3529 - binary_crossentropy: 0.0103\n",
      "Epoch 254: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0103 - accuracy: 0.3527 - binary_crossentropy: 0.0103 - val_loss: 0.0553 - val_accuracy: 0.2982 - val_binary_crossentropy: 0.0553\n",
      "Epoch 255/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.3420 - binary_crossentropy: 0.0098\n",
      "Epoch 255: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0098 - accuracy: 0.3420 - binary_crossentropy: 0.0098 - val_loss: 0.0553 - val_accuracy: 0.3314 - val_binary_crossentropy: 0.0553\n",
      "Epoch 256/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3615 - binary_crossentropy: 0.0100\n",
      "Epoch 256: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3615 - binary_crossentropy: 0.0100 - val_loss: 0.0538 - val_accuracy: 0.2881 - val_binary_crossentropy: 0.0538\n",
      "Epoch 257/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3683 - binary_crossentropy: 0.0100\n",
      "Epoch 257: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3683 - binary_crossentropy: 0.0100 - val_loss: 0.0532 - val_accuracy: 0.3065 - val_binary_crossentropy: 0.0532\n",
      "Epoch 258/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3691 - binary_crossentropy: 0.0099\n",
      "Epoch 258: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0099 - accuracy: 0.3688 - binary_crossentropy: 0.0099 - val_loss: 0.0545 - val_accuracy: 0.3008 - val_binary_crossentropy: 0.0545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.3453 - binary_crossentropy: 0.0101\n",
      "Epoch 259: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0101 - accuracy: 0.3453 - binary_crossentropy: 0.0101 - val_loss: 0.0543 - val_accuracy: 0.3307 - val_binary_crossentropy: 0.0543\n",
      "Epoch 260/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3373 - binary_crossentropy: 0.0100\n",
      "Epoch 260: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0100 - accuracy: 0.3370 - binary_crossentropy: 0.0100 - val_loss: 0.0535 - val_accuracy: 0.3639 - val_binary_crossentropy: 0.0535\n",
      "Epoch 261/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3509 - binary_crossentropy: 0.0099\n",
      "Epoch 261: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0099 - accuracy: 0.3507 - binary_crossentropy: 0.0099 - val_loss: 0.0549 - val_accuracy: 0.2806 - val_binary_crossentropy: 0.0549\n",
      "Epoch 262/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.3555 - binary_crossentropy: 0.0098\n",
      "Epoch 262: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0098 - accuracy: 0.3555 - binary_crossentropy: 0.0098 - val_loss: 0.0549 - val_accuracy: 0.3242 - val_binary_crossentropy: 0.0549\n",
      "Epoch 263/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.3507 - binary_crossentropy: 0.0097\n",
      "Epoch 263: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0097 - accuracy: 0.3507 - binary_crossentropy: 0.0097 - val_loss: 0.0566 - val_accuracy: 0.3069 - val_binary_crossentropy: 0.0566\n",
      "Epoch 264/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.3410 - binary_crossentropy: 0.0098\n",
      "Epoch 264: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0098 - accuracy: 0.3410 - binary_crossentropy: 0.0098 - val_loss: 0.0528 - val_accuracy: 0.3502 - val_binary_crossentropy: 0.0528\n",
      "Epoch 265/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.3581 - binary_crossentropy: 0.0099\n",
      "Epoch 265: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0099 - accuracy: 0.3581 - binary_crossentropy: 0.0099 - val_loss: 0.0558 - val_accuracy: 0.3137 - val_binary_crossentropy: 0.0558\n",
      "Epoch 266/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.3516 - binary_crossentropy: 0.0098\n",
      "Epoch 266: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0098 - accuracy: 0.3514 - binary_crossentropy: 0.0098 - val_loss: 0.0540 - val_accuracy: 0.3152 - val_binary_crossentropy: 0.0540\n",
      "Epoch 267/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.3525 - binary_crossentropy: 0.0101\n",
      "Epoch 267: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0101 - accuracy: 0.3523 - binary_crossentropy: 0.0101 - val_loss: 0.0578 - val_accuracy: 0.2495 - val_binary_crossentropy: 0.0578\n",
      "Epoch 268/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3490 - binary_crossentropy: 0.0100\n",
      "Epoch 268: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0100 - accuracy: 0.3489 - binary_crossentropy: 0.0100 - val_loss: 0.0554 - val_accuracy: 0.2990 - val_binary_crossentropy: 0.0554\n",
      "Epoch 269/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.3390 - binary_crossentropy: 0.0099\n",
      "Epoch 269: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0099 - accuracy: 0.3390 - binary_crossentropy: 0.0099 - val_loss: 0.0563 - val_accuracy: 0.3375 - val_binary_crossentropy: 0.0563\n",
      "Epoch 270/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3652 - binary_crossentropy: 0.0096\n",
      "Epoch 270: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0096 - accuracy: 0.3649 - binary_crossentropy: 0.0096 - val_loss: 0.0567 - val_accuracy: 0.3000 - val_binary_crossentropy: 0.0567\n",
      "Epoch 271/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.3726 - binary_crossentropy: 0.0094\n",
      "Epoch 271: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0094 - accuracy: 0.3724 - binary_crossentropy: 0.0094 - val_loss: 0.0525 - val_accuracy: 0.3307 - val_binary_crossentropy: 0.0525\n",
      "Epoch 272/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.3607 - binary_crossentropy: 0.0098\n",
      "Epoch 272: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0098 - accuracy: 0.3605 - binary_crossentropy: 0.0098 - val_loss: 0.0540 - val_accuracy: 0.2917 - val_binary_crossentropy: 0.0540\n",
      "Epoch 273/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.3653 - binary_crossentropy: 0.0096\n",
      "Epoch 273: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0096 - accuracy: 0.3653 - binary_crossentropy: 0.0096 - val_loss: 0.0535 - val_accuracy: 0.3761 - val_binary_crossentropy: 0.0535\n",
      "Epoch 274/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3549 - binary_crossentropy: 0.0099\n",
      "Epoch 274: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0099 - accuracy: 0.3547 - binary_crossentropy: 0.0099 - val_loss: 0.0551 - val_accuracy: 0.2773 - val_binary_crossentropy: 0.0551\n",
      "Epoch 275/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.3389 - binary_crossentropy: 0.0100\n",
      "Epoch 275: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 37ms/step - loss: 0.0100 - accuracy: 0.3387 - binary_crossentropy: 0.0100 - val_loss: 0.0603 - val_accuracy: 0.3267 - val_binary_crossentropy: 0.0603\n",
      "Epoch 276/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3561 - binary_crossentropy: 0.0099\n",
      "Epoch 276: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0099 - accuracy: 0.3559 - binary_crossentropy: 0.0099 - val_loss: 0.0531 - val_accuracy: 0.2697 - val_binary_crossentropy: 0.0531\n",
      "Epoch 277/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.3420 - binary_crossentropy: 0.0096\n",
      "Epoch 277: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0096 - accuracy: 0.3420 - binary_crossentropy: 0.0096 - val_loss: 0.0532 - val_accuracy: 0.2899 - val_binary_crossentropy: 0.0532\n",
      "Epoch 278/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.3503 - binary_crossentropy: 0.0097\n",
      "Epoch 278: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0097 - accuracy: 0.3502 - binary_crossentropy: 0.0097 - val_loss: 0.0534 - val_accuracy: 0.3094 - val_binary_crossentropy: 0.0534\n",
      "Epoch 279/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.3524 - binary_crossentropy: 0.0095\n",
      "Epoch 279: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 29s 37ms/step - loss: 0.0095 - accuracy: 0.3524 - binary_crossentropy: 0.0095 - val_loss: 0.0530 - val_accuracy: 0.3235 - val_binary_crossentropy: 0.0530\n",
      "Epoch 280/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.3393 - binary_crossentropy: 0.0094\n",
      "Epoch 280: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0094 - accuracy: 0.3393 - binary_crossentropy: 0.0094 - val_loss: 0.0556 - val_accuracy: 0.3891 - val_binary_crossentropy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.3568 - binary_crossentropy: 0.0099\n",
      "Epoch 281: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0099 - accuracy: 0.3565 - binary_crossentropy: 0.0099 - val_loss: 0.0575 - val_accuracy: 0.2413 - val_binary_crossentropy: 0.0575\n",
      "Epoch 282/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.3519 - binary_crossentropy: 0.0098\n",
      "Epoch 282: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0098 - accuracy: 0.3516 - binary_crossentropy: 0.0098 - val_loss: 0.0546 - val_accuracy: 0.2943 - val_binary_crossentropy: 0.0546\n",
      "Epoch 283/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.3684 - binary_crossentropy: 0.0097\n",
      "Epoch 283: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0097 - accuracy: 0.3681 - binary_crossentropy: 0.0097 - val_loss: 0.0541 - val_accuracy: 0.3069 - val_binary_crossentropy: 0.0541\n",
      "Epoch 284/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.3825 - binary_crossentropy: 0.0097\n",
      "Epoch 284: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0097 - accuracy: 0.3825 - binary_crossentropy: 0.0097 - val_loss: 0.0580 - val_accuracy: 0.3877 - val_binary_crossentropy: 0.0580\n",
      "Epoch 285/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3814 - binary_crossentropy: 0.0096\n",
      "Epoch 285: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0096 - accuracy: 0.3811 - binary_crossentropy: 0.0096 - val_loss: 0.0581 - val_accuracy: 0.3567 - val_binary_crossentropy: 0.0581\n",
      "Epoch 286/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.3704 - binary_crossentropy: 0.0098\n",
      "Epoch 286: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0098 - accuracy: 0.3702 - binary_crossentropy: 0.0098 - val_loss: 0.0569 - val_accuracy: 0.3191 - val_binary_crossentropy: 0.0569\n",
      "Epoch 287/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.3525 - binary_crossentropy: 0.0100\n",
      "Epoch 287: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 27s 35ms/step - loss: 0.0100 - accuracy: 0.3525 - binary_crossentropy: 0.0100 - val_loss: 0.0554 - val_accuracy: 0.2838 - val_binary_crossentropy: 0.0554\n",
      "Epoch 288/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.3674 - binary_crossentropy: 0.0097\n",
      "Epoch 288: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0097 - accuracy: 0.3671 - binary_crossentropy: 0.0097 - val_loss: 0.0524 - val_accuracy: 0.2770 - val_binary_crossentropy: 0.0524\n",
      "Epoch 289/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3480 - binary_crossentropy: 0.0096\n",
      "Epoch 289: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0095 - accuracy: 0.3478 - binary_crossentropy: 0.0095 - val_loss: 0.0548 - val_accuracy: 0.2687 - val_binary_crossentropy: 0.0548\n",
      "Epoch 290/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.3540 - binary_crossentropy: 0.0094\n",
      "Epoch 290: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0094 - accuracy: 0.3540 - binary_crossentropy: 0.0094 - val_loss: 0.0514 - val_accuracy: 0.3613 - val_binary_crossentropy: 0.0514\n",
      "Epoch 291/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.3674 - binary_crossentropy: 0.0098\n",
      "Epoch 291: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0098 - accuracy: 0.3672 - binary_crossentropy: 0.0098 - val_loss: 0.0524 - val_accuracy: 0.3469 - val_binary_crossentropy: 0.0524\n",
      "Epoch 292/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.3491 - binary_crossentropy: 0.0092\n",
      "Epoch 292: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0092 - accuracy: 0.3488 - binary_crossentropy: 0.0092 - val_loss: 0.0551 - val_accuracy: 0.2907 - val_binary_crossentropy: 0.0551\n",
      "Epoch 293/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3488 - binary_crossentropy: 0.0096\n",
      "Epoch 293: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0096 - accuracy: 0.3486 - binary_crossentropy: 0.0096 - val_loss: 0.0573 - val_accuracy: 0.2470 - val_binary_crossentropy: 0.0573\n",
      "Epoch 294/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3525 - binary_crossentropy: 0.0096\n",
      "Epoch 294: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0096 - accuracy: 0.3523 - binary_crossentropy: 0.0096 - val_loss: 0.0545 - val_accuracy: 0.3502 - val_binary_crossentropy: 0.0545\n",
      "Epoch 295/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.3651 - binary_crossentropy: 0.0096\n",
      "Epoch 295: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0096 - accuracy: 0.3649 - binary_crossentropy: 0.0096 - val_loss: 0.0549 - val_accuracy: 0.3300 - val_binary_crossentropy: 0.0549\n",
      "Epoch 296/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.3752 - binary_crossentropy: 0.0094\n",
      "Epoch 296: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0094 - accuracy: 0.3750 - binary_crossentropy: 0.0094 - val_loss: 0.0550 - val_accuracy: 0.3303 - val_binary_crossentropy: 0.0550\n",
      "Epoch 297/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.3435 - binary_crossentropy: 0.0093\n",
      "Epoch 297: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0093 - accuracy: 0.3435 - binary_crossentropy: 0.0093 - val_loss: 0.0532 - val_accuracy: 0.2625 - val_binary_crossentropy: 0.0532\n",
      "Epoch 298/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.3638 - binary_crossentropy: 0.0093\n",
      "Epoch 298: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0093 - accuracy: 0.3636 - binary_crossentropy: 0.0093 - val_loss: 0.0578 - val_accuracy: 0.2254 - val_binary_crossentropy: 0.0578\n",
      "Epoch 299/300\n",
      "779/780 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.3558 - binary_crossentropy: 0.0091\n",
      "Epoch 299: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 35ms/step - loss: 0.0091 - accuracy: 0.3556 - binary_crossentropy: 0.0091 - val_loss: 0.0554 - val_accuracy: 0.2510 - val_binary_crossentropy: 0.0554\n",
      "Epoch 300/300\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.3594 - binary_crossentropy: 0.0096\n",
      "Epoch 300: val_loss did not improve from 0.03996\n",
      "780/780 [==============================] - 28s 36ms/step - loss: 0.0096 - accuracy: 0.3594 - binary_crossentropy: 0.0096 - val_loss: 0.0586 - val_accuracy: 0.2607 - val_binary_crossentropy: 0.0586\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "\n",
    "# very very very basic LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(sequence_len, input_shape=(sequence_len, len(instruments)), return_sequences=True, dropout=dropout))\n",
    "model.add(LSTM(sequence_len, return_sequences=True, dropout=dropout))\n",
    "model.add(LSTM(sequence_len, dropout=dropout))\n",
    "model.add(Dense(output_shape, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.BinaryCrossentropy()])\n",
    "model.summary()\n",
    "mc = ModelCheckpoint(filepath='./new_encode_1st_try.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(inputs_list, outputs_list, epochs=300, callbacks=mc, validation_split=0.1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f44b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['binary_crossentropy'])\n",
    "plt.plot(history.history['val_binary_crossentropy'])\n",
    "plt.title('Model binary crossetropy')\n",
    "plt.ylabel('Binary crossetropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['binary_crossentropy', 'val_binary_crossentropy'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad68ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_list = []\n",
    "test_out = []\n",
    "raw_notes = test.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    test2_list.append(raw_notes[input_start:input_end])\n",
    "    test_out.append(raw_notes[output_start:output_end])\n",
    "\n",
    "test_out = list(np.array(test_out).reshape(-1, np.array(test_out).shape[-1]))\n",
    "\n",
    "test2_list = np.array(test2_list)\n",
    "test_out = np.array(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fced35b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11864, 32, 21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test2_list\n",
    "test2_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae63fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict new notes\n",
    "prediction = model.predict(test2_list[:], verbose=0)\n",
    "# round prediction to 1 or 0\n",
    "prediction = np.around(prediction)\n",
    "# retype it to int\n",
    "prediction = prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68aeada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f04fe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = 120\n",
    "file_name = \"./output/rhcp_final.mid\"\n",
    "create_midi(bpm, prediction, mid.ticks_per_beat, file_name, instruments)\n",
    "# create_midi(bpm, transcription.values, mid.ticks_per_beat, \"./output/transcription.mid\", instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72778f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_metric_complete_lines(candidate, reference):\n",
    "    correct_lines = 0\n",
    "    for i,c in enumerate(candidate):\n",
    "        # line of candidate is the same as reference\n",
    "        if (c == reference[i]).all() == True:\n",
    "            correct_lines += 1\n",
    "    \n",
    "    # probability of correct lines\n",
    "    return correct_lines/len(reference)\n",
    "\n",
    "def bleu_metric_ngrams(candidate, reference, ngram):\n",
    "    correct_ngrams = 0\n",
    "    offset = 0\n",
    "    true_flag = True\n",
    "    \n",
    "    for i,c in enumerate(candidate):\n",
    "        \n",
    "#         print(candidate[i+offset], reference[i+offset], (candidate[i+offset] == reference[i+offset]).all())\n",
    "        # line is correct\n",
    "        if (candidate[i] == reference[i]).all() == True:\n",
    "            pass\n",
    "        else:\n",
    "            true_flag = False\n",
    "\n",
    "        # every ngram sequence\n",
    "        if (i+1)%ngram == 0:\n",
    "#             print(i, true_flag)\n",
    "            # all sequence is correct\n",
    "            if true_flag:\n",
    "                correct_ngrams += 1\n",
    "            true_flag = True\n",
    "    \n",
    "    allngrams = len(reference)/ngram\n",
    "#     print(correct_ngrams, allngrams)\n",
    "    # probability of correct lines\n",
    "    return correct_ngrams/allngrams\n",
    "\n",
    "def bleu_metric_single_notes(candidate, reference, length_of_line):\n",
    "    correct_lines = 0\n",
    "    probabilities = []\n",
    "    for i,c in enumerate(candidate):\n",
    "        # how many notes are correct in single line\n",
    "        tmp = ((c == reference[i]) == True).sum()\n",
    "        # probability of correct notes in single line\n",
    "        probabilities.append(tmp/length_of_line)\n",
    "    \n",
    "    # geometric mean of probabilities\n",
    "    return gmean(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "172358c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "candidate = prediction.copy()\n",
    "reference = test_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "087f0ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03632838840188807"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_complete_lines(candidate, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46166ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.812266989051192"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_single_notes(candidate, reference, length_of_line=len(instruments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "088a6f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03236682400539447"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_ngrams(candidate, reference, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d12a4c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9487.66513299942\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadda286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

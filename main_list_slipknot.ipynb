{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa32159f",
   "metadata": {},
   "source": [
    "# Hudba a neurónové siete\n",
    "## Bakárska práca\n",
    "### Peter Oliver Kolek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d922943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack, MetaMessage, bpm2tempo, Message\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from scipy.stats import gmean\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b128547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_content(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    return f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775690a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_midi(midi_file):\n",
    "    # open midi file\n",
    "    mid = MidiFile(midi_file, clip=True)\n",
    "\n",
    "    drum_track_number = 0\n",
    "    # find track number of drums\n",
    "    for i in range(len(mid.tracks)):\n",
    "        for j in range(len(mid.tracks[i])):\n",
    "            if mid.tracks[i][j].is_meta:\n",
    "                continue\n",
    "            if mid.tracks[i][j].channel == 9:\n",
    "                drum_track_number = i\n",
    "                break\n",
    "    print(\"Drum track number: \", str(drum_track_number))\n",
    "    return mid, mid.tracks[drum_track_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbacaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcription(drum_track, mid):\n",
    "    # find ticks per beat, and divide it to Thirty-Second 32 notes\n",
    "    ticks_per_beat_in_32_notes = mid.ticks_per_beat / 8\n",
    "#     print(ticks_per_beat_in_32_notes)\n",
    "    # change notes time to stick it to 32 notes\n",
    "    tmp_time = 0\n",
    "    time_with_note = {}\n",
    "    for i, message in enumerate(drum_track):\n",
    "        # find time how it goes through song\n",
    "        tmp_time += drum_track[i].time\n",
    "        message.time = round(tmp_time / ticks_per_beat_in_32_notes)\n",
    "#         print(\"i: \", i, \"msg time: \", message.time, \"tmp time: \", tmp_time, \"Msg_type: \", message.type)\n",
    "        # make velocity of notes same\n",
    "        if message.type == 'note_on':\n",
    "            if message.velocity > 0:\n",
    "                message.velocity = 1\n",
    "\n",
    "    # crating DataFrame for notes sticked to 32s and filter only note_on notes\n",
    "    transcription = pd.DataFrame(m.dict() for m in drum_track)\n",
    "    transcription = transcription[transcription.type == 'note_on']\n",
    "    # modify table to have columns for every note and lines with time (32 notes as they folow the song)\n",
    "    transcription = transcription.pivot_table(index='time', columns='note', values='velocity', fill_value=0)\n",
    "    # because we have 4/4 tempo, we have to add notes to have folowing 32 notes and empty values we fill with zeros\n",
    "    transcription = transcription.reindex(pd.RangeIndex(transcription.index.max() + 1)).fillna(0).sort_index()\n",
    "    # retype to int\n",
    "    transcription = transcription.astype(int)\n",
    "    transcription.columns = transcription.columns.astype(int)\n",
    "    transcription = transcription.reset_index(drop=True)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797eeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(tempo, transcription, ticks_per_beat, file_name, instruments):\n",
    "    # create new midi file\n",
    "    new_mid = MidiFile()\n",
    "    new_mid.ticks_per_beat = ticks_per_beat\n",
    "    meta_track = MidiTrack()\n",
    "    new_mid.tracks.append(meta_track)\n",
    "\n",
    "    # necessary meta track\n",
    "    meta_track.append(MetaMessage(type='track_name', name='meta_track', time=0))\n",
    "    meta_track.append(MetaMessage(type='time_signature', numerator=4, denominator=4, clocks_per_click=24,\n",
    "                                  notated_32nd_notes_per_beat=8, time=0))\n",
    "    meta_track.append(MetaMessage(type='set_tempo', tempo=bpm2tempo(tempo), time=0))\n",
    "\n",
    "    drum_track_new = MidiTrack()\n",
    "    new_mid.tracks.append(drum_track_new)\n",
    "\n",
    "    # apend notes to drum track\n",
    "\n",
    "    ticks_per_32note = int(ticks_per_beat/8)\n",
    "    notes_from_last_message = 0\n",
    "    for i, note in enumerate(transcription):\n",
    "        if i == 0:\n",
    "            for idx, inst in enumerate(note):\n",
    "                if inst == 0:\n",
    "                    continue\n",
    "                drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80, time=0))\n",
    "            continue\n",
    "        else:\n",
    "            if sum(note) < 1:\n",
    "                notes_from_last_message += 1\n",
    "                continue\n",
    "            else:\n",
    "                notes_from_last_message += 1\n",
    "\n",
    "            same_note_count = 0\n",
    "            for idx, inst in enumerate(note):\n",
    "                if inst == 0:\n",
    "                    pass\n",
    "                # if there are more notes at the same time played, they must have time 0\n",
    "                elif same_note_count == 0:\n",
    "                    drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80,\n",
    "                                                  time=notes_from_last_message * ticks_per_32note))\n",
    "                    same_note_count += 1\n",
    "                else:\n",
    "                    drum_track_new.append(Message('note_on', channel=9, note=instruments[idx], velocity=80, time=0))\n",
    "                    same_note_count += 1\n",
    "            notes_from_last_message = 0\n",
    "#     print(new_mid)\n",
    "    new_mid.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7bd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ba59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BeforeIForget.midi', 'Eyeless.midi', 'TheNameless.midi', 'Disasterpiece.midi', 'People=Shit.midi', 'WaitAndBleed.midi', 'Duality.midi', 'Sic.midi', 'Eeyore.midi', 'Surfacing.midi']\n"
     ]
    }
   ],
   "source": [
    "slipknot_list = get_list_of_content('./Slipknot_midi/list.txt')\n",
    "print(slipknot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drum track number:  7\n",
      "Drum track number:  3\n",
      "Drum track number:  5\n",
      "Drum track number:  3\n",
      "Drum track number:  6\n",
      "Drum track number:  1\n",
      "Drum track number:  4\n",
      "Drum track number:  4\n",
      "Drum track number:  5\n",
      "Drum track number:  6\n",
      "note   35  38  40  41  43  45  46  47  49  57  ...  37  42  44  48  51  55  \\\n",
      "0       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "1       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "2       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "3       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "45218   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "45219   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "45220   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "45221   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "45222   0   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "\n",
      "note   50  0   52  53  \n",
      "0       0   0   0   0  \n",
      "1       0   0   0   0  \n",
      "2       0   0   0   0  \n",
      "3       0   0   0   0  \n",
      "4       0   0   0   0  \n",
      "...    ..  ..  ..  ..  \n",
      "45218   0   0   0   0  \n",
      "45219   0   0   0   0  \n",
      "45220   0   0   0   0  \n",
      "45221   0   0   0   0  \n",
      "45222   0   0   0   0  \n",
      "\n",
      "[45223 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "slipknot_transcription_full = pd.DataFrame()\n",
    "frames = []\n",
    "for item in slipknot_list:\n",
    "    mid, drum_track = open_midi('./Slipknot_midi/' + item)\n",
    "    transcription = get_transcription(drum_track, mid)\n",
    "    frames.append(transcription)\n",
    "    instruments = transcription.columns.tolist()\n",
    "\n",
    "\n",
    "instruments = slipknot_transcription_full.columns.tolist()\n",
    "slipknot_transcription_full = pd.concat(frames)\n",
    "slipknot_transcription_full = slipknot_transcription_full.fillna(0)\n",
    "slipknot_transcription_full = slipknot_transcription_full.astype(int)\n",
    "slipknot_transcription_full = slipknot_transcription_full.reset_index(drop=True)\n",
    "\n",
    "instruments = slipknot_transcription_full.columns.tolist()\n",
    "\n",
    "create_midi(120, slipknot_transcription_full.values, mid.ticks_per_beat, \"./output/transcription_full_slipknot.mid\", instruments)\n",
    "\n",
    "print(slipknot_transcription_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7dd284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split = int(slipknot_transcription_full.shape[0]*0.7)\n",
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6978f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = slipknot_transcription_full.loc[:train_test_split]\n",
    "test = slipknot_transcription_full.loc[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f55c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = []\n",
    "outputs_list = []\n",
    "sequence_len = 32\n",
    "raw_notes = train.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    inputs_list.append(raw_notes[input_start:input_end])\n",
    "    outputs_list.append(raw_notes[output_start:output_end])\n",
    "\n",
    "outputs_list = list(np.array(outputs_list).reshape(-1, np.array(outputs_list).shape[-1]))\n",
    "\n",
    "inputs_list = np.array(inputs_list)\n",
    "outputs_list = np.array(outputs_list)\n",
    "\n",
    "output_shape = outputs_list.shape[1]\n",
    "\n",
    "test_list = []\n",
    "test_out = []\n",
    "raw_notes = test.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    test_list.append(raw_notes[input_start:input_end])\n",
    "    test_out.append(raw_notes[output_start:output_end])\n",
    "\n",
    "test_out = list(np.array(test_out).reshape(-1, np.array(test_out).shape[-1]))\n",
    "\n",
    "test_list = np.array(test_list)\n",
    "test_out = np.array(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb251a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:03:25.595269: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32, 32)            7040      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32, 32)            8320      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 22)                726       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,406\n",
      "Trainable params: 24,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.2168 - binary_crossentropy: 0.0966\n",
      "Epoch 1: val_loss improved from inf to 0.07208, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 49s 49ms/step - loss: 0.0966 - accuracy: 0.2167 - binary_crossentropy: 0.0966 - val_loss: 0.0721 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0721\n",
      "Epoch 2/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.2870 - binary_crossentropy: 0.0676\n",
      "Epoch 2: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 40s 45ms/step - loss: 0.0676 - accuracy: 0.2869 - binary_crossentropy: 0.0676 - val_loss: 0.0727 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0727\n",
      "Epoch 3/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.2791 - binary_crossentropy: 0.0658\n",
      "Epoch 3: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0658 - accuracy: 0.2790 - binary_crossentropy: 0.0658 - val_loss: 0.0733 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0733\n",
      "Epoch 4/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.2874 - binary_crossentropy: 0.0661\n",
      "Epoch 4: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0661 - accuracy: 0.2874 - binary_crossentropy: 0.0661 - val_loss: 0.0728 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0728\n",
      "Epoch 5/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.2869 - binary_crossentropy: 0.0674\n",
      "Epoch 5: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0674 - accuracy: 0.2869 - binary_crossentropy: 0.0674 - val_loss: 0.0723 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0723\n",
      "Epoch 6/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.2732 - binary_crossentropy: 0.0673\n",
      "Epoch 6: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 36s 41ms/step - loss: 0.0673 - accuracy: 0.2732 - binary_crossentropy: 0.0673 - val_loss: 0.0724 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0724\n",
      "Epoch 7/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.2702 - binary_crossentropy: 0.0672\n",
      "Epoch 7: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0672 - accuracy: 0.2702 - binary_crossentropy: 0.0672 - val_loss: 0.0724 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0724\n",
      "Epoch 8/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.2777 - binary_crossentropy: 0.0672\n",
      "Epoch 8: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 41s 46ms/step - loss: 0.0671 - accuracy: 0.2776 - binary_crossentropy: 0.0671 - val_loss: 0.0727 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0727\n",
      "Epoch 9/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.2827 - binary_crossentropy: 0.0672\n",
      "Epoch 9: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0672 - accuracy: 0.2827 - binary_crossentropy: 0.0672 - val_loss: 0.0728 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0728\n",
      "Epoch 10/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.2798 - binary_crossentropy: 0.0671\n",
      "Epoch 10: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 38s 42ms/step - loss: 0.0671 - accuracy: 0.2798 - binary_crossentropy: 0.0671 - val_loss: 0.0729 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0729\n",
      "Epoch 11/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.2815 - binary_crossentropy: 0.0671\n",
      "Epoch 11: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0671 - accuracy: 0.2814 - binary_crossentropy: 0.0671 - val_loss: 0.0727 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0727\n",
      "Epoch 12/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.2871 - binary_crossentropy: 0.0671\n",
      "Epoch 12: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0671 - accuracy: 0.2870 - binary_crossentropy: 0.0671 - val_loss: 0.0729 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0729\n",
      "Epoch 13/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.2909 - binary_crossentropy: 0.0671\n",
      "Epoch 13: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0671 - accuracy: 0.2908 - binary_crossentropy: 0.0671 - val_loss: 0.0728 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0728\n",
      "Epoch 14/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.2919 - binary_crossentropy: 0.0671\n",
      "Epoch 14: val_loss did not improve from 0.07208\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0671 - accuracy: 0.2919 - binary_crossentropy: 0.0671 - val_loss: 0.0728 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0728\n",
      "Epoch 15/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.2915 - binary_crossentropy: 0.0664\n",
      "Epoch 15: val_loss improved from 0.07208 to 0.06501, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0664 - accuracy: 0.2915 - binary_crossentropy: 0.0664 - val_loss: 0.0650 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0650\n",
      "Epoch 16/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.3179 - binary_crossentropy: 0.0578\n",
      "Epoch 16: val_loss improved from 0.06501 to 0.06225, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0578 - accuracy: 0.3179 - binary_crossentropy: 0.0578 - val_loss: 0.0622 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0622\n",
      "Epoch 17/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.3654 - binary_crossentropy: 0.0568\n",
      "Epoch 17: val_loss did not improve from 0.06225\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0568 - accuracy: 0.3654 - binary_crossentropy: 0.0568 - val_loss: 0.0637 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0637\n",
      "Epoch 18/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.3327 - binary_crossentropy: 0.0577\n",
      "Epoch 18: val_loss did not improve from 0.06225\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0577 - accuracy: 0.3327 - binary_crossentropy: 0.0577 - val_loss: 0.0626 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0626\n",
      "Epoch 19/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.2944 - binary_crossentropy: 0.0581\n",
      "Epoch 19: val_loss improved from 0.06225 to 0.06158, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0581 - accuracy: 0.2944 - binary_crossentropy: 0.0581 - val_loss: 0.0616 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.2841 - binary_crossentropy: 0.0579\n",
      "Epoch 20: val_loss improved from 0.06158 to 0.06111, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0579 - accuracy: 0.2841 - binary_crossentropy: 0.0579 - val_loss: 0.0611 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0611\n",
      "Epoch 21/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.3516 - binary_crossentropy: 0.0584\n",
      "Epoch 21: val_loss improved from 0.06111 to 0.06096, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0584 - accuracy: 0.3516 - binary_crossentropy: 0.0584 - val_loss: 0.0610 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0610\n",
      "Epoch 22/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.3429 - binary_crossentropy: 0.0587\n",
      "Epoch 22: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0587 - accuracy: 0.3429 - binary_crossentropy: 0.0587 - val_loss: 0.0612 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0612\n",
      "Epoch 23/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.3204 - binary_crossentropy: 0.0595\n",
      "Epoch 23: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0595 - accuracy: 0.3204 - binary_crossentropy: 0.0595 - val_loss: 0.0618 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0618\n",
      "Epoch 24/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.3052 - binary_crossentropy: 0.0593\n",
      "Epoch 24: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0593 - accuracy: 0.3052 - binary_crossentropy: 0.0593 - val_loss: 0.0617 - val_accuracy: 0.0686 - val_binary_crossentropy: 0.0617\n",
      "Epoch 25/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.3178 - binary_crossentropy: 0.0609\n",
      "Epoch 25: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0609 - accuracy: 0.3178 - binary_crossentropy: 0.0609 - val_loss: 0.0612 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0612\n",
      "Epoch 26/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.3361 - binary_crossentropy: 0.0609\n",
      "Epoch 26: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0609 - accuracy: 0.3362 - binary_crossentropy: 0.0609 - val_loss: 0.0615 - val_accuracy: 0.6001 - val_binary_crossentropy: 0.0615\n",
      "Epoch 27/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.3821 - binary_crossentropy: 0.0624\n",
      "Epoch 27: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0624 - accuracy: 0.3821 - binary_crossentropy: 0.0624 - val_loss: 0.0652 - val_accuracy: 0.5005 - val_binary_crossentropy: 0.0652\n",
      "Epoch 28/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.3721 - binary_crossentropy: 0.0634\n",
      "Epoch 28: val_loss did not improve from 0.06096\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0634 - accuracy: 0.3721 - binary_crossentropy: 0.0634 - val_loss: 0.0624 - val_accuracy: 0.5138 - val_binary_crossentropy: 0.0624\n",
      "Epoch 29/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.3472 - binary_crossentropy: 0.0575\n",
      "Epoch 29: val_loss improved from 0.06096 to 0.06039, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0575 - accuracy: 0.3472 - binary_crossentropy: 0.0575 - val_loss: 0.0604 - val_accuracy: 0.0746 - val_binary_crossentropy: 0.0604\n",
      "Epoch 30/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.2544 - binary_crossentropy: 0.0568\n",
      "Epoch 30: val_loss improved from 0.06039 to 0.06016, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0567 - accuracy: 0.2543 - binary_crossentropy: 0.0567 - val_loss: 0.0602 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0602\n",
      "Epoch 31/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.2092 - binary_crossentropy: 0.0567\n",
      "Epoch 31: val_loss improved from 0.06016 to 0.06008, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0567 - accuracy: 0.2092 - binary_crossentropy: 0.0567 - val_loss: 0.0601 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0601\n",
      "Epoch 32/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.1795 - binary_crossentropy: 0.0565\n",
      "Epoch 32: val_loss did not improve from 0.06008\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0565 - accuracy: 0.1795 - binary_crossentropy: 0.0565 - val_loss: 0.0619 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0619\n",
      "Epoch 33/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.2006 - binary_crossentropy: 0.0563\n",
      "Epoch 33: val_loss did not improve from 0.06008\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0562 - accuracy: 0.2006 - binary_crossentropy: 0.0562 - val_loss: 0.0604 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0604\n",
      "Epoch 34/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.1758 - binary_crossentropy: 0.0573\n",
      "Epoch 34: val_loss did not improve from 0.06008\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0573 - accuracy: 0.1757 - binary_crossentropy: 0.0573 - val_loss: 0.0610 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0610\n",
      "Epoch 35/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.1906 - binary_crossentropy: 0.0560\n",
      "Epoch 35: val_loss improved from 0.06008 to 0.05693, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0560 - accuracy: 0.1905 - binary_crossentropy: 0.0560 - val_loss: 0.0569 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0569\n",
      "Epoch 36/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.1989 - binary_crossentropy: 0.0526\n",
      "Epoch 36: val_loss improved from 0.05693 to 0.05621, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0526 - accuracy: 0.1989 - binary_crossentropy: 0.0526 - val_loss: 0.0562 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0562\n",
      "Epoch 37/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.2292 - binary_crossentropy: 0.0508\n",
      "Epoch 37: val_loss improved from 0.05621 to 0.05587, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0508 - accuracy: 0.2291 - binary_crossentropy: 0.0508 - val_loss: 0.0559 - val_accuracy: 0.0831 - val_binary_crossentropy: 0.0559\n",
      "Epoch 38/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.2524 - binary_crossentropy: 0.0496\n",
      "Epoch 38: val_loss did not improve from 0.05587\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0496 - accuracy: 0.2524 - binary_crossentropy: 0.0496 - val_loss: 0.0570 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0570\n",
      "Epoch 39/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.2131 - binary_crossentropy: 0.0487\n",
      "Epoch 39: val_loss did not improve from 0.05587\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0487 - accuracy: 0.2131 - binary_crossentropy: 0.0487 - val_loss: 0.0564 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0564\n",
      "Epoch 40/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.2448 - binary_crossentropy: 0.0483\n",
      "Epoch 40: val_loss did not improve from 0.05587\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0483 - accuracy: 0.2448 - binary_crossentropy: 0.0483 - val_loss: 0.0564 - val_accuracy: 0.0974 - val_binary_crossentropy: 0.0564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.2407 - binary_crossentropy: 0.0473\n",
      "Epoch 41: val_loss improved from 0.05587 to 0.05527, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0473 - accuracy: 0.2406 - binary_crossentropy: 0.0473 - val_loss: 0.0553 - val_accuracy: 0.0980 - val_binary_crossentropy: 0.0553\n",
      "Epoch 42/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.2163 - binary_crossentropy: 0.0462\n",
      "Epoch 42: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0462 - accuracy: 0.2163 - binary_crossentropy: 0.0462 - val_loss: 0.0556 - val_accuracy: 0.1043 - val_binary_crossentropy: 0.0556\n",
      "Epoch 43/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.2183 - binary_crossentropy: 0.0454\n",
      "Epoch 43: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0454 - accuracy: 0.2183 - binary_crossentropy: 0.0454 - val_loss: 0.0557 - val_accuracy: 0.1742 - val_binary_crossentropy: 0.0557\n",
      "Epoch 44/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.2249 - binary_crossentropy: 0.0451\n",
      "Epoch 44: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0451 - accuracy: 0.2249 - binary_crossentropy: 0.0451 - val_loss: 0.0563 - val_accuracy: 0.1729 - val_binary_crossentropy: 0.0563\n",
      "Epoch 45/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.2275 - binary_crossentropy: 0.0445\n",
      "Epoch 45: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0445 - accuracy: 0.2274 - binary_crossentropy: 0.0445 - val_loss: 0.0568 - val_accuracy: 0.1581 - val_binary_crossentropy: 0.0568\n",
      "Epoch 46/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.2334 - binary_crossentropy: 0.0443\n",
      "Epoch 46: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0443 - accuracy: 0.2334 - binary_crossentropy: 0.0443 - val_loss: 0.0561 - val_accuracy: 0.1625 - val_binary_crossentropy: 0.0561\n",
      "Epoch 47/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.2337 - binary_crossentropy: 0.0435\n",
      "Epoch 47: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0435 - accuracy: 0.2336 - binary_crossentropy: 0.0435 - val_loss: 0.0568 - val_accuracy: 0.1584 - val_binary_crossentropy: 0.0568\n",
      "Epoch 48/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.2391 - binary_crossentropy: 0.0431\n",
      "Epoch 48: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0431 - accuracy: 0.2390 - binary_crossentropy: 0.0431 - val_loss: 0.0570 - val_accuracy: 0.1641 - val_binary_crossentropy: 0.0570\n",
      "Epoch 49/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.2234 - binary_crossentropy: 0.0429\n",
      "Epoch 49: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0429 - accuracy: 0.2234 - binary_crossentropy: 0.0429 - val_loss: 0.0567 - val_accuracy: 0.1660 - val_binary_crossentropy: 0.0567\n",
      "Epoch 50/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.2830 - binary_crossentropy: 0.0425\n",
      "Epoch 50: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0425 - accuracy: 0.2829 - binary_crossentropy: 0.0425 - val_loss: 0.0571 - val_accuracy: 0.1296 - val_binary_crossentropy: 0.0571\n",
      "Epoch 51/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.2599 - binary_crossentropy: 0.0420\n",
      "Epoch 51: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0420 - accuracy: 0.2599 - binary_crossentropy: 0.0420 - val_loss: 0.0566 - val_accuracy: 0.2197 - val_binary_crossentropy: 0.0566\n",
      "Epoch 52/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.2719 - binary_crossentropy: 0.0412\n",
      "Epoch 52: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0412 - accuracy: 0.2719 - binary_crossentropy: 0.0412 - val_loss: 0.0567 - val_accuracy: 0.1227 - val_binary_crossentropy: 0.0567\n",
      "Epoch 53/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.2445 - binary_crossentropy: 0.0409\n",
      "Epoch 53: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0409 - accuracy: 0.2445 - binary_crossentropy: 0.0409 - val_loss: 0.0567 - val_accuracy: 0.1369 - val_binary_crossentropy: 0.0567\n",
      "Epoch 54/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.2269 - binary_crossentropy: 0.0408\n",
      "Epoch 54: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0408 - accuracy: 0.2269 - binary_crossentropy: 0.0408 - val_loss: 0.0562 - val_accuracy: 0.1173 - val_binary_crossentropy: 0.0562\n",
      "Epoch 55/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.2097 - binary_crossentropy: 0.0399\n",
      "Epoch 55: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0399 - accuracy: 0.2096 - binary_crossentropy: 0.0399 - val_loss: 0.0564 - val_accuracy: 0.1331 - val_binary_crossentropy: 0.0564\n",
      "Epoch 56/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.2424 - binary_crossentropy: 0.0400\n",
      "Epoch 56: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0400 - accuracy: 0.2424 - binary_crossentropy: 0.0400 - val_loss: 0.0563 - val_accuracy: 0.1201 - val_binary_crossentropy: 0.0563\n",
      "Epoch 57/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.2083 - binary_crossentropy: 0.0394\n",
      "Epoch 57: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0394 - accuracy: 0.2082 - binary_crossentropy: 0.0394 - val_loss: 0.0570 - val_accuracy: 0.0844 - val_binary_crossentropy: 0.0570\n",
      "Epoch 58/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.2118 - binary_crossentropy: 0.0385\n",
      "Epoch 58: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0385 - accuracy: 0.2118 - binary_crossentropy: 0.0385 - val_loss: 0.0578 - val_accuracy: 0.1148 - val_binary_crossentropy: 0.0578\n",
      "Epoch 59/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.2285 - binary_crossentropy: 0.0379\n",
      "Epoch 59: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 35s 40ms/step - loss: 0.0379 - accuracy: 0.2284 - binary_crossentropy: 0.0379 - val_loss: 0.0578 - val_accuracy: 0.1679 - val_binary_crossentropy: 0.0578\n",
      "Epoch 60/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.2560 - binary_crossentropy: 0.0373\n",
      "Epoch 60: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0373 - accuracy: 0.2560 - binary_crossentropy: 0.0373 - val_loss: 0.0588 - val_accuracy: 0.2150 - val_binary_crossentropy: 0.0588\n",
      "Epoch 61/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.2105 - binary_crossentropy: 0.0446\n",
      "Epoch 61: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0446 - accuracy: 0.2105 - binary_crossentropy: 0.0446 - val_loss: 0.0573 - val_accuracy: 0.0768 - val_binary_crossentropy: 0.0573\n",
      "Epoch 62/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.2418 - binary_crossentropy: 0.0418\n",
      "Epoch 62: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0418 - accuracy: 0.2417 - binary_crossentropy: 0.0418 - val_loss: 0.0624 - val_accuracy: 0.1723 - val_binary_crossentropy: 0.0624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.2130 - binary_crossentropy: 0.0413\n",
      "Epoch 63: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0413 - accuracy: 0.2130 - binary_crossentropy: 0.0413 - val_loss: 0.0574 - val_accuracy: 0.0809 - val_binary_crossentropy: 0.0574\n",
      "Epoch 64/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.2565 - binary_crossentropy: 0.0407\n",
      "Epoch 64: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0407 - accuracy: 0.2564 - binary_crossentropy: 0.0407 - val_loss: 0.0556 - val_accuracy: 0.0771 - val_binary_crossentropy: 0.0556\n",
      "Epoch 65/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.2188 - binary_crossentropy: 0.0412\n",
      "Epoch 65: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0412 - accuracy: 0.2188 - binary_crossentropy: 0.0412 - val_loss: 0.0577 - val_accuracy: 0.0964 - val_binary_crossentropy: 0.0577\n",
      "Epoch 66/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.2444 - binary_crossentropy: 0.0386\n",
      "Epoch 66: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0386 - accuracy: 0.2444 - binary_crossentropy: 0.0386 - val_loss: 0.0576 - val_accuracy: 0.2302 - val_binary_crossentropy: 0.0576\n",
      "Epoch 67/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.2732 - binary_crossentropy: 0.0370\n",
      "Epoch 67: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0370 - accuracy: 0.2732 - binary_crossentropy: 0.0370 - val_loss: 0.0581 - val_accuracy: 0.1985 - val_binary_crossentropy: 0.0581\n",
      "Epoch 68/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.2527 - binary_crossentropy: 0.0387\n",
      "Epoch 68: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0387 - accuracy: 0.2527 - binary_crossentropy: 0.0387 - val_loss: 0.0554 - val_accuracy: 0.1015 - val_binary_crossentropy: 0.0554\n",
      "Epoch 69/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.2359 - binary_crossentropy: 0.0395\n",
      "Epoch 69: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0395 - accuracy: 0.2359 - binary_crossentropy: 0.0395 - val_loss: 0.0589 - val_accuracy: 0.1748 - val_binary_crossentropy: 0.0589\n",
      "Epoch 70/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.2070 - binary_crossentropy: 0.0390\n",
      "Epoch 70: val_loss did not improve from 0.05527\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0390 - accuracy: 0.2069 - binary_crossentropy: 0.0390 - val_loss: 0.0571 - val_accuracy: 0.0781 - val_binary_crossentropy: 0.0571\n",
      "Epoch 71/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.1793 - binary_crossentropy: 0.0401\n",
      "Epoch 71: val_loss improved from 0.05527 to 0.05513, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0401 - accuracy: 0.1793 - binary_crossentropy: 0.0401 - val_loss: 0.0551 - val_accuracy: 0.0828 - val_binary_crossentropy: 0.0551\n",
      "Epoch 72/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.1866 - binary_crossentropy: 0.0397\n",
      "Epoch 72: val_loss improved from 0.05513 to 0.05421, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0397 - accuracy: 0.1866 - binary_crossentropy: 0.0397 - val_loss: 0.0542 - val_accuracy: 0.0857 - val_binary_crossentropy: 0.0542\n",
      "Epoch 73/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.1831 - binary_crossentropy: 0.0391\n",
      "Epoch 73: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0391 - accuracy: 0.1831 - binary_crossentropy: 0.0391 - val_loss: 0.0544 - val_accuracy: 0.0850 - val_binary_crossentropy: 0.0544\n",
      "Epoch 74/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.2025 - binary_crossentropy: 0.0387\n",
      "Epoch 74: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0387 - accuracy: 0.2025 - binary_crossentropy: 0.0387 - val_loss: 0.0569 - val_accuracy: 0.1056 - val_binary_crossentropy: 0.0569\n",
      "Epoch 75/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.2029 - binary_crossentropy: 0.0377\n",
      "Epoch 75: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0377 - accuracy: 0.2028 - binary_crossentropy: 0.0377 - val_loss: 0.0554 - val_accuracy: 0.1770 - val_binary_crossentropy: 0.0554\n",
      "Epoch 76/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.1972 - binary_crossentropy: 0.0368\n",
      "Epoch 76: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0367 - accuracy: 0.1971 - binary_crossentropy: 0.0367 - val_loss: 0.0550 - val_accuracy: 0.1679 - val_binary_crossentropy: 0.0550\n",
      "Epoch 77/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.1959 - binary_crossentropy: 0.0368\n",
      "Epoch 77: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0368 - accuracy: 0.1959 - binary_crossentropy: 0.0368 - val_loss: 0.0554 - val_accuracy: 0.1827 - val_binary_crossentropy: 0.0554\n",
      "Epoch 78/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.2103 - binary_crossentropy: 0.0362\n",
      "Epoch 78: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0362 - accuracy: 0.2103 - binary_crossentropy: 0.0362 - val_loss: 0.0555 - val_accuracy: 0.1894 - val_binary_crossentropy: 0.0555\n",
      "Epoch 79/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.2105 - binary_crossentropy: 0.0356\n",
      "Epoch 79: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0356 - accuracy: 0.2105 - binary_crossentropy: 0.0356 - val_loss: 0.0573 - val_accuracy: 0.1764 - val_binary_crossentropy: 0.0573\n",
      "Epoch 80/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.2121 - binary_crossentropy: 0.0350\n",
      "Epoch 80: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0350 - accuracy: 0.2121 - binary_crossentropy: 0.0350 - val_loss: 0.0588 - val_accuracy: 0.1903 - val_binary_crossentropy: 0.0588\n",
      "Epoch 81/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.2166 - binary_crossentropy: 0.0344\n",
      "Epoch 81: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0344 - accuracy: 0.2165 - binary_crossentropy: 0.0344 - val_loss: 0.0590 - val_accuracy: 0.1840 - val_binary_crossentropy: 0.0590\n",
      "Epoch 82/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.2195 - binary_crossentropy: 0.0340\n",
      "Epoch 82: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0340 - accuracy: 0.2195 - binary_crossentropy: 0.0340 - val_loss: 0.0559 - val_accuracy: 0.1929 - val_binary_crossentropy: 0.0559\n",
      "Epoch 83/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.2528 - binary_crossentropy: 0.0334\n",
      "Epoch 83: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0334 - accuracy: 0.2528 - binary_crossentropy: 0.0334 - val_loss: 0.0566 - val_accuracy: 0.2008 - val_binary_crossentropy: 0.0566\n",
      "Epoch 84/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.2371 - binary_crossentropy: 0.0331\n",
      "Epoch 84: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0331 - accuracy: 0.2371 - binary_crossentropy: 0.0331 - val_loss: 0.0592 - val_accuracy: 0.1827 - val_binary_crossentropy: 0.0592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.2440 - binary_crossentropy: 0.0325\n",
      "Epoch 85: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0325 - accuracy: 0.2440 - binary_crossentropy: 0.0325 - val_loss: 0.0579 - val_accuracy: 0.1897 - val_binary_crossentropy: 0.0579\n",
      "Epoch 86/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.2444 - binary_crossentropy: 0.0323\n",
      "Epoch 86: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0323 - accuracy: 0.2444 - binary_crossentropy: 0.0323 - val_loss: 0.0586 - val_accuracy: 0.1805 - val_binary_crossentropy: 0.0586\n",
      "Epoch 87/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.2513 - binary_crossentropy: 0.0319\n",
      "Epoch 87: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0319 - accuracy: 0.2513 - binary_crossentropy: 0.0319 - val_loss: 0.0563 - val_accuracy: 0.1875 - val_binary_crossentropy: 0.0563\n",
      "Epoch 88/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.2448 - binary_crossentropy: 0.0316\n",
      "Epoch 88: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0316 - accuracy: 0.2448 - binary_crossentropy: 0.0316 - val_loss: 0.0580 - val_accuracy: 0.1824 - val_binary_crossentropy: 0.0580\n",
      "Epoch 89/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.2686 - binary_crossentropy: 0.0311\n",
      "Epoch 89: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0311 - accuracy: 0.2686 - binary_crossentropy: 0.0311 - val_loss: 0.0588 - val_accuracy: 0.1815 - val_binary_crossentropy: 0.0588\n",
      "Epoch 90/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.2575 - binary_crossentropy: 0.0310\n",
      "Epoch 90: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0310 - accuracy: 0.2574 - binary_crossentropy: 0.0310 - val_loss: 0.0600 - val_accuracy: 0.0939 - val_binary_crossentropy: 0.0600\n",
      "Epoch 91/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.2644 - binary_crossentropy: 0.0310\n",
      "Epoch 91: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0310 - accuracy: 0.2644 - binary_crossentropy: 0.0310 - val_loss: 0.0586 - val_accuracy: 0.1957 - val_binary_crossentropy: 0.0586\n",
      "Epoch 92/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.2710 - binary_crossentropy: 0.0305\n",
      "Epoch 92: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0305 - accuracy: 0.2710 - binary_crossentropy: 0.0305 - val_loss: 0.0580 - val_accuracy: 0.1812 - val_binary_crossentropy: 0.0580\n",
      "Epoch 93/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.2853 - binary_crossentropy: 0.0298\n",
      "Epoch 93: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0298 - accuracy: 0.2853 - binary_crossentropy: 0.0298 - val_loss: 0.0573 - val_accuracy: 0.0980 - val_binary_crossentropy: 0.0573\n",
      "Epoch 94/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.2888 - binary_crossentropy: 0.0295\n",
      "Epoch 94: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0295 - accuracy: 0.2888 - binary_crossentropy: 0.0295 - val_loss: 0.0581 - val_accuracy: 0.0974 - val_binary_crossentropy: 0.0581\n",
      "Epoch 95/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.2638 - binary_crossentropy: 0.0295\n",
      "Epoch 95: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0295 - accuracy: 0.2638 - binary_crossentropy: 0.0295 - val_loss: 0.0569 - val_accuracy: 0.1982 - val_binary_crossentropy: 0.0569\n",
      "Epoch 96/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.2787 - binary_crossentropy: 0.0291\n",
      "Epoch 96: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0291 - accuracy: 0.2787 - binary_crossentropy: 0.0291 - val_loss: 0.0561 - val_accuracy: 0.1948 - val_binary_crossentropy: 0.0561\n",
      "Epoch 97/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.2855 - binary_crossentropy: 0.0289\n",
      "Epoch 97: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0289 - accuracy: 0.2855 - binary_crossentropy: 0.0289 - val_loss: 0.0564 - val_accuracy: 0.1113 - val_binary_crossentropy: 0.0564\n",
      "Epoch 98/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.2938 - binary_crossentropy: 0.0288\n",
      "Epoch 98: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0288 - accuracy: 0.2938 - binary_crossentropy: 0.0288 - val_loss: 0.0563 - val_accuracy: 0.1929 - val_binary_crossentropy: 0.0563\n",
      "Epoch 99/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.3004 - binary_crossentropy: 0.0284\n",
      "Epoch 99: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0284 - accuracy: 0.3003 - binary_crossentropy: 0.0284 - val_loss: 0.0558 - val_accuracy: 0.1116 - val_binary_crossentropy: 0.0558\n",
      "Epoch 100/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.2743 - binary_crossentropy: 0.0283\n",
      "Epoch 100: val_loss did not improve from 0.05421\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0283 - accuracy: 0.2742 - binary_crossentropy: 0.0283 - val_loss: 0.0546 - val_accuracy: 0.1088 - val_binary_crossentropy: 0.0546\n",
      "Epoch 101/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.2636 - binary_crossentropy: 0.0288\n",
      "Epoch 101: val_loss improved from 0.05421 to 0.05375, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0288 - accuracy: 0.2636 - binary_crossentropy: 0.0288 - val_loss: 0.0538 - val_accuracy: 0.1053 - val_binary_crossentropy: 0.0538\n",
      "Epoch 102/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.2577 - binary_crossentropy: 0.0279\n",
      "Epoch 102: val_loss did not improve from 0.05375\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0279 - accuracy: 0.2577 - binary_crossentropy: 0.0279 - val_loss: 0.0548 - val_accuracy: 0.1135 - val_binary_crossentropy: 0.0548\n",
      "Epoch 103/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.2901 - binary_crossentropy: 0.0280\n",
      "Epoch 103: val_loss improved from 0.05375 to 0.05300, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0280 - accuracy: 0.2901 - binary_crossentropy: 0.0280 - val_loss: 0.0530 - val_accuracy: 0.1075 - val_binary_crossentropy: 0.0530\n",
      "Epoch 104/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.2884 - binary_crossentropy: 0.0275\n",
      "Epoch 104: val_loss did not improve from 0.05300\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0275 - accuracy: 0.2883 - binary_crossentropy: 0.0275 - val_loss: 0.0533 - val_accuracy: 0.1056 - val_binary_crossentropy: 0.0533\n",
      "Epoch 105/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.2828 - binary_crossentropy: 0.0276\n",
      "Epoch 105: val_loss did not improve from 0.05300\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0276 - accuracy: 0.2827 - binary_crossentropy: 0.0276 - val_loss: 0.0531 - val_accuracy: 0.1119 - val_binary_crossentropy: 0.0531\n",
      "Epoch 106/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.2762 - binary_crossentropy: 0.0277\n",
      "Epoch 106: val_loss did not improve from 0.05300\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0277 - accuracy: 0.2762 - binary_crossentropy: 0.0277 - val_loss: 0.0532 - val_accuracy: 0.1024 - val_binary_crossentropy: 0.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.2972 - binary_crossentropy: 0.0272\n",
      "Epoch 107: val_loss improved from 0.05300 to 0.05205, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0272 - accuracy: 0.2972 - binary_crossentropy: 0.0272 - val_loss: 0.0521 - val_accuracy: 0.1113 - val_binary_crossentropy: 0.0521\n",
      "Epoch 108/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.2725 - binary_crossentropy: 0.0272\n",
      "Epoch 108: val_loss did not improve from 0.05205\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0272 - accuracy: 0.2725 - binary_crossentropy: 0.0272 - val_loss: 0.0527 - val_accuracy: 0.1116 - val_binary_crossentropy: 0.0527\n",
      "Epoch 109/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.2705 - binary_crossentropy: 0.0273\n",
      "Epoch 109: val_loss improved from 0.05205 to 0.05140, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0273 - accuracy: 0.2705 - binary_crossentropy: 0.0273 - val_loss: 0.0514 - val_accuracy: 0.1252 - val_binary_crossentropy: 0.0514\n",
      "Epoch 110/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.2731 - binary_crossentropy: 0.0272\n",
      "Epoch 110: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0272 - accuracy: 0.2731 - binary_crossentropy: 0.0272 - val_loss: 0.0522 - val_accuracy: 0.1170 - val_binary_crossentropy: 0.0522\n",
      "Epoch 111/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.2905 - binary_crossentropy: 0.0269\n",
      "Epoch 111: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0269 - accuracy: 0.2905 - binary_crossentropy: 0.0269 - val_loss: 0.0522 - val_accuracy: 0.1151 - val_binary_crossentropy: 0.0522\n",
      "Epoch 112/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.2686 - binary_crossentropy: 0.0266\n",
      "Epoch 112: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0266 - accuracy: 0.2685 - binary_crossentropy: 0.0266 - val_loss: 0.0521 - val_accuracy: 0.1094 - val_binary_crossentropy: 0.0521\n",
      "Epoch 113/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.2798 - binary_crossentropy: 0.0262\n",
      "Epoch 113: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0262 - accuracy: 0.2798 - binary_crossentropy: 0.0262 - val_loss: 0.0533 - val_accuracy: 0.1069 - val_binary_crossentropy: 0.0533\n",
      "Epoch 114/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.2678 - binary_crossentropy: 0.0263\n",
      "Epoch 114: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0263 - accuracy: 0.2677 - binary_crossentropy: 0.0263 - val_loss: 0.0532 - val_accuracy: 0.1034 - val_binary_crossentropy: 0.0532\n",
      "Epoch 115/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.2542 - binary_crossentropy: 0.0259\n",
      "Epoch 115: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0259 - accuracy: 0.2542 - binary_crossentropy: 0.0259 - val_loss: 0.0517 - val_accuracy: 0.1205 - val_binary_crossentropy: 0.0517\n",
      "Epoch 116/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.2787 - binary_crossentropy: 0.0262\n",
      "Epoch 116: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0262 - accuracy: 0.2787 - binary_crossentropy: 0.0262 - val_loss: 0.0519 - val_accuracy: 0.1246 - val_binary_crossentropy: 0.0519\n",
      "Epoch 117/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.2813 - binary_crossentropy: 0.0264\n",
      "Epoch 117: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0264 - accuracy: 0.2813 - binary_crossentropy: 0.0264 - val_loss: 0.0586 - val_accuracy: 0.0926 - val_binary_crossentropy: 0.0586\n",
      "Epoch 118/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.2804 - binary_crossentropy: 0.0264\n",
      "Epoch 118: val_loss did not improve from 0.05140\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0264 - accuracy: 0.2804 - binary_crossentropy: 0.0264 - val_loss: 0.0537 - val_accuracy: 0.1157 - val_binary_crossentropy: 0.0537\n",
      "Epoch 119/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.2680 - binary_crossentropy: 0.0259\n",
      "Epoch 119: val_loss improved from 0.05140 to 0.05091, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0259 - accuracy: 0.2680 - binary_crossentropy: 0.0259 - val_loss: 0.0509 - val_accuracy: 0.1163 - val_binary_crossentropy: 0.0509\n",
      "Epoch 120/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.2759 - binary_crossentropy: 0.0257\n",
      "Epoch 120: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0257 - accuracy: 0.2759 - binary_crossentropy: 0.0257 - val_loss: 0.0514 - val_accuracy: 0.1075 - val_binary_crossentropy: 0.0514\n",
      "Epoch 121/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.2631 - binary_crossentropy: 0.0253\n",
      "Epoch 121: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0253 - accuracy: 0.2631 - binary_crossentropy: 0.0253 - val_loss: 0.0537 - val_accuracy: 0.1069 - val_binary_crossentropy: 0.0537\n",
      "Epoch 122/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.2546 - binary_crossentropy: 0.0254\n",
      "Epoch 122: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0254 - accuracy: 0.2546 - binary_crossentropy: 0.0254 - val_loss: 0.0539 - val_accuracy: 0.1976 - val_binary_crossentropy: 0.0539\n",
      "Epoch 123/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.2964 - binary_crossentropy: 0.0254\n",
      "Epoch 123: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0254 - accuracy: 0.2964 - binary_crossentropy: 0.0254 - val_loss: 0.0522 - val_accuracy: 0.2175 - val_binary_crossentropy: 0.0522\n",
      "Epoch 124/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.2723 - binary_crossentropy: 0.0250\n",
      "Epoch 124: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0250 - accuracy: 0.2722 - binary_crossentropy: 0.0250 - val_loss: 0.0517 - val_accuracy: 0.2109 - val_binary_crossentropy: 0.0517\n",
      "Epoch 125/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.2762 - binary_crossentropy: 0.0251\n",
      "Epoch 125: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0251 - accuracy: 0.2762 - binary_crossentropy: 0.0251 - val_loss: 0.0543 - val_accuracy: 0.1154 - val_binary_crossentropy: 0.0543\n",
      "Epoch 126/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.2572 - binary_crossentropy: 0.0255\n",
      "Epoch 126: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0254 - accuracy: 0.2572 - binary_crossentropy: 0.0254 - val_loss: 0.0535 - val_accuracy: 0.1268 - val_binary_crossentropy: 0.0535\n",
      "Epoch 127/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.2831 - binary_crossentropy: 0.0249\n",
      "Epoch 127: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0250 - accuracy: 0.2830 - binary_crossentropy: 0.0250 - val_loss: 0.0528 - val_accuracy: 0.1170 - val_binary_crossentropy: 0.0528\n",
      "Epoch 128/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.2939 - binary_crossentropy: 0.0247\n",
      "Epoch 128: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0247 - accuracy: 0.2938 - binary_crossentropy: 0.0247 - val_loss: 0.0533 - val_accuracy: 0.1141 - val_binary_crossentropy: 0.0533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.2764 - binary_crossentropy: 0.0245\n",
      "Epoch 129: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0245 - accuracy: 0.2764 - binary_crossentropy: 0.0245 - val_loss: 0.0524 - val_accuracy: 0.2071 - val_binary_crossentropy: 0.0524\n",
      "Epoch 130/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.2940 - binary_crossentropy: 0.0250\n",
      "Epoch 130: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0250 - accuracy: 0.2940 - binary_crossentropy: 0.0250 - val_loss: 0.0514 - val_accuracy: 0.1211 - val_binary_crossentropy: 0.0514\n",
      "Epoch 131/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.2711 - binary_crossentropy: 0.0244\n",
      "Epoch 131: val_loss did not improve from 0.05091\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0244 - accuracy: 0.2711 - binary_crossentropy: 0.0244 - val_loss: 0.0525 - val_accuracy: 0.1211 - val_binary_crossentropy: 0.0525\n",
      "Epoch 132/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.2748 - binary_crossentropy: 0.0245\n",
      "Epoch 132: val_loss improved from 0.05091 to 0.04959, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0245 - accuracy: 0.2747 - binary_crossentropy: 0.0245 - val_loss: 0.0496 - val_accuracy: 0.1306 - val_binary_crossentropy: 0.0496\n",
      "Epoch 133/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.2624 - binary_crossentropy: 0.0243\n",
      "Epoch 133: val_loss did not improve from 0.04959\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0243 - accuracy: 0.2624 - binary_crossentropy: 0.0243 - val_loss: 0.0505 - val_accuracy: 0.2128 - val_binary_crossentropy: 0.0505\n",
      "Epoch 134/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.2897 - binary_crossentropy: 0.0244\n",
      "Epoch 134: val_loss did not improve from 0.04959\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0244 - accuracy: 0.2896 - binary_crossentropy: 0.0244 - val_loss: 0.0502 - val_accuracy: 0.1236 - val_binary_crossentropy: 0.0502\n",
      "Epoch 135/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.2896 - binary_crossentropy: 0.0238\n",
      "Epoch 135: val_loss did not improve from 0.04959\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0238 - accuracy: 0.2896 - binary_crossentropy: 0.0238 - val_loss: 0.0496 - val_accuracy: 0.1375 - val_binary_crossentropy: 0.0496\n",
      "Epoch 136/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.2842 - binary_crossentropy: 0.0241\n",
      "Epoch 136: val_loss improved from 0.04959 to 0.04939, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0241 - accuracy: 0.2842 - binary_crossentropy: 0.0241 - val_loss: 0.0494 - val_accuracy: 0.1258 - val_binary_crossentropy: 0.0494\n",
      "Epoch 137/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.2776 - binary_crossentropy: 0.0241\n",
      "Epoch 137: val_loss did not improve from 0.04939\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0241 - accuracy: 0.2776 - binary_crossentropy: 0.0241 - val_loss: 0.0497 - val_accuracy: 0.2216 - val_binary_crossentropy: 0.0497\n",
      "Epoch 138/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.2806 - binary_crossentropy: 0.0240\n",
      "Epoch 138: val_loss improved from 0.04939 to 0.04853, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0240 - accuracy: 0.2806 - binary_crossentropy: 0.0240 - val_loss: 0.0485 - val_accuracy: 0.2194 - val_binary_crossentropy: 0.0485\n",
      "Epoch 139/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.2777 - binary_crossentropy: 0.0239\n",
      "Epoch 139: val_loss did not improve from 0.04853\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0239 - accuracy: 0.2777 - binary_crossentropy: 0.0239 - val_loss: 0.0496 - val_accuracy: 0.1280 - val_binary_crossentropy: 0.0496\n",
      "Epoch 140/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.3011 - binary_crossentropy: 0.0240\n",
      "Epoch 140: val_loss did not improve from 0.04853\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0240 - accuracy: 0.3011 - binary_crossentropy: 0.0240 - val_loss: 0.0496 - val_accuracy: 0.2185 - val_binary_crossentropy: 0.0496\n",
      "Epoch 141/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.2879 - binary_crossentropy: 0.0238\n",
      "Epoch 141: val_loss did not improve from 0.04853\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0238 - accuracy: 0.2879 - binary_crossentropy: 0.0238 - val_loss: 0.0500 - val_accuracy: 0.2213 - val_binary_crossentropy: 0.0500\n",
      "Epoch 142/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.2687 - binary_crossentropy: 0.0233\n",
      "Epoch 142: val_loss improved from 0.04853 to 0.04827, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 36s 40ms/step - loss: 0.0233 - accuracy: 0.2687 - binary_crossentropy: 0.0233 - val_loss: 0.0483 - val_accuracy: 0.2207 - val_binary_crossentropy: 0.0483\n",
      "Epoch 143/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.2809 - binary_crossentropy: 0.0233\n",
      "Epoch 143: val_loss did not improve from 0.04827\n",
      "890/890 [==============================] - 34s 39ms/step - loss: 0.0233 - accuracy: 0.2808 - binary_crossentropy: 0.0233 - val_loss: 0.0490 - val_accuracy: 0.2194 - val_binary_crossentropy: 0.0490\n",
      "Epoch 144/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.2893 - binary_crossentropy: 0.0240\n",
      "Epoch 144: val_loss did not improve from 0.04827\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0240 - accuracy: 0.2893 - binary_crossentropy: 0.0240 - val_loss: 0.0499 - val_accuracy: 0.2033 - val_binary_crossentropy: 0.0499\n",
      "Epoch 145/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.2770 - binary_crossentropy: 0.0236\n",
      "Epoch 145: val_loss improved from 0.04827 to 0.04773, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0236 - accuracy: 0.2770 - binary_crossentropy: 0.0236 - val_loss: 0.0477 - val_accuracy: 0.2194 - val_binary_crossentropy: 0.0477\n",
      "Epoch 146/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.2953 - binary_crossentropy: 0.0232\n",
      "Epoch 146: val_loss did not improve from 0.04773\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0232 - accuracy: 0.2952 - binary_crossentropy: 0.0232 - val_loss: 0.0483 - val_accuracy: 0.1410 - val_binary_crossentropy: 0.0483\n",
      "Epoch 147/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.2810 - binary_crossentropy: 0.0233\n",
      "Epoch 147: val_loss did not improve from 0.04773\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0233 - accuracy: 0.2810 - binary_crossentropy: 0.0233 - val_loss: 0.0489 - val_accuracy: 0.2447 - val_binary_crossentropy: 0.0489\n",
      "Epoch 148/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.2940 - binary_crossentropy: 0.0233\n",
      "Epoch 148: val_loss improved from 0.04773 to 0.04656, saving model to ./new_encode_1st_try.h5\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0233 - accuracy: 0.2940 - binary_crossentropy: 0.0233 - val_loss: 0.0466 - val_accuracy: 0.2273 - val_binary_crossentropy: 0.0466\n",
      "Epoch 149/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.2802 - binary_crossentropy: 0.0231\n",
      "Epoch 149: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0231 - accuracy: 0.2802 - binary_crossentropy: 0.0231 - val_loss: 0.0476 - val_accuracy: 0.2286 - val_binary_crossentropy: 0.0476\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/890 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.2865 - binary_crossentropy: 0.0231\n",
      "Epoch 150: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0231 - accuracy: 0.2865 - binary_crossentropy: 0.0231 - val_loss: 0.0482 - val_accuracy: 0.2232 - val_binary_crossentropy: 0.0482\n",
      "Epoch 151/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.2949 - binary_crossentropy: 0.0228\n",
      "Epoch 151: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0228 - accuracy: 0.2948 - binary_crossentropy: 0.0228 - val_loss: 0.0481 - val_accuracy: 0.1426 - val_binary_crossentropy: 0.0481\n",
      "Epoch 152/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.2861 - binary_crossentropy: 0.0228\n",
      "Epoch 152: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0228 - accuracy: 0.2860 - binary_crossentropy: 0.0228 - val_loss: 0.0490 - val_accuracy: 0.2261 - val_binary_crossentropy: 0.0490\n",
      "Epoch 153/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.2758 - binary_crossentropy: 0.0226\n",
      "Epoch 153: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0226 - accuracy: 0.2757 - binary_crossentropy: 0.0226 - val_loss: 0.0480 - val_accuracy: 0.2254 - val_binary_crossentropy: 0.0480\n",
      "Epoch 154/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.2927 - binary_crossentropy: 0.0227\n",
      "Epoch 154: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0227 - accuracy: 0.2926 - binary_crossentropy: 0.0227 - val_loss: 0.0467 - val_accuracy: 0.2245 - val_binary_crossentropy: 0.0467\n",
      "Epoch 155/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.2955 - binary_crossentropy: 0.0224\n",
      "Epoch 155: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0224 - accuracy: 0.2954 - binary_crossentropy: 0.0224 - val_loss: 0.0485 - val_accuracy: 0.1420 - val_binary_crossentropy: 0.0485\n",
      "Epoch 156/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.2941 - binary_crossentropy: 0.0224\n",
      "Epoch 156: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0224 - accuracy: 0.2940 - binary_crossentropy: 0.0224 - val_loss: 0.0470 - val_accuracy: 0.1423 - val_binary_crossentropy: 0.0470\n",
      "Epoch 157/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.3025 - binary_crossentropy: 0.0224\n",
      "Epoch 157: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0224 - accuracy: 0.3025 - binary_crossentropy: 0.0224 - val_loss: 0.0476 - val_accuracy: 0.1378 - val_binary_crossentropy: 0.0476\n",
      "Epoch 158/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.2995 - binary_crossentropy: 0.0224\n",
      "Epoch 158: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0224 - accuracy: 0.2994 - binary_crossentropy: 0.0224 - val_loss: 0.0482 - val_accuracy: 0.1420 - val_binary_crossentropy: 0.0482\n",
      "Epoch 159/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.3182 - binary_crossentropy: 0.0222\n",
      "Epoch 159: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0222 - accuracy: 0.3181 - binary_crossentropy: 0.0222 - val_loss: 0.0482 - val_accuracy: 0.1353 - val_binary_crossentropy: 0.0482\n",
      "Epoch 160/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.3234 - binary_crossentropy: 0.0222\n",
      "Epoch 160: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0222 - accuracy: 0.3233 - binary_crossentropy: 0.0222 - val_loss: 0.0473 - val_accuracy: 0.2267 - val_binary_crossentropy: 0.0473\n",
      "Epoch 161/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.3266 - binary_crossentropy: 0.0224\n",
      "Epoch 161: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0224 - accuracy: 0.3265 - binary_crossentropy: 0.0224 - val_loss: 0.0479 - val_accuracy: 0.2194 - val_binary_crossentropy: 0.0479\n",
      "Epoch 162/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.2975 - binary_crossentropy: 0.0218\n",
      "Epoch 162: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0218 - accuracy: 0.2974 - binary_crossentropy: 0.0218 - val_loss: 0.0478 - val_accuracy: 0.1337 - val_binary_crossentropy: 0.0478\n",
      "Epoch 163/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.3097 - binary_crossentropy: 0.0217\n",
      "Epoch 163: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0217 - accuracy: 0.3097 - binary_crossentropy: 0.0217 - val_loss: 0.0474 - val_accuracy: 0.1457 - val_binary_crossentropy: 0.0474\n",
      "Epoch 164/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.3149 - binary_crossentropy: 0.0219\n",
      "Epoch 164: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0219 - accuracy: 0.3148 - binary_crossentropy: 0.0219 - val_loss: 0.0479 - val_accuracy: 0.2292 - val_binary_crossentropy: 0.0479\n",
      "Epoch 165/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.3254 - binary_crossentropy: 0.0220\n",
      "Epoch 165: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0220 - accuracy: 0.3254 - binary_crossentropy: 0.0220 - val_loss: 0.0483 - val_accuracy: 0.2279 - val_binary_crossentropy: 0.0483\n",
      "Epoch 166/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.2973 - binary_crossentropy: 0.0217\n",
      "Epoch 166: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0217 - accuracy: 0.2973 - binary_crossentropy: 0.0217 - val_loss: 0.0498 - val_accuracy: 0.2229 - val_binary_crossentropy: 0.0498\n",
      "Epoch 167/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.3268 - binary_crossentropy: 0.0218\n",
      "Epoch 167: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0218 - accuracy: 0.3268 - binary_crossentropy: 0.0218 - val_loss: 0.0482 - val_accuracy: 0.2264 - val_binary_crossentropy: 0.0482\n",
      "Epoch 168/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.2659 - binary_crossentropy: 0.0218\n",
      "Epoch 168: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0218 - accuracy: 0.2658 - binary_crossentropy: 0.0218 - val_loss: 0.0487 - val_accuracy: 0.1397 - val_binary_crossentropy: 0.0487\n",
      "Epoch 169/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.2601 - binary_crossentropy: 0.0216\n",
      "Epoch 169: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0216 - accuracy: 0.2600 - binary_crossentropy: 0.0216 - val_loss: 0.0493 - val_accuracy: 0.1445 - val_binary_crossentropy: 0.0493\n",
      "Epoch 170/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.2861 - binary_crossentropy: 0.0215\n",
      "Epoch 170: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0215 - accuracy: 0.2861 - binary_crossentropy: 0.0215 - val_loss: 0.0487 - val_accuracy: 0.1476 - val_binary_crossentropy: 0.0487\n",
      "Epoch 171/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.2890 - binary_crossentropy: 0.0217\n",
      "Epoch 171: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0217 - accuracy: 0.2890 - binary_crossentropy: 0.0217 - val_loss: 0.0483 - val_accuracy: 0.2295 - val_binary_crossentropy: 0.0483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.3184 - binary_crossentropy: 0.0217\n",
      "Epoch 172: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0217 - accuracy: 0.3184 - binary_crossentropy: 0.0217 - val_loss: 0.0480 - val_accuracy: 0.2365 - val_binary_crossentropy: 0.0480\n",
      "Epoch 173/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.2974 - binary_crossentropy: 0.0213\n",
      "Epoch 173: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0213 - accuracy: 0.2974 - binary_crossentropy: 0.0213 - val_loss: 0.0481 - val_accuracy: 0.1451 - val_binary_crossentropy: 0.0481\n",
      "Epoch 174/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.2933 - binary_crossentropy: 0.0215\n",
      "Epoch 174: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0215 - accuracy: 0.2933 - binary_crossentropy: 0.0215 - val_loss: 0.0489 - val_accuracy: 0.1416 - val_binary_crossentropy: 0.0489\n",
      "Epoch 175/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.2956 - binary_crossentropy: 0.0214\n",
      "Epoch 175: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0214 - accuracy: 0.2956 - binary_crossentropy: 0.0214 - val_loss: 0.0491 - val_accuracy: 0.2298 - val_binary_crossentropy: 0.0491\n",
      "Epoch 176/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.3251 - binary_crossentropy: 0.0212\n",
      "Epoch 176: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0212 - accuracy: 0.3251 - binary_crossentropy: 0.0212 - val_loss: 0.0486 - val_accuracy: 0.2365 - val_binary_crossentropy: 0.0486\n",
      "Epoch 177/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.3077 - binary_crossentropy: 0.0212\n",
      "Epoch 177: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 38ms/step - loss: 0.0212 - accuracy: 0.3077 - binary_crossentropy: 0.0212 - val_loss: 0.0483 - val_accuracy: 0.2292 - val_binary_crossentropy: 0.0483\n",
      "Epoch 178/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.3037 - binary_crossentropy: 0.0214\n",
      "Epoch 178: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0214 - accuracy: 0.3036 - binary_crossentropy: 0.0214 - val_loss: 0.0486 - val_accuracy: 0.1369 - val_binary_crossentropy: 0.0486\n",
      "Epoch 179/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.2925 - binary_crossentropy: 0.0211\n",
      "Epoch 179: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0211 - accuracy: 0.2925 - binary_crossentropy: 0.0211 - val_loss: 0.0479 - val_accuracy: 0.1423 - val_binary_crossentropy: 0.0479\n",
      "Epoch 180/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.3069 - binary_crossentropy: 0.0210\n",
      "Epoch 180: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 34s 38ms/step - loss: 0.0210 - accuracy: 0.3069 - binary_crossentropy: 0.0210 - val_loss: 0.0480 - val_accuracy: 0.1416 - val_binary_crossentropy: 0.0480\n",
      "Epoch 181/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.3063 - binary_crossentropy: 0.0206\n",
      "Epoch 181: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0206 - accuracy: 0.3063 - binary_crossentropy: 0.0206 - val_loss: 0.0484 - val_accuracy: 0.1439 - val_binary_crossentropy: 0.0484\n",
      "Epoch 182/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.3173 - binary_crossentropy: 0.0211\n",
      "Epoch 182: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0211 - accuracy: 0.3173 - binary_crossentropy: 0.0211 - val_loss: 0.0488 - val_accuracy: 0.2330 - val_binary_crossentropy: 0.0488\n",
      "Epoch 183/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.2960 - binary_crossentropy: 0.0209\n",
      "Epoch 183: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 30s 33ms/step - loss: 0.0209 - accuracy: 0.2960 - binary_crossentropy: 0.0209 - val_loss: 0.0496 - val_accuracy: 0.2374 - val_binary_crossentropy: 0.0496\n",
      "Epoch 184/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.3157 - binary_crossentropy: 0.0210\n",
      "Epoch 184: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 29s 33ms/step - loss: 0.0210 - accuracy: 0.3156 - binary_crossentropy: 0.0210 - val_loss: 0.0488 - val_accuracy: 0.1464 - val_binary_crossentropy: 0.0488\n",
      "Epoch 185/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.3001 - binary_crossentropy: 0.0211\n",
      "Epoch 185: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 30s 34ms/step - loss: 0.0211 - accuracy: 0.3000 - binary_crossentropy: 0.0211 - val_loss: 0.0482 - val_accuracy: 0.1426 - val_binary_crossentropy: 0.0482\n",
      "Epoch 186/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.2900 - binary_crossentropy: 0.0210\n",
      "Epoch 186: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0210 - accuracy: 0.2900 - binary_crossentropy: 0.0210 - val_loss: 0.0495 - val_accuracy: 0.1461 - val_binary_crossentropy: 0.0495\n",
      "Epoch 187/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.2892 - binary_crossentropy: 0.0209\n",
      "Epoch 187: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 30s 34ms/step - loss: 0.0209 - accuracy: 0.2892 - binary_crossentropy: 0.0209 - val_loss: 0.0486 - val_accuracy: 0.1363 - val_binary_crossentropy: 0.0486\n",
      "Epoch 188/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.3057 - binary_crossentropy: 0.0213\n",
      "Epoch 188: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 35s 39ms/step - loss: 0.0213 - accuracy: 0.3057 - binary_crossentropy: 0.0213 - val_loss: 0.0496 - val_accuracy: 0.1318 - val_binary_crossentropy: 0.0496\n",
      "Epoch 189/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.3095 - binary_crossentropy: 0.0215\n",
      "Epoch 189: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0215 - accuracy: 0.3094 - binary_crossentropy: 0.0215 - val_loss: 0.0499 - val_accuracy: 0.1255 - val_binary_crossentropy: 0.0499\n",
      "Epoch 190/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.2968 - binary_crossentropy: 0.0218\n",
      "Epoch 190: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0218 - accuracy: 0.2968 - binary_crossentropy: 0.0218 - val_loss: 0.0508 - val_accuracy: 0.2115 - val_binary_crossentropy: 0.0508\n",
      "Epoch 191/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.3049 - binary_crossentropy: 0.0211\n",
      "Epoch 191: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0211 - accuracy: 0.3049 - binary_crossentropy: 0.0211 - val_loss: 0.0481 - val_accuracy: 0.1334 - val_binary_crossentropy: 0.0481\n",
      "Epoch 192/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.3071 - binary_crossentropy: 0.0205\n",
      "Epoch 192: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0205 - accuracy: 0.3070 - binary_crossentropy: 0.0205 - val_loss: 0.0490 - val_accuracy: 0.1306 - val_binary_crossentropy: 0.0490\n",
      "Epoch 193/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.2735 - binary_crossentropy: 0.0207\n",
      "Epoch 193: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0207 - accuracy: 0.2735 - binary_crossentropy: 0.0207 - val_loss: 0.0494 - val_accuracy: 0.1299 - val_binary_crossentropy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.3012 - binary_crossentropy: 0.0210\n",
      "Epoch 194: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0210 - accuracy: 0.3012 - binary_crossentropy: 0.0210 - val_loss: 0.0500 - val_accuracy: 0.2200 - val_binary_crossentropy: 0.0500\n",
      "Epoch 195/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.2917 - binary_crossentropy: 0.0207\n",
      "Epoch 195: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0207 - accuracy: 0.2917 - binary_crossentropy: 0.0207 - val_loss: 0.0494 - val_accuracy: 0.1296 - val_binary_crossentropy: 0.0494\n",
      "Epoch 196/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.3064 - binary_crossentropy: 0.0207\n",
      "Epoch 196: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0207 - accuracy: 0.3063 - binary_crossentropy: 0.0207 - val_loss: 0.0496 - val_accuracy: 0.2166 - val_binary_crossentropy: 0.0496\n",
      "Epoch 197/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.2647 - binary_crossentropy: 0.0208\n",
      "Epoch 197: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0208 - accuracy: 0.2646 - binary_crossentropy: 0.0208 - val_loss: 0.0498 - val_accuracy: 0.1344 - val_binary_crossentropy: 0.0498\n",
      "Epoch 198/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.2934 - binary_crossentropy: 0.0204\n",
      "Epoch 198: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0204 - accuracy: 0.2934 - binary_crossentropy: 0.0204 - val_loss: 0.0503 - val_accuracy: 0.1318 - val_binary_crossentropy: 0.0503\n",
      "Epoch 199/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.3161 - binary_crossentropy: 0.0201\n",
      "Epoch 199: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0201 - accuracy: 0.3160 - binary_crossentropy: 0.0201 - val_loss: 0.0501 - val_accuracy: 0.2207 - val_binary_crossentropy: 0.0501\n",
      "Epoch 200/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.3079 - binary_crossentropy: 0.0204\n",
      "Epoch 200: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0204 - accuracy: 0.3078 - binary_crossentropy: 0.0204 - val_loss: 0.0492 - val_accuracy: 0.2245 - val_binary_crossentropy: 0.0492\n",
      "Epoch 201/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.3257 - binary_crossentropy: 0.0206\n",
      "Epoch 201: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0206 - accuracy: 0.3256 - binary_crossentropy: 0.0206 - val_loss: 0.0500 - val_accuracy: 0.1318 - val_binary_crossentropy: 0.0500\n",
      "Epoch 202/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.3092 - binary_crossentropy: 0.0204\n",
      "Epoch 202: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0204 - accuracy: 0.3092 - binary_crossentropy: 0.0204 - val_loss: 0.0492 - val_accuracy: 0.1331 - val_binary_crossentropy: 0.0492\n",
      "Epoch 203/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.3264 - binary_crossentropy: 0.0204\n",
      "Epoch 203: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0204 - accuracy: 0.3263 - binary_crossentropy: 0.0204 - val_loss: 0.0503 - val_accuracy: 0.1426 - val_binary_crossentropy: 0.0503\n",
      "Epoch 204/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.2764 - binary_crossentropy: 0.0205\n",
      "Epoch 204: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0205 - accuracy: 0.2764 - binary_crossentropy: 0.0205 - val_loss: 0.0483 - val_accuracy: 0.2229 - val_binary_crossentropy: 0.0483\n",
      "Epoch 205/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.3316 - binary_crossentropy: 0.0202\n",
      "Epoch 205: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0202 - accuracy: 0.3316 - binary_crossentropy: 0.0202 - val_loss: 0.0496 - val_accuracy: 0.2254 - val_binary_crossentropy: 0.0496\n",
      "Epoch 206/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.3015 - binary_crossentropy: 0.0201\n",
      "Epoch 206: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0201 - accuracy: 0.3015 - binary_crossentropy: 0.0201 - val_loss: 0.0504 - val_accuracy: 0.1274 - val_binary_crossentropy: 0.0504\n",
      "Epoch 207/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.3248 - binary_crossentropy: 0.0201\n",
      "Epoch 207: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0201 - accuracy: 0.3248 - binary_crossentropy: 0.0201 - val_loss: 0.0505 - val_accuracy: 0.2226 - val_binary_crossentropy: 0.0505\n",
      "Epoch 208/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.3288 - binary_crossentropy: 0.0198\n",
      "Epoch 208: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0198 - accuracy: 0.3288 - binary_crossentropy: 0.0198 - val_loss: 0.0496 - val_accuracy: 0.2223 - val_binary_crossentropy: 0.0496\n",
      "Epoch 209/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.2997 - binary_crossentropy: 0.0203\n",
      "Epoch 209: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0203 - accuracy: 0.2996 - binary_crossentropy: 0.0203 - val_loss: 0.0503 - val_accuracy: 0.2248 - val_binary_crossentropy: 0.0503\n",
      "Epoch 210/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.3226 - binary_crossentropy: 0.0201\n",
      "Epoch 210: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0201 - accuracy: 0.3225 - binary_crossentropy: 0.0201 - val_loss: 0.0501 - val_accuracy: 0.2207 - val_binary_crossentropy: 0.0501\n",
      "Epoch 211/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.3230 - binary_crossentropy: 0.0198\n",
      "Epoch 211: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0198 - accuracy: 0.3230 - binary_crossentropy: 0.0198 - val_loss: 0.0489 - val_accuracy: 0.2169 - val_binary_crossentropy: 0.0489\n",
      "Epoch 212/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.3380 - binary_crossentropy: 0.0199\n",
      "Epoch 212: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0199 - accuracy: 0.3380 - binary_crossentropy: 0.0199 - val_loss: 0.0495 - val_accuracy: 0.2204 - val_binary_crossentropy: 0.0495\n",
      "Epoch 213/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.3120 - binary_crossentropy: 0.0202\n",
      "Epoch 213: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0202 - accuracy: 0.3120 - binary_crossentropy: 0.0202 - val_loss: 0.0475 - val_accuracy: 0.1401 - val_binary_crossentropy: 0.0475\n",
      "Epoch 214/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.3009 - binary_crossentropy: 0.0200\n",
      "Epoch 214: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0200 - accuracy: 0.3008 - binary_crossentropy: 0.0200 - val_loss: 0.0470 - val_accuracy: 0.2343 - val_binary_crossentropy: 0.0470\n",
      "Epoch 215/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.3048 - binary_crossentropy: 0.0200\n",
      "Epoch 215: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0200 - accuracy: 0.3048 - binary_crossentropy: 0.0200 - val_loss: 0.0480 - val_accuracy: 0.2257 - val_binary_crossentropy: 0.0480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.3076 - binary_crossentropy: 0.0195\n",
      "Epoch 216: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0195 - accuracy: 0.3076 - binary_crossentropy: 0.0195 - val_loss: 0.0481 - val_accuracy: 0.1432 - val_binary_crossentropy: 0.0481\n",
      "Epoch 217/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.3128 - binary_crossentropy: 0.0196\n",
      "Epoch 217: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0196 - accuracy: 0.3128 - binary_crossentropy: 0.0196 - val_loss: 0.0491 - val_accuracy: 0.2242 - val_binary_crossentropy: 0.0491\n",
      "Epoch 218/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.3041 - binary_crossentropy: 0.0197\n",
      "Epoch 218: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0197 - accuracy: 0.3041 - binary_crossentropy: 0.0197 - val_loss: 0.0486 - val_accuracy: 0.2276 - val_binary_crossentropy: 0.0486\n",
      "Epoch 219/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.2857 - binary_crossentropy: 0.0196\n",
      "Epoch 219: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0196 - accuracy: 0.2857 - binary_crossentropy: 0.0196 - val_loss: 0.0489 - val_accuracy: 0.2349 - val_binary_crossentropy: 0.0489\n",
      "Epoch 220/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.3218 - binary_crossentropy: 0.0198\n",
      "Epoch 220: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0198 - accuracy: 0.3218 - binary_crossentropy: 0.0198 - val_loss: 0.0486 - val_accuracy: 0.2257 - val_binary_crossentropy: 0.0486\n",
      "Epoch 221/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.3175 - binary_crossentropy: 0.0196\n",
      "Epoch 221: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0196 - accuracy: 0.3175 - binary_crossentropy: 0.0196 - val_loss: 0.0492 - val_accuracy: 0.1473 - val_binary_crossentropy: 0.0492\n",
      "Epoch 222/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3005 - binary_crossentropy: 0.0194\n",
      "Epoch 222: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0193 - accuracy: 0.3004 - binary_crossentropy: 0.0193 - val_loss: 0.0485 - val_accuracy: 0.2314 - val_binary_crossentropy: 0.0485\n",
      "Epoch 223/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.3187 - binary_crossentropy: 0.0200\n",
      "Epoch 223: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 35ms/step - loss: 0.0200 - accuracy: 0.3187 - binary_crossentropy: 0.0200 - val_loss: 0.0493 - val_accuracy: 0.2343 - val_binary_crossentropy: 0.0493\n",
      "Epoch 224/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.3011 - binary_crossentropy: 0.0198\n",
      "Epoch 224: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 35ms/step - loss: 0.0198 - accuracy: 0.3011 - binary_crossentropy: 0.0198 - val_loss: 0.0489 - val_accuracy: 0.2324 - val_binary_crossentropy: 0.0489\n",
      "Epoch 225/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3053 - binary_crossentropy: 0.0194\n",
      "Epoch 225: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0195 - accuracy: 0.3052 - binary_crossentropy: 0.0195 - val_loss: 0.0495 - val_accuracy: 0.2213 - val_binary_crossentropy: 0.0495\n",
      "Epoch 226/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.3138 - binary_crossentropy: 0.0195\n",
      "Epoch 226: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0195 - accuracy: 0.3137 - binary_crossentropy: 0.0195 - val_loss: 0.0491 - val_accuracy: 0.1483 - val_binary_crossentropy: 0.0491\n",
      "Epoch 227/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.3438 - binary_crossentropy: 0.0194\n",
      "Epoch 227: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0194 - accuracy: 0.3438 - binary_crossentropy: 0.0194 - val_loss: 0.0488 - val_accuracy: 0.2384 - val_binary_crossentropy: 0.0488\n",
      "Epoch 228/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.3342 - binary_crossentropy: 0.0196\n",
      "Epoch 228: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0196 - accuracy: 0.3342 - binary_crossentropy: 0.0196 - val_loss: 0.0494 - val_accuracy: 0.2197 - val_binary_crossentropy: 0.0494\n",
      "Epoch 229/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3291 - binary_crossentropy: 0.0194\n",
      "Epoch 229: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0194 - accuracy: 0.3291 - binary_crossentropy: 0.0194 - val_loss: 0.0501 - val_accuracy: 0.1309 - val_binary_crossentropy: 0.0501\n",
      "Epoch 230/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.2665 - binary_crossentropy: 0.0197\n",
      "Epoch 230: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0197 - accuracy: 0.2665 - binary_crossentropy: 0.0197 - val_loss: 0.0506 - val_accuracy: 0.1382 - val_binary_crossentropy: 0.0506\n",
      "Epoch 231/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3002 - binary_crossentropy: 0.0194\n",
      "Epoch 231: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0194 - accuracy: 0.3001 - binary_crossentropy: 0.0194 - val_loss: 0.0489 - val_accuracy: 0.1382 - val_binary_crossentropy: 0.0489\n",
      "Epoch 232/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3052 - binary_crossentropy: 0.0194\n",
      "Epoch 232: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0194 - accuracy: 0.3051 - binary_crossentropy: 0.0194 - val_loss: 0.0509 - val_accuracy: 0.2257 - val_binary_crossentropy: 0.0509\n",
      "Epoch 233/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.2952 - binary_crossentropy: 0.0192\n",
      "Epoch 233: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0192 - accuracy: 0.2952 - binary_crossentropy: 0.0192 - val_loss: 0.0502 - val_accuracy: 0.2210 - val_binary_crossentropy: 0.0502\n",
      "Epoch 234/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.2989 - binary_crossentropy: 0.0199\n",
      "Epoch 234: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0199 - accuracy: 0.2989 - binary_crossentropy: 0.0199 - val_loss: 0.0494 - val_accuracy: 0.1416 - val_binary_crossentropy: 0.0494\n",
      "Epoch 235/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.2949 - binary_crossentropy: 0.0196\n",
      "Epoch 235: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0196 - accuracy: 0.2948 - binary_crossentropy: 0.0196 - val_loss: 0.0505 - val_accuracy: 0.1394 - val_binary_crossentropy: 0.0505\n",
      "Epoch 236/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.3278 - binary_crossentropy: 0.0200\n",
      "Epoch 236: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0200 - accuracy: 0.3276 - binary_crossentropy: 0.0200 - val_loss: 0.0487 - val_accuracy: 0.2131 - val_binary_crossentropy: 0.0487\n",
      "Epoch 237/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.3150 - binary_crossentropy: 0.0195\n",
      "Epoch 237: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0195 - accuracy: 0.3149 - binary_crossentropy: 0.0195 - val_loss: 0.0495 - val_accuracy: 0.2207 - val_binary_crossentropy: 0.0495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.3342 - binary_crossentropy: 0.0199\n",
      "Epoch 238: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0199 - accuracy: 0.3341 - binary_crossentropy: 0.0199 - val_loss: 0.0497 - val_accuracy: 0.2314 - val_binary_crossentropy: 0.0497\n",
      "Epoch 239/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.3339 - binary_crossentropy: 0.0196\n",
      "Epoch 239: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0196 - accuracy: 0.3338 - binary_crossentropy: 0.0196 - val_loss: 0.0495 - val_accuracy: 0.2242 - val_binary_crossentropy: 0.0495\n",
      "Epoch 240/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.3047 - binary_crossentropy: 0.0194\n",
      "Epoch 240: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 33s 37ms/step - loss: 0.0194 - accuracy: 0.3046 - binary_crossentropy: 0.0194 - val_loss: 0.0492 - val_accuracy: 0.1426 - val_binary_crossentropy: 0.0492\n",
      "Epoch 241/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.3322 - binary_crossentropy: 0.0194\n",
      "Epoch 241: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0194 - accuracy: 0.3322 - binary_crossentropy: 0.0194 - val_loss: 0.0501 - val_accuracy: 0.2200 - val_binary_crossentropy: 0.0501\n",
      "Epoch 242/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.2984 - binary_crossentropy: 0.0195\n",
      "Epoch 242: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0195 - accuracy: 0.2983 - binary_crossentropy: 0.0195 - val_loss: 0.0485 - val_accuracy: 0.2270 - val_binary_crossentropy: 0.0485\n",
      "Epoch 243/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.3268 - binary_crossentropy: 0.0189\n",
      "Epoch 243: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0189 - accuracy: 0.3267 - binary_crossentropy: 0.0189 - val_loss: 0.0497 - val_accuracy: 0.2273 - val_binary_crossentropy: 0.0497\n",
      "Epoch 244/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.3278 - binary_crossentropy: 0.0192\n",
      "Epoch 244: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0192 - accuracy: 0.3277 - binary_crossentropy: 0.0192 - val_loss: 0.0492 - val_accuracy: 0.1420 - val_binary_crossentropy: 0.0492\n",
      "Epoch 245/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.3177 - binary_crossentropy: 0.0187\n",
      "Epoch 245: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0187 - accuracy: 0.3176 - binary_crossentropy: 0.0187 - val_loss: 0.0493 - val_accuracy: 0.2261 - val_binary_crossentropy: 0.0493\n",
      "Epoch 246/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.3204 - binary_crossentropy: 0.0191\n",
      "Epoch 246: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0191 - accuracy: 0.3204 - binary_crossentropy: 0.0191 - val_loss: 0.0496 - val_accuracy: 0.1385 - val_binary_crossentropy: 0.0496\n",
      "Epoch 247/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.2999 - binary_crossentropy: 0.0188\n",
      "Epoch 247: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0188 - accuracy: 0.2998 - binary_crossentropy: 0.0188 - val_loss: 0.0494 - val_accuracy: 0.1407 - val_binary_crossentropy: 0.0494\n",
      "Epoch 248/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.3143 - binary_crossentropy: 0.0192\n",
      "Epoch 248: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0192 - accuracy: 0.3142 - binary_crossentropy: 0.0192 - val_loss: 0.0489 - val_accuracy: 0.1394 - val_binary_crossentropy: 0.0489\n",
      "Epoch 249/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.3154 - binary_crossentropy: 0.0189\n",
      "Epoch 249: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0189 - accuracy: 0.3154 - binary_crossentropy: 0.0189 - val_loss: 0.0504 - val_accuracy: 0.2235 - val_binary_crossentropy: 0.0504\n",
      "Epoch 250/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.2988 - binary_crossentropy: 0.0190\n",
      "Epoch 250: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0190 - accuracy: 0.2988 - binary_crossentropy: 0.0190 - val_loss: 0.0511 - val_accuracy: 0.2251 - val_binary_crossentropy: 0.0511\n",
      "Epoch 251/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.2794 - binary_crossentropy: 0.0189\n",
      "Epoch 251: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0189 - accuracy: 0.2793 - binary_crossentropy: 0.0189 - val_loss: 0.0505 - val_accuracy: 0.1397 - val_binary_crossentropy: 0.0505\n",
      "Epoch 252/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.3164 - binary_crossentropy: 0.0186\n",
      "Epoch 252: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0186 - accuracy: 0.3164 - binary_crossentropy: 0.0186 - val_loss: 0.0502 - val_accuracy: 0.2257 - val_binary_crossentropy: 0.0502\n",
      "Epoch 253/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.3231 - binary_crossentropy: 0.0189\n",
      "Epoch 253: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0189 - accuracy: 0.3230 - binary_crossentropy: 0.0189 - val_loss: 0.0486 - val_accuracy: 0.2279 - val_binary_crossentropy: 0.0486\n",
      "Epoch 254/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.3262 - binary_crossentropy: 0.0190\n",
      "Epoch 254: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 35ms/step - loss: 0.0190 - accuracy: 0.3261 - binary_crossentropy: 0.0190 - val_loss: 0.0495 - val_accuracy: 0.1410 - val_binary_crossentropy: 0.0495\n",
      "Epoch 255/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.3119 - binary_crossentropy: 0.0189\n",
      "Epoch 255: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0189 - accuracy: 0.3119 - binary_crossentropy: 0.0189 - val_loss: 0.0521 - val_accuracy: 0.2273 - val_binary_crossentropy: 0.0521\n",
      "Epoch 256/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.3101 - binary_crossentropy: 0.0186\n",
      "Epoch 256: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 31s 35ms/step - loss: 0.0186 - accuracy: 0.3101 - binary_crossentropy: 0.0186 - val_loss: 0.0500 - val_accuracy: 0.1363 - val_binary_crossentropy: 0.0500\n",
      "Epoch 257/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.3032 - binary_crossentropy: 0.0190\n",
      "Epoch 257: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0190 - accuracy: 0.3032 - binary_crossentropy: 0.0190 - val_loss: 0.0496 - val_accuracy: 0.2302 - val_binary_crossentropy: 0.0496\n",
      "Epoch 258/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.3081 - binary_crossentropy: 0.0188\n",
      "Epoch 258: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 32s 36ms/step - loss: 0.0188 - accuracy: 0.3081 - binary_crossentropy: 0.0188 - val_loss: 0.0478 - val_accuracy: 0.2283 - val_binary_crossentropy: 0.0478\n",
      "Epoch 259/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.3054 - binary_crossentropy: 0.0188\n",
      "Epoch 259: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 26s 29ms/step - loss: 0.0188 - accuracy: 0.3052 - binary_crossentropy: 0.0188 - val_loss: 0.0489 - val_accuracy: 0.2295 - val_binary_crossentropy: 0.0489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.3083 - binary_crossentropy: 0.0189\n",
      "Epoch 260: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0189 - accuracy: 0.3082 - binary_crossentropy: 0.0189 - val_loss: 0.0493 - val_accuracy: 0.2276 - val_binary_crossentropy: 0.0493\n",
      "Epoch 261/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.3272 - binary_crossentropy: 0.0186\n",
      "Epoch 261: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0186 - accuracy: 0.3272 - binary_crossentropy: 0.0186 - val_loss: 0.0496 - val_accuracy: 0.2321 - val_binary_crossentropy: 0.0496\n",
      "Epoch 262/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.2909 - binary_crossentropy: 0.0191\n",
      "Epoch 262: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0191 - accuracy: 0.2909 - binary_crossentropy: 0.0191 - val_loss: 0.0491 - val_accuracy: 0.2270 - val_binary_crossentropy: 0.0491\n",
      "Epoch 263/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.3116 - binary_crossentropy: 0.0186\n",
      "Epoch 263: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0186 - accuracy: 0.3116 - binary_crossentropy: 0.0186 - val_loss: 0.0498 - val_accuracy: 0.1407 - val_binary_crossentropy: 0.0498\n",
      "Epoch 264/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.2938 - binary_crossentropy: 0.0185\n",
      "Epoch 264: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0185 - accuracy: 0.2938 - binary_crossentropy: 0.0185 - val_loss: 0.0479 - val_accuracy: 0.1442 - val_binary_crossentropy: 0.0479\n",
      "Epoch 265/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.3189 - binary_crossentropy: 0.0182\n",
      "Epoch 265: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0182 - accuracy: 0.3188 - binary_crossentropy: 0.0182 - val_loss: 0.0484 - val_accuracy: 0.2283 - val_binary_crossentropy: 0.0484\n",
      "Epoch 266/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.2868 - binary_crossentropy: 0.0185\n",
      "Epoch 266: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0185 - accuracy: 0.2867 - binary_crossentropy: 0.0185 - val_loss: 0.0484 - val_accuracy: 0.1439 - val_binary_crossentropy: 0.0484\n",
      "Epoch 267/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.2888 - binary_crossentropy: 0.0186\n",
      "Epoch 267: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0186 - accuracy: 0.2888 - binary_crossentropy: 0.0186 - val_loss: 0.0496 - val_accuracy: 0.2238 - val_binary_crossentropy: 0.0496\n",
      "Epoch 268/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.3106 - binary_crossentropy: 0.0187\n",
      "Epoch 268: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0187 - accuracy: 0.3106 - binary_crossentropy: 0.0187 - val_loss: 0.0505 - val_accuracy: 0.2279 - val_binary_crossentropy: 0.0505\n",
      "Epoch 269/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.2824 - binary_crossentropy: 0.0184\n",
      "Epoch 269: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0184 - accuracy: 0.2824 - binary_crossentropy: 0.0184 - val_loss: 0.0500 - val_accuracy: 0.1397 - val_binary_crossentropy: 0.0500\n",
      "Epoch 270/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.2922 - binary_crossentropy: 0.0187\n",
      "Epoch 270: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0187 - accuracy: 0.2921 - binary_crossentropy: 0.0187 - val_loss: 0.0496 - val_accuracy: 0.1413 - val_binary_crossentropy: 0.0496\n",
      "Epoch 271/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.3043 - binary_crossentropy: 0.0187\n",
      "Epoch 271: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0187 - accuracy: 0.3043 - binary_crossentropy: 0.0187 - val_loss: 0.0500 - val_accuracy: 0.2219 - val_binary_crossentropy: 0.0500\n",
      "Epoch 272/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.2942 - binary_crossentropy: 0.0186\n",
      "Epoch 272: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 22ms/step - loss: 0.0186 - accuracy: 0.2941 - binary_crossentropy: 0.0186 - val_loss: 0.0493 - val_accuracy: 0.1495 - val_binary_crossentropy: 0.0493\n",
      "Epoch 273/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.3034 - binary_crossentropy: 0.0187\n",
      "Epoch 273: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 23ms/step - loss: 0.0187 - accuracy: 0.3033 - binary_crossentropy: 0.0187 - val_loss: 0.0499 - val_accuracy: 0.1353 - val_binary_crossentropy: 0.0499\n",
      "Epoch 274/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.3091 - binary_crossentropy: 0.0183\n",
      "Epoch 274: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 23ms/step - loss: 0.0183 - accuracy: 0.3090 - binary_crossentropy: 0.0183 - val_loss: 0.0499 - val_accuracy: 0.1347 - val_binary_crossentropy: 0.0499\n",
      "Epoch 275/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.3247 - binary_crossentropy: 0.0186\n",
      "Epoch 275: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0186 - accuracy: 0.3246 - binary_crossentropy: 0.0186 - val_loss: 0.0479 - val_accuracy: 0.1416 - val_binary_crossentropy: 0.0479\n",
      "Epoch 276/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.3214 - binary_crossentropy: 0.0183\n",
      "Epoch 276: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0183 - accuracy: 0.3214 - binary_crossentropy: 0.0183 - val_loss: 0.0496 - val_accuracy: 0.1407 - val_binary_crossentropy: 0.0496\n",
      "Epoch 277/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.2941 - binary_crossentropy: 0.0185\n",
      "Epoch 277: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0185 - accuracy: 0.2939 - binary_crossentropy: 0.0185 - val_loss: 0.0485 - val_accuracy: 0.2295 - val_binary_crossentropy: 0.0485\n",
      "Epoch 278/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3272 - binary_crossentropy: 0.0181\n",
      "Epoch 278: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0181 - accuracy: 0.3270 - binary_crossentropy: 0.0181 - val_loss: 0.0497 - val_accuracy: 0.1404 - val_binary_crossentropy: 0.0497\n",
      "Epoch 279/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.3202 - binary_crossentropy: 0.0182\n",
      "Epoch 279: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0182 - accuracy: 0.3201 - binary_crossentropy: 0.0182 - val_loss: 0.0494 - val_accuracy: 0.1359 - val_binary_crossentropy: 0.0494\n",
      "Epoch 280/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.3076 - binary_crossentropy: 0.0183\n",
      "Epoch 280: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0183 - accuracy: 0.3074 - binary_crossentropy: 0.0183 - val_loss: 0.0498 - val_accuracy: 0.2314 - val_binary_crossentropy: 0.0498\n",
      "Epoch 281/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3310 - binary_crossentropy: 0.0181\n",
      "Epoch 281: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0181 - accuracy: 0.3309 - binary_crossentropy: 0.0181 - val_loss: 0.0496 - val_accuracy: 0.1397 - val_binary_crossentropy: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.3032 - binary_crossentropy: 0.0183\n",
      "Epoch 282: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 22ms/step - loss: 0.0183 - accuracy: 0.3032 - binary_crossentropy: 0.0183 - val_loss: 0.0499 - val_accuracy: 0.2261 - val_binary_crossentropy: 0.0499\n",
      "Epoch 283/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.2967 - binary_crossentropy: 0.0181\n",
      "Epoch 283: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0181 - accuracy: 0.2967 - binary_crossentropy: 0.0181 - val_loss: 0.0499 - val_accuracy: 0.2346 - val_binary_crossentropy: 0.0499\n",
      "Epoch 284/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.3001 - binary_crossentropy: 0.0185\n",
      "Epoch 284: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 22ms/step - loss: 0.0185 - accuracy: 0.3000 - binary_crossentropy: 0.0185 - val_loss: 0.0500 - val_accuracy: 0.1388 - val_binary_crossentropy: 0.0500\n",
      "Epoch 285/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3037 - binary_crossentropy: 0.0181\n",
      "Epoch 285: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0181 - accuracy: 0.3036 - binary_crossentropy: 0.0181 - val_loss: 0.0507 - val_accuracy: 0.2273 - val_binary_crossentropy: 0.0507\n",
      "Epoch 286/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.2863 - binary_crossentropy: 0.0182\n",
      "Epoch 286: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0182 - accuracy: 0.2862 - binary_crossentropy: 0.0182 - val_loss: 0.0497 - val_accuracy: 0.2317 - val_binary_crossentropy: 0.0497\n",
      "Epoch 287/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.3019 - binary_crossentropy: 0.0185\n",
      "Epoch 287: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0185 - accuracy: 0.3019 - binary_crossentropy: 0.0185 - val_loss: 0.0491 - val_accuracy: 0.1439 - val_binary_crossentropy: 0.0491\n",
      "Epoch 288/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.3146 - binary_crossentropy: 0.0182\n",
      "Epoch 288: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0182 - accuracy: 0.3146 - binary_crossentropy: 0.0182 - val_loss: 0.0531 - val_accuracy: 0.2213 - val_binary_crossentropy: 0.0531\n",
      "Epoch 289/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.3100 - binary_crossentropy: 0.0182\n",
      "Epoch 289: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0182 - accuracy: 0.3099 - binary_crossentropy: 0.0182 - val_loss: 0.0489 - val_accuracy: 0.2333 - val_binary_crossentropy: 0.0489\n",
      "Epoch 290/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3165 - binary_crossentropy: 0.0181\n",
      "Epoch 290: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 22s 24ms/step - loss: 0.0181 - accuracy: 0.3164 - binary_crossentropy: 0.0181 - val_loss: 0.0497 - val_accuracy: 0.2352 - val_binary_crossentropy: 0.0497\n",
      "Epoch 291/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3003 - binary_crossentropy: 0.0181\n",
      "Epoch 291: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0181 - accuracy: 0.3003 - binary_crossentropy: 0.0181 - val_loss: 0.0493 - val_accuracy: 0.2381 - val_binary_crossentropy: 0.0493\n",
      "Epoch 292/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.3167 - binary_crossentropy: 0.0184\n",
      "Epoch 292: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 22ms/step - loss: 0.0184 - accuracy: 0.3167 - binary_crossentropy: 0.0184 - val_loss: 0.0503 - val_accuracy: 0.2235 - val_binary_crossentropy: 0.0503\n",
      "Epoch 293/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.3250 - binary_crossentropy: 0.0181\n",
      "Epoch 293: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0181 - accuracy: 0.3248 - binary_crossentropy: 0.0181 - val_loss: 0.0520 - val_accuracy: 0.1344 - val_binary_crossentropy: 0.0520\n",
      "Epoch 294/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.2907 - binary_crossentropy: 0.0180\n",
      "Epoch 294: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0180 - accuracy: 0.2906 - binary_crossentropy: 0.0180 - val_loss: 0.0489 - val_accuracy: 0.1451 - val_binary_crossentropy: 0.0489\n",
      "Epoch 295/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.2859 - binary_crossentropy: 0.0179\n",
      "Epoch 295: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0179 - accuracy: 0.2857 - binary_crossentropy: 0.0179 - val_loss: 0.0487 - val_accuracy: 0.1445 - val_binary_crossentropy: 0.0487\n",
      "Epoch 296/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.2924 - binary_crossentropy: 0.0180\n",
      "Epoch 296: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0180 - accuracy: 0.2923 - binary_crossentropy: 0.0180 - val_loss: 0.0495 - val_accuracy: 0.1407 - val_binary_crossentropy: 0.0495\n",
      "Epoch 297/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.2975 - binary_crossentropy: 0.0182\n",
      "Epoch 297: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 19s 21ms/step - loss: 0.0182 - accuracy: 0.2974 - binary_crossentropy: 0.0182 - val_loss: 0.0489 - val_accuracy: 0.2273 - val_binary_crossentropy: 0.0489\n",
      "Epoch 298/300\n",
      "890/890 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.3197 - binary_crossentropy: 0.0180\n",
      "Epoch 298: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 21s 23ms/step - loss: 0.0180 - accuracy: 0.3197 - binary_crossentropy: 0.0180 - val_loss: 0.0510 - val_accuracy: 0.2270 - val_binary_crossentropy: 0.0510\n",
      "Epoch 299/300\n",
      "889/890 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.2892 - binary_crossentropy: 0.0183\n",
      "Epoch 299: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 20s 22ms/step - loss: 0.0183 - accuracy: 0.2892 - binary_crossentropy: 0.0183 - val_loss: 0.0513 - val_accuracy: 0.2245 - val_binary_crossentropy: 0.0513\n",
      "Epoch 300/300\n",
      "888/890 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.3207 - binary_crossentropy: 0.0182\n",
      "Epoch 300: val_loss did not improve from 0.04656\n",
      "890/890 [==============================] - 21s 23ms/step - loss: 0.0182 - accuracy: 0.3206 - binary_crossentropy: 0.0182 - val_loss: 0.0516 - val_accuracy: 0.1457 - val_binary_crossentropy: 0.0516\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "\n",
    "# very very very basic LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(sequence_len, input_shape=(sequence_len, len(instruments)), return_sequences=True, dropout=dropout))\n",
    "model.add(LSTM(sequence_len, return_sequences=True, dropout=dropout))\n",
    "model.add(LSTM(sequence_len, dropout=dropout))\n",
    "model.add(Dense(output_shape, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.BinaryCrossentropy()])\n",
    "model.summary()\n",
    "mc = ModelCheckpoint(filepath='./new_encode_1st_try.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(inputs_list, outputs_list, epochs=300, callbacks=mc, validation_split=0.1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfdcfa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['binary_crossentropy'])\n",
    "plt.plot(history.history['val_binary_crossentropy'])\n",
    "plt.title('Model binary crossetropy')\n",
    "plt.ylabel('Binary crossetropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['binary_crossentropy', 'val_binary_crossentropy'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d450a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_list = []\n",
    "test_out = []\n",
    "raw_notes = test.values\n",
    "for i in range(len(raw_notes) - sequence_len):\n",
    "    input_start = i\n",
    "    input_end = i + sequence_len\n",
    "    output_start = input_end\n",
    "    output_end = output_start + 1\n",
    "\n",
    "    # for every 32 notes sequence set next note as output\n",
    "    test2_list.append(raw_notes[input_start:input_end])\n",
    "    test_out.append(raw_notes[output_start:output_end])\n",
    "\n",
    "test_out = list(np.array(test_out).reshape(-1, np.array(test_out).shape[-1]))\n",
    "\n",
    "test2_list = np.array(test2_list)\n",
    "test_out = np.array(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae63fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict new notes\n",
    "prediction = model.predict(test2_list, verbose=0)\n",
    "# round prediction to 1 or 0\n",
    "prediction = np.around(prediction)\n",
    "# retype it to int\n",
    "prediction = prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68aeada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f04fe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = 160\n",
    "file_name = \"./output/slipknot_final.mid\"\n",
    "create_midi(bpm, prediction, mid.ticks_per_beat, file_name, instruments)\n",
    "# create_midi(bpm, transcription.values, mid.ticks_per_beat, \"./output/transcription.mid\", instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72778f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_metric_complete_lines(candidate, reference):\n",
    "    correct_lines = 0\n",
    "    for i,c in enumerate(candidate):\n",
    "        # line of candidate is the same as reference\n",
    "        if (c == reference[i]).all() == True:\n",
    "            correct_lines += 1\n",
    "    \n",
    "    # probability of correct lines\n",
    "    return correct_lines/len(reference)\n",
    "\n",
    "def bleu_metric_ngrams(candidate, reference, ngram):\n",
    "    correct_ngrams = 0\n",
    "    offset = 0\n",
    "    true_flag = True\n",
    "    \n",
    "    for i,c in enumerate(candidate):\n",
    "        \n",
    "#         print(candidate[i+offset], reference[i+offset], (candidate[i+offset] == reference[i+offset]).all())\n",
    "        # line is correct\n",
    "        if (candidate[i] == reference[i]).all() == True:\n",
    "            pass\n",
    "        else:\n",
    "            true_flag = False\n",
    "\n",
    "        # every ngram sequence\n",
    "        if (i+1)%ngram == 0:\n",
    "#             print(i, true_flag)\n",
    "            # all sequence is correct\n",
    "            if true_flag:\n",
    "                correct_ngrams += 1\n",
    "            true_flag = True\n",
    "    \n",
    "    allngrams = len(reference)/ngram\n",
    "#     print(correct_ngrams, allngrams)\n",
    "    # probability of correct lines\n",
    "    return correct_ngrams/allngrams\n",
    "\n",
    "def bleu_metric_single_notes(candidate, reference, length_of_line):\n",
    "    correct_lines = 0\n",
    "    probabilities = []\n",
    "    for i,c in enumerate(candidate):\n",
    "        # how many notes are correct in single line\n",
    "        tmp = ((c == reference[i]) == True).sum()\n",
    "        # probability of correct notes in single line\n",
    "        probabilities.append(tmp/length_of_line)\n",
    "    \n",
    "    # geometric mean of probabilities\n",
    "    return gmean(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172358c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "candidate = prediction.copy()\n",
    "reference = test_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "087f0ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2879940893978574"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_complete_lines(candidate, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46166ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.337106593270036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_single_notes(candidate, reference, length_of_line=len(instruments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "088a6f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28016254155892134"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric_ngrams(candidate, reference, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d12a4c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9488.115195989609\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4005d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
